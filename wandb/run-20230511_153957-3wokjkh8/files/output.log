BEFORE NORMALIZATION:
[tensor([[10.1295],
        [20.2208],
        [10.9614],
        [47.8558],
        [22.9517],
        [18.3202],
        [11.4761],
        [20.0891],
        [12.4660],
        [46.7500],
        [13.3969],
        [31.8442],
        [12.0517],
        [10.9634],
        [12.5175],
        [32.4592],
        [12.3087],
        [33.2333],
        [20.3985],
        [25.7378],
        [10.8770],
        [20.6208],
        [11.7175],
        [41.4979],
        [12.1486],
        [21.8984],
        [10.1548],
        [37.3951],
        [17.0506],
        [16.7393],
        [10.0882],
        [18.2296],
        [ 9.6985],
        [29.5249],
        [17.5841],
        [32.9993],
        [13.2213],
        [10.6331],
        [18.5347],
        [36.7856],
        [ 9.6035],
        [29.1248],
        [ 9.3855],
        [54.3843],
        [16.7485],
        [13.7755],
        [ 9.5611],
        [18.4433],
        [ 9.2736],
        [17.3599],
        [13.5858],
        [45.0141],
        [13.6064],
        [29.5763],
        [ 9.4384],
        [28.7704],
        [17.2854],
        [35.9411],
        [10.3679],
        [24.8113],
        [11.1864],
        [11.3162],
        [10.4196],
        [30.7871],
        [11.9555],
        [25.5339],
        [13.5761],
        [23.6193],
        [11.7591],
        [14.9892],
        [14.5221],
        [41.1183],
        [ 9.9497],
        [22.3754],
        [ 9.7866],
        [40.6962],
        [14.5865],
        [14.5083],
        [ 9.7964],
        [25.0445],
        [ 9.7814],
        [26.6319],
        [15.1204],
        [51.0715],
        [19.5320],
        [25.5396],
        [ 9.7710],
        [20.1597],
        [15.9942],
        [45.7338],
        [15.4820],
        [29.5534],
        [13.7910],
        [10.6256],
        [12.3895],
        [23.9716],
        [ 9.0593],
        [12.7526],
        [10.7848],
        [41.1921],
        [16.2819],
        [21.5005],
        [10.2283],
        [28.0159],
        [13.3041],
        [37.0945],
        [ 9.6939],
        [27.6225],
        [10.5207],
        [11.1651],
        [10.5827],
        [40.0308],
        [ 9.8528],
        [39.2575],
        [26.3997],
        [35.7660],
        [11.3305],
        [12.7950],
        [13.9655],
        [37.9389],
        [10.1515],
        [28.3418],
        [ 9.8219],
        [50.2312],
        [20.4128],
        [14.5777],
        [ 9.3634],
        [13.7337],
        [ 9.2243],
        [39.0990],
        [17.8657],
        [34.5486],
        [12.7531],
        [12.8879],
        [16.3020],
        [38.3472],
        [ 9.8171],
        [25.1159],
        [ 9.6270],
        [45.3690],
        [21.1945],
        [11.7902],
        [ 9.3624],
        [16.1707],
        [ 9.3438],
        [16.8144],
        [12.1796],
        [36.5148],
        [17.1895],
        [29.9668],
        [ 9.6171],
        [21.6193],
        [17.3427],
        [41.2390],
        [13.0824],
        [26.0159],
        [11.0999],
        [12.3482],
        [ 9.2799],
        [36.2584],
        [10.4990],
        [20.3891],
        [12.3579],
        [57.2928],
        [18.4599],
        [18.3552],
        [10.6118],
        [25.7339],
        [12.3591],
        [40.9135],
        [10.6124],
        [31.1547],
        [11.8917],
        [11.0420],
        [16.2426],
        [27.1173],
        [13.9176],
        [25.4522],
        [19.5939],
        [24.6754],
        [10.8249],
        [14.7458],
        [12.6302],
        [40.7912],
        [10.3439],
        [25.2630],
        [ 9.9755],
        [44.8244],
        [14.1386],
        [20.1276],
        [ 9.8610],
        [21.1683],
        [ 9.3430],
        [16.6421],
        [10.8497],
        [42.8306],
        [15.5929],
        [28.0982],
        [10.1577],
        [28.5893],
        [17.4582],
        [33.5037],
        [ 9.8223],
        [21.8150],
        [11.3626],
        [10.9485],
        [10.6431],
        [36.9579],
        [10.8370],
        [39.1349],
        [21.2197],
        [28.9712],
        [13.5108],
        [13.4200],
        [16.6499],
        [30.0982],
        [10.3211],
        [31.8533],
        [11.5553],
        [52.4354],
        [19.3950],
        [15.7892],
        [ 9.2106],
        [15.6380],
        [10.7556],
        [24.7758],
        [17.2079],
        [28.9910],
        [10.9439],
        [14.3791],
        [12.7551],
        [49.7020],
        [ 9.9832],
        [19.7618],
        [11.6965],
        [39.0483],
        [14.9613],
        [14.2921],
        [ 9.1414],
        [21.6741],
        [ 9.2684],
        [20.8385],
        [13.8000],
        [50.1922],
        [19.7094],
        [19.0741],
        [10.3032],
        [20.3759],
        [12.5214],
        [50.2685],
        [14.6764],
        [36.3513],
        [11.7829],
        [10.9531],
        [12.0618],
        [26.3759],
        [10.6896],
        [30.8996],
        [15.2110],
        [26.0214],
        [11.1263],
        [15.8189],
        [13.0695],
        [48.1798],
        [11.1152],
        [18.7385],
        [10.6009],
        [36.8775],
        [16.9917],
        [15.0529],
        [ 9.1833],
        [20.9748],
        [ 9.1475],
        [23.4587],
        [14.3581],
        [44.9813],
        [21.1813],
        [22.5023],
        [10.8733],
        [17.6898],
        [13.0076],
        [49.5557],
        [16.4884],
        [34.2973],
        [12.7029],
        [10.8954],
        [10.2135],
        [26.8293],
        [ 9.1911],
        [15.7560],
        [10.9815],
        [45.0535],
        [14.2466],
        [21.9970],
        [ 9.7310],
        [33.8109],
        [15.5642],
        [32.2477],
        [ 9.3340],
        [25.0946],
        [10.7852],
        [11.0771],
        [12.0937],
        [34.7377],
        [11.5666],
        [34.4087],
        [25.8157],
        [31.0898],
        [12.0772],
        [11.6450],
        [17.2947],
        [33.4096],
        [ 9.8955],
        [30.7452],
        [ 9.8755],
        [56.5336],
        [18.2993],
        [15.7266],
        [ 9.0871],
        [15.0535],
        [10.2536],
        [22.8239],
        [12.7192],
        [51.7719],
        [19.2967],
        [21.7480],
        [11.1490],
        [22.7755],
        [12.8526],
        [40.2712],
        [11.6548],
        [29.2363],
        [13.4022],
        [11.7336],
        [12.9785],
        [27.4118],
        [13.6549],
        [31.5504],
        [17.2903],
        [21.4901],
        [11.2191],
        [16.3522],
        [12.9101],
        [39.5427],
        [11.3448],
        [24.4673],
        [10.1505],
        [43.2675],
        [15.8459],
        [21.3789],
        [10.6685],
        [20.3987],
        [ 9.4087],
        [33.6231],
        [21.4016],
        [35.7100],
        [11.7868],
        [11.3484],
        [17.1506],
        [41.5566],
        [ 9.3489],
        [24.8460],
        [ 9.8637],
        [50.5568],
        [19.5844],
        [11.8697],
        [ 9.5544],
        [15.7211],
        [ 9.4839],
        [16.1202],
        [12.3639],
        [39.0825],
        [14.9927],
        [24.0977],
        [ 9.2947],
        [26.8089],
        [15.7389],
        [39.3113],
        [11.2279],
        [29.2592],
        [10.9231],
        [13.5731],
        [ 9.8524],
        [33.3610],
        [ 9.1108],
        [16.0285],
        [10.3054],
        [37.7381],
        [17.2150],
        [24.0474],
        [10.3894],
        [27.2464],
        [15.4721],
        [35.3522],
        [11.0410],
        [25.7398],
        [10.8138],
        [11.3990],
        [ 9.8442],
        [38.6442],
        [10.0457],
        [43.0277],
        [27.5679],
        [31.3747],
        [12.1027],
        [14.6485],
        [14.9339],
        [33.3019],
        [10.3677],
        [28.0236],
        [10.0842],
        [47.9760],
        [22.5435],
        [13.7514],
        [ 9.1845],
        [14.0248],
        [12.2578],
        [24.4443],
        [13.8305],
        [25.1998],
        [11.0821],
        [12.3402],
        [14.7303],
        [47.9147],
        [ 9.5148],
        [21.3487],
        [10.6022],
        [45.4626],
        [13.5451],
        [17.0432],
        [ 9.3182],
        [23.1536],
        [ 9.6062],
        [22.7573],
        [18.1305],
        [53.8470],
        [17.1342],
        [21.4679],
        [ 9.8569],
        [22.4319],
        [13.2900],
        [44.3405],
        [11.9589],
        [32.7511],
        [13.0894],
        [10.5196],
        [12.9010],
        [23.2165],
        [ 9.8657],
        [33.0966],
        [18.5492],
        [29.4049],
        [13.6151],
        [11.4231],
        [19.1636],
        [33.1996],
        [ 9.6685],
        [28.4159],
        [ 9.4823],
        [51.2177],
        [19.3625],
        [12.7096],
        [ 9.0528],
        [18.5606],
        [ 9.0888],
        [21.6090],
        [12.2309],
        [39.9561],
        [14.6085],
        [32.5093],
        [ 9.5276],
        [27.5490],
        [19.5826],
        [35.1425],
        [12.2242],
        [24.0470],
        [11.8059],
        [11.8269],
        [ 9.7326],
        [29.9513],
        [ 9.5458],
        [17.1874],
        [12.4910],
        [49.7541],
        [20.2203],
        [15.5355],
        [11.7386],
        [22.3438],
        [10.4616],
        [45.8155],
        [10.6597],
        [35.8723],
        [11.5040],
        [10.8960],
        [13.1257],
        [31.4681],
        [12.7404],
        [31.7642],
        [20.6926],
        [27.5073],
        [10.3311],
        [16.3831],
        [11.6828],
        [48.8879],
        [11.2198],
        [20.9304],
        [10.5715],
        [41.8859],
        [16.2205],
        [19.4111],
        [ 9.2293],
        [16.7357]], device='cuda:0', dtype=torch.float64), tensor([[14.1325],
        [23.2331],
        [11.2927],
        [21.6706],
        [33.4299],
        [ 9.9564],
        [12.0307],
        [12.3137],
        [15.5380],
        [48.2194],
        [13.3346],
        [11.9112],
        [31.3183],
        [12.5384],
        [55.3626],
        [ 9.6055],
        [24.9201],
        [ 9.5225],
        [27.5541],
        [10.4188],
        [22.5003],
        [49.3738],
        [ 9.8213],
        [35.9809],
        [49.4735],
        [ 9.8211],
        [11.9428],
        [20.8205],
        [ 9.6011],
        [20.0808],
        [11.2535],
        [21.7075],
        [33.3683],
        [ 9.8010],
        [31.3519],
        [11.5699],
        [10.3176],
        [29.0917],
        [12.4573],
        [10.7489],
        [47.8042],
        [25.7549],
        [18.2623],
        [ 9.7239],
        [10.0925],
        [29.8068],
        [ 9.4409],
        [51.6453],
        [13.2608],
        [28.4551],
        [10.0385],
        [31.8056],
        [54.5332],
        [12.9670],
        [25.8181],
        [13.7484],
        [ 9.8170],
        [53.6528],
        [19.1189],
        [16.0949],
        [13.1980],
        [13.4383],
        [14.8081],
        [11.4724],
        [19.6497],
        [10.7404],
        [21.3319],
        [16.3104],
        [14.2890],
        [12.1503],
        [15.5584],
        [45.7923],
        [20.4935],
        [ 9.8443],
        [39.4452],
        [17.7242],
        [ 9.2752],
        [49.6952],
        [11.5346],
        [34.7044],
        [10.4136],
        [32.2473],
        [10.0136],
        [23.3979],
        [23.2602],
        [14.0490],
        [64.9858],
        [18.2993],
        [14.3852],
        [11.3752],
        [11.2313],
        [33.7530],
        [23.4348],
        [10.8811],
        [21.4837],
        [ 9.0816],
        [10.9874],
        [29.0533],
        [15.0692],
        [23.5379],
        [10.5602],
        [14.3599],
        [33.4194],
        [11.1892],
        [ 9.1601],
        [22.7709],
        [27.5627],
        [41.4593],
        [33.7499],
        [10.5952],
        [36.5324],
        [ 9.6373],
        [46.5071],
        [14.0485],
        [20.6124],
        [16.1909],
        [15.6551],
        [20.2806],
        [12.3000],
        [60.7149],
        [15.8459],
        [16.8367],
        [48.7171],
        [ 9.1683],
        [10.9507],
        [16.7125],
        [ 9.6391],
        [20.1118],
        [14.9508],
        [10.3344],
        [11.6231],
        [39.3562],
        [32.4427],
        [11.1403],
        [27.1206],
        [11.7827],
        [10.1094],
        [39.5122],
        [ 9.6931],
        [33.3083],
        [25.7627],
        [ 9.3777],
        [38.4209],
        [30.5386],
        [16.9836],
        [19.4438],
        [60.4955],
        [11.5461],
        [12.7369],
        [40.8226],
        [15.4525],
        [23.7479],
        [14.6320],
        [10.9584],
        [16.8771],
        [11.1280],
        [16.3643],
        [16.9273],
        [ 9.2948],
        [42.5403],
        [11.2635],
        [13.6364],
        [41.3797],
        [11.9883],
        [10.4263],
        [20.2186],
        [17.7575],
        [17.7378],
        [44.1829],
        [ 9.3093],
        [36.7021],
        [10.5436],
        [10.3941],
        [16.8279],
        [16.8331],
        [43.6049],
        [12.7388],
        [27.5020],
        [19.6892],
        [58.9763],
        [37.8051],
        [11.6265],
        [22.8766],
        [10.7861],
        [10.6755],
        [22.2972],
        [ 9.0651],
        [25.2114],
        [12.3448],
        [17.2531],
        [39.3883],
        [10.0136],
        [23.4878],
        [10.4351],
        [10.9247],
        [11.6428],
        [10.7208],
        [31.6920],
        [11.0343],
        [31.9247],
        [32.9273],
        [ 9.9764],
        [43.4817],
        [ 9.6007],
        [28.0501],
        [49.3375],
        [10.6965],
        [17.3852],
        [11.9049],
        [53.0019],
        [12.1436],
        [27.3774],
        [25.0780],
        [14.9689],
        [37.8541],
        [10.8229],
        [12.0422],
        [13.9481],
        [10.9092],
        [14.5048],
        [61.5311],
        [10.7004],
        [15.7021],
        [19.1309],
        [10.9441],
        [35.0226],
        [13.3670],
        [11.8399],
        [28.7305],
        [12.5317],
        [22.2530],
        [11.7017],
        [11.8869],
        [29.7969],
        [10.4655],
        [57.8465],
        [44.7465],
        [17.2862],
        [14.7854],
        [12.0386],
        [56.1151],
        [19.7301],
        [30.3057],
        [10.6371],
        [ 9.7179],
        [25.8366],
        [10.0947],
        [25.9026],
        [16.3783],
        [10.5654],
        [21.8219],
        [11.4683],
        [ 9.6745],
        [47.0039],
        [18.4178],
        [12.0129],
        [ 9.5887],
        [39.3667],
        [ 9.8458],
        [37.6775],
        [20.3432],
        [ 9.7753],
        [42.5956],
        [21.8011],
        [13.5058],
        [11.0631],
        [11.0889],
        [29.6444],
        [34.7070],
        [10.8024],
        [26.9661],
        [12.5226],
        [13.7905],
        [10.6482],
        [16.9917],
        [10.8087],
        [16.2669],
        [18.0521],
        [ 9.4234],
        [52.2277],
        [23.2700],
        [13.8023],
        [60.9390],
        [15.2219],
        [11.7583],
        [42.3719],
        [12.2883],
        [21.8876],
        [52.1416],
        [ 9.9773],
        [33.7950],
        [14.1004],
        [10.9581],
        [17.4709],
        [13.2583],
        [38.0825],
        [10.7412],
        [15.4420],
        [42.7338],
        [13.0590],
        [11.0728],
        [23.8142],
        [14.6901],
        [23.8557],
        [11.0170],
        [20.0392],
        [ 9.5564],
        [19.6860],
        [13.2062],
        [15.4527],
        [38.6329],
        [10.1806],
        [12.0476],
        [25.9880],
        [25.4752],
        [63.7985],
        [28.8785],
        [10.6312],
        [22.0854],
        [ 9.2281],
        [29.3907],
        [10.1848],
        [46.0917],
        [ 9.7254],
        [33.5865],
        [45.4138],
        [ 9.1713],
        [21.1538],
        [34.2622],
        [10.3162],
        [10.9606],
        [12.9951],
        [10.7699],
        [30.1986],
        [11.9191],
        [27.0011],
        [12.1799],
        [15.3514],
        [11.6000],
        [17.9228],
        [48.0969],
        [ 9.4754],
        [13.3638],
        [19.4139],
        [10.5746],
        [53.0614],
        [15.6688],
        [21.1555],
        [27.5420],
        [16.0768],
        [35.3804],
        [10.7636],
        [10.5189],
        [32.1682],
        [ 9.2232],
        [50.6888],
        [50.3780],
        [18.8052],
        [13.5950],
        [12.3499],
        [10.4932],
        [36.1230],
        [11.9433],
        [13.8647],
        [19.4334],
        [15.6617],
        [16.2042],
        [10.7012],
        [22.4644],
        [ 9.1243],
        [26.9013],
        [11.1064],
        [10.1279],
        [44.7510],
        [20.3086],
        [10.9929],
        [50.9904],
        [17.7511],
        [33.4415],
        [10.4635],
        [11.0712],
        [26.2716],
        [10.3492],
        [32.2041],
        [22.5274],
        [46.2239],
        [10.7100],
        [17.5404],
        [30.7912],
        [10.6155],
        [54.3342],
        [ 9.7788],
        [13.8121],
        [25.5921],
        [11.4483],
        [17.9452],
        [38.6429],
        [12.2680],
        [14.0171],
        [12.5832],
        [40.7715],
        [10.3181],
        [10.9472],
        [17.6300],
        [ 9.7240],
        [18.1982],
        [11.4642],
        [26.3591],
        [27.0651],
        [11.0925],
        [29.6022],
        [ 9.7716],
        [14.7814],
        [56.6709],
        [12.0462],
        [26.8144],
        [47.8113],
        [33.9076],
        [19.6005],
        [ 9.7779],
        [10.5590],
        [31.4799],
        [10.2604],
        [36.4469],
        [27.8166],
        [12.5191],
        [26.0487],
        [11.3387],
        [10.1622],
        [27.3842],
        [12.3103],
        [11.0022],
        [ 9.8319],
        [57.2547],
        [19.9021],
        [13.7437],
        [16.7560],
        [10.6111],
        [18.4887],
        [11.1276],
        [19.7415],
        [23.2033],
        [12.6880],
        [42.0903],
        [52.1624],
        [10.3211],
        [23.5911],
        [13.5131],
        [14.9771],
        [11.3779],
        [41.8853],
        [13.5228],
        [ 9.0727],
        [48.4721],
        [13.2975],
        [36.0601],
        [26.2520],
        [10.9457],
        [20.6339],
        [15.6295],
        [14.1050],
        [10.5550],
        [11.1350],
        [38.5313],
        [17.5228],
        [14.0899],
        [ 9.4426],
        [43.1565],
        [18.2051],
        [10.9607],
        [22.8975],
        [ 9.3589],
        [11.2987],
        [33.1943],
        [ 9.4799],
        [22.1315],
        [29.4920],
        [11.3524],
        [58.0733],
        [25.6251],
        [ 9.0824],
        [23.0404],
        [22.5083],
        [40.6038],
        [44.3069],
        [ 9.4337],
        [33.7691],
        [ 9.9217],
        [10.7188],
        [36.7580],
        [10.3555],
        [29.4495],
        [11.3362],
        [14.0944],
        [33.9284],
        [11.3645],
        [20.1976],
        [15.7830],
        [47.1073],
        [ 9.2071],
        [10.6957],
        [12.6610],
        [12.3369],
        [14.7666],
        [37.3957],
        [11.3015],
        [24.8004],
        [12.4184],
        [16.9273],
        [20.3880],
        [14.5975],
        [62.4562]], device='cuda:0', dtype=torch.float64), tensor([[10.5741],
        [30.5929],
        [43.9707],
        [23.8525],
        [ 9.6513],
        [13.2272],
        [44.6373],
        [14.3482],
        [15.1745],
        [80.9953],
        [26.0857],
        [16.7154],
        [14.5709],
        [42.3980],
        [48.9202],
        [ 9.9731],
        [49.5319],
        [ 9.7065],
        [ 9.4604],
        [43.6479],
        [77.2906],
        [11.5935],
        [24.3458],
        [20.3850],
        [15.4015],
        [10.2463],
        [12.8136],
        [46.8354],
        [19.3144],
        [11.4720],
        [15.8564],
        [24.3806],
        [60.6897],
        [ 9.2809],
        [17.5037],
        [31.1030],
        [67.1592],
        [11.1962],
        [11.2358],
        [27.3022],
        [24.7610],
        [10.8553],
        [10.0549],
        [13.5149],
        [11.7974],
        [10.2770],
        [18.2048],
        [67.7640],
        [ 9.8607],
        [11.4795],
        [68.7613],
        [20.4879],
        [10.4805],
        [41.6721],
        [27.8491],
        [15.9526],
        [11.4393],
        [58.3435],
        [33.5259],
        [13.2066],
        [10.4871],
        [64.2640],
        [36.9530],
        [13.7545],
        [10.8630],
        [57.8222],
        [39.5828],
        [19.0104],
        [10.5828],
        [80.0691],
        [26.3141],
        [10.0120],
        [12.2884],
        [22.5455],
        [17.5379],
        [ 9.5492],
        [10.8152],
        [14.9678],
        [61.7448],
        [24.9083],
        [12.6906],
        [11.4515],
        [23.3401],
        [53.1811],
        [30.7522],
        [10.8195],
        [12.1523],
        [32.4745],
        [59.7275],
        [13.0784],
        [12.9933],
        [26.4936],
        [53.3375],
        [10.9146],
        [16.3644],
        [38.9952],
        [23.4413],
        [10.2140],
        [18.3060],
        [48.5694],
        [14.1819],
        [ 9.5381],
        [15.3188],
        [34.0381],
        [65.2786],
        [16.7232],
        [21.7693],
        [28.5575],
        [45.5798],
        [18.7170],
        [ 9.6179],
        [38.4464],
        [10.0691],
        [62.1634],
        [40.0832],
        [10.1836],
        [15.9684],
        [72.2293],
        [28.2651],
        [27.1329],
        [10.1099],
        [19.5959],
        [44.1101],
        [16.3402],
        [10.9617],
        [18.0634],
        [30.9863],
        [14.9146],
        [13.0580],
        [ 9.6307],
        [13.7408],
        [43.8198],
        [27.7074],
        [11.2906],
        [21.2234],
        [40.8855],
        [36.0285],
        [17.9129],
        [11.4497],
        [43.2862],
        [78.5057],
        [14.0983],
        [18.5265],
        [24.3088],
        [13.8672],
        [84.9873],
        [24.7056],
        [19.4263],
        [ 9.6412],
        [51.8459],
        [44.8232],
        [ 9.5446],
        [11.2845],
        [19.5287],
        [24.2633],
        [16.1814],
        [10.6537],
        [16.7771],
        [51.1128],
        [14.6565],
        [12.2038],
        [73.4953],
        [32.1236],
        [10.2927],
        [ 9.3465],
        [62.4924],
        [31.5129],
        [17.6702],
        [10.2623],
        [12.4539],
        [70.9771],
        [18.6720],
        [11.3647],
        [30.1808],
        [16.4091],
        [11.6332],
        [38.9524],
        [10.4908],
        [14.9941],
        [25.6450],
        [10.6982],
        [10.2577],
        [18.1218],
        [60.1601],
        [57.7677],
        [ 9.9045],
        [14.3411],
        [33.6376],
        [57.1439],
        [11.3871],
        [13.5586],
        [32.0980],
        [76.7646],
        [10.1617],
        [10.0962],
        [25.3515],
        [51.9716],
        [ 9.6417],
        [23.3597],
        [33.8063],
        [13.9314],
        [11.7252],
        [21.4359],
        [57.1552],
        [21.9354],
        [11.9798],
        [ 9.4784],
        [17.6474],
        [12.0522],
        [34.2136],
        [35.2718],
        [13.2260],
        [11.1579],
        [12.7277],
        [53.8684],
        [24.4138],
        [11.5404],
        [54.8383],
        [41.0779],
        [15.0615],
        [11.3795],
        [68.5472],
        [30.6497],
        [10.8497],
        [ 9.4786],
        [17.2980],
        [40.5860],
        [17.4747],
        [10.0604],
        [24.9170],
        [51.6909],
        [19.2868],
        [18.8667],
        [46.2234],
        [39.5631],
        [ 9.6459],
        [18.7333],
        [73.2231],
        [32.0086],
        [20.1119],
        [69.5546],
        [15.5429],
        [27.4487],
        [27.4199],
        [57.0428],
        [10.2499],
        [ 9.8890],
        [34.9432],
        [14.9638],
        [11.0082],
        [12.5033],
        [25.1170],
        [17.8118],
        [ 9.9240],
        [15.7049],
        [41.3648],
        [14.6668],
        [25.5757],
        [71.7505],
        [15.7440],
        [ 9.4851],
        [45.4323],
        [43.9699],
        [12.8115],
        [20.5442],
        [34.3155],
        [25.8520],
        [11.3124],
        [12.7944],
        [35.7887],
        [11.0516],
        [ 9.1314],
        [55.5586],
        [12.9112],
        [11.6210],
        [19.9006],
        [32.9801],
        [20.4294],
        [11.0903],
        [25.0632],
        [48.3913],
        [ 9.1184],
        [10.5524],
        [50.0965],
        [20.1692],
        [28.2313],
        [11.3456],
        [82.0298],
        [19.3224],
        [11.9551],
        [11.4218],
        [31.0209],
        [75.6405],
        [19.0569],
        [10.5850],
        [14.9233],
        [29.0167],
        [20.0296],
        [ 9.2574],
        [65.7153],
        [33.4816],
        [10.9515],
        [11.1810],
        [66.7793],
        [13.2085],
        [31.9809],
        [57.2779],
        [10.6078],
        [11.4288],
        [36.0554],
        [59.7872],
        [10.7897],
        [19.4908],
        [56.0697],
        [10.8388],
        [10.2918],
        [12.9631],
        [22.0705],
        [33.3206],
        [10.8476],
        [10.0812],
        [19.5557],
        [24.2513],
        [11.6744],
        [20.4660],
        [64.4478],
        [15.8033],
        [11.2821],
        [28.3052],
        [33.3903],
        [51.6707],
        [ 9.6495],
        [10.0840],
        [24.7367],
        [73.6346],
        [ 9.8927],
        [28.4231],
        [10.0911],
        [10.6896],
        [72.2354],
        [46.6094],
        [12.6171],
        [13.7401],
        [53.6651],
        [52.9458],
        [24.6800],
        [10.7962],
        [11.6525],
        [28.5753],
        [12.1409],
        [11.9861],
        [31.0304],
        [32.9196],
        [15.5986],
        [20.3843],
        [67.7567],
        [42.1483],
        [ 9.0616],
        [13.1088],
        [54.4170],
        [44.8543],
        [18.0403],
        [10.6128],
        [22.4750],
        [32.1839],
        [16.5854],
        [ 9.3987],
        [13.0429],
        [14.1103],
        [44.2181],
        [21.7490],
        [10.5823],
        [15.3297],
        [35.0704],
        [18.7410],
        [10.9078],
        [ 9.1859],
        [38.7670],
        [54.4612],
        [12.3699],
        [38.2144],
        [21.9849],
        [67.7147],
        [12.2500],
        [47.0272],
        [ 9.4381],
        [12.9361],
        [44.8332],
        [29.0307],
        [13.5720],
        [17.5919],
        [80.7481],
        [42.5856],
        [14.5613],
        [ 9.2986],
        [12.0436],
        [36.8326],
        [21.8550],
        [11.0613],
        [27.4587],
        [17.0388],
        [27.1385],
        [20.9231],
        [11.7511],
        [12.5515],
        [52.6399],
        [18.1834],
        [11.1197],
        [28.4147],
        [19.5490],
        [79.2663],
        [11.1276],
        [ 9.3763],
        [42.7970],
        [45.8506],
        [10.6877],
        [16.1825],
        [70.0056],
        [13.6980],
        [10.8932],
        [11.7390],
        [19.2031],
        [30.0829],
        [11.2120],
        [11.5562],
        [32.2395],
        [63.6271],
        [10.6980],
        [24.7156],
        [24.2685],
        [59.0707],
        [ 9.4967],
        [37.7241],
        [10.7459],
        [11.3497],
        [61.0037],
        [36.3154],
        [11.1370],
        [10.7281],
        [65.3451],
        [23.9939],
        [14.2198],
        [11.4893],
        [36.9210],
        [56.7587],
        [20.1737],
        [10.1294],
        [10.8861],
        [67.1826],
        [20.9695],
        [11.1202],
        [16.9470],
        [24.1753],
        [11.4966],
        [12.7072],
        [29.3838],
        [28.9632],
        [ 9.4925],
        [10.1730],
        [80.0527],
        [33.8249],
        [28.6876],
        [ 9.7490],
        [53.1823],
        [13.2344],
        [42.3413],
        [47.3124],
        [12.5695],
        [10.3067],
        [26.9052],
        [70.5474],
        [10.5940],
        [11.4365],
        [26.3465],
        [28.7430],
        [11.7235],
        [21.5138],
        [45.4709],
        [10.9353],
        [12.3914],
        [ 9.2371],
        [37.5691],
        [47.3204],
        [15.9742],
        [17.2528],
        [31.0715],
        [65.9497],
        [18.9387],
        [15.9518],
        [31.5728],
        [12.9327],
        [ 9.5353],
        [16.3081],
        [41.8755],
        [20.3373],
        [10.6035],
        [35.1676],
        [15.6250],
        [10.9292],
        [19.0671],
        [48.7518],
        [16.5910],
        [10.7314],
        [23.9573],
        [26.7195],
        [30.8686],
        [14.8029],
        [75.2526],
        [39.9549],
        [ 9.3640],
        [11.5521],
        [57.0292]], device='cuda:0', dtype=torch.float64)]
AFTER NORMALIZATION:
[tensor([[ 230.9215],
        [ 451.7155],
        [ 249.1231],
        [1056.3599],
        [ 511.4682],
        [ 410.1327],
        [ 260.3860],
        [ 448.8336],
        [ 282.0436],
        [1032.1638],
        [ 302.4124],
        [ 706.0317],
        [ 272.9797],
        [ 249.1669],
        [ 283.1710],
        [ 719.4868],
        [ 278.6032],
        [ 736.4237],
        [ 455.6033],
        [ 572.4258],
        [ 247.2767],
        [ 460.4685],
        [ 265.6662],
        [ 917.2511],
        [ 275.0987],
        [ 488.4219],
        [ 231.4752],
        [ 827.4825],
        [ 382.3530],
        [ 375.5421],
        [ 230.0190],
        [ 408.1493],
        [ 221.4924],
        [ 655.2859],
        [ 394.0256],
        [ 731.3039],
        [ 298.5688],
        [ 241.9404],
        [ 414.8254],
        [ 814.1474],
        [ 219.4148],
        [ 646.5330],
        [ 214.6449],
        [1199.2011],
        [ 375.7435],
        [ 310.6962],
        [ 218.4865],
        [ 412.8247],
        [ 212.1967],
        [ 389.1206],
        [ 306.5446],
        [ 994.1828],
        [ 306.9953],
        [ 656.4111],
        [ 215.8008],
        [ 638.7790],
        [ 387.4901],
        [ 795.6700],
        [ 236.1382],
        [ 552.1540],
        [ 254.0459],
        [ 256.8876],
        [ 237.2702],
        [ 682.9030],
        [ 270.8745],
        [ 567.9640],
        [ 306.3334],
        [ 526.0750],
        [ 266.5778],
        [ 337.2511],
        [ 327.0316],
        [ 908.9444],
        [ 226.9875],
        [ 498.8569],
        [ 223.4195],
        [ 899.7105],
        [ 328.4388],
        [ 326.7288],
        [ 223.6351],
        [ 557.2567],
        [ 223.3058],
        [ 591.9876],
        [ 340.1214],
        [1126.7173],
        [ 436.6464],
        [ 568.0902],
        [ 223.0788],
        [ 450.3797],
        [ 359.2390],
        [1009.9316],
        [ 348.0327],
        [ 655.9090],
        [ 311.0347],
        [ 241.7761],
        [ 280.3693],
        [ 533.7831],
        [ 207.5063],
        [ 288.3157],
        [ 245.2612],
        [ 910.5599],
        [ 365.5347],
        [ 479.7151],
        [ 233.0849],
        [ 622.2701],
        [ 300.3819],
        [ 820.9063],
        [ 221.3917],
        [ 613.6626],
        [ 239.4826],
        [ 253.5810],
        [ 240.8389],
        [ 885.1504],
        [ 224.8693],
        [ 868.2320],
        [ 586.9081],
        [ 791.8380],
        [ 257.2006],
        [ 289.2422],
        [ 314.8527],
        [ 839.3818],
        [ 231.4047],
        [ 629.4003],
        [ 224.1912],
        [1108.3310],
        [ 455.9181],
        [ 328.2476],
        [ 214.1603],
        [ 309.7799],
        [ 211.1179],
        [ 864.7638],
        [ 400.1868],
        [ 765.2025],
        [ 288.3268],
        [ 291.2762],
        [ 365.9750],
        [ 848.3151],
        [ 224.0880],
        [ 558.8191],
        [ 219.9281],
        [1001.9489],
        [ 473.0200],
        [ 267.2571],
        [ 214.1385],
        [ 363.1008],
        [ 213.7326],
        [ 377.1849],
        [ 275.7778],
        [ 808.2229],
        [ 385.3924],
        [ 664.9555],
        [ 219.7107],
        [ 482.3140],
        [ 388.7447],
        [ 911.5871],
        [ 295.5302],
        [ 578.5096],
        [ 252.1546],
        [ 279.4671],
        [ 212.3339],
        [ 802.6121],
        [ 239.0071],
        [ 455.3993],
        [ 279.6788],
        [1262.8373],
        [ 413.1873],
        [ 410.8975],
        [ 241.4746],
        [ 572.3416],
        [ 279.7061],
        [ 904.4646],
        [ 241.4876],
        [ 690.9449],
        [ 269.4778],
        [ 250.8885],
        [ 364.6757],
        [ 602.6089],
        [ 313.8040],
        [ 566.1776],
        [ 437.9994],
        [ 549.1802],
        [ 246.1379],
        [ 331.9247],
        [ 285.6368],
        [ 901.7882],
        [ 235.6143],
        [ 562.0365],
        [ 227.5525],
        [ 990.0326],
        [ 318.6399],
        [ 449.6771],
        [ 225.0480],
        [ 472.4464],
        [ 213.7132],
        [ 373.4161],
        [ 246.6811],
        [ 946.4092],
        [ 350.4591],
        [ 624.0709],
        [ 231.5393],
        [ 634.8164],
        [ 391.2705],
        [ 742.3408],
        [ 224.2020],
        [ 486.5958],
        [ 257.9021],
        [ 248.8412],
        [ 242.1598],
        [ 817.9176],
        [ 246.4024],
        [ 865.5489],
        [ 473.5721],
        [ 643.1718],
        [ 304.9039],
        [ 302.9168],
        [ 373.5852],
        [ 667.8301],
        [ 235.1143],
        [ 706.2302],
        [ 262.1189],
        [1156.5587],
        [ 433.6477],
        [ 354.7551],
        [ 210.8163],
        [ 351.4458],
        [ 244.6207],
        [ 551.3778],
        [ 385.7950],
        [ 643.6037],
        [ 248.7417],
        [ 323.9012],
        [ 288.3688],
        [1096.7524],
        [ 227.7216],
        [ 441.6742],
        [ 265.2079],
        [ 863.6535],
        [ 336.6394],
        [ 321.9977],
        [ 209.3039],
        [ 483.5139],
        [ 212.0811],
        [ 465.2310],
        [ 311.2306],
        [1107.4785],
        [ 440.5261],
        [ 426.6276],
        [ 234.7220],
        [ 455.1088],
        [ 283.2556],
        [1109.1480],
        [ 330.4069],
        [ 804.6458],
        [ 267.0991],
        [ 248.9422],
        [ 273.1994],
        [ 586.3881],
        [ 243.1768],
        [ 685.3642],
        [ 342.1029],
        [ 578.6313],
        [ 252.7324],
        [ 355.4049],
        [ 295.2477],
        [1063.4483],
        [ 252.4896],
        [ 419.2830],
        [ 241.2359],
        [ 816.1584],
        [ 381.0656],
        [ 338.6439],
        [ 210.2195],
        [ 468.2131],
        [ 209.4368],
        [ 522.5597],
        [ 323.4420],
        [ 993.4672],
        [ 472.7309],
        [ 501.6341],
        [ 247.1975],
        [ 396.3396],
        [ 293.8946],
        [1093.5514],
        [ 370.0517],
        [ 759.7045],
        [ 287.2273],
        [ 247.6802],
        [ 232.7593],
        [ 596.3081],
        [ 210.3912],
        [ 354.0273],
        [ 249.5636],
        [ 995.0453],
        [ 321.0035],
        [ 490.5777],
        [ 222.2041],
        [ 749.0625],
        [ 349.8306],
        [ 714.8591],
        [ 213.5179],
        [ 558.3522],
        [ 245.2693],
        [ 251.6555],
        [ 273.8976],
        [ 769.3400],
        [ 262.3649],
        [ 762.1418],
        [ 574.1310],
        [ 689.5258],
        [ 273.5383],
        [ 264.0817],
        [ 387.6948],
        [ 740.2812],
        [ 225.8025],
        [ 681.9867],
        [ 225.3643],
        [1246.2262],
        [ 409.6752],
        [ 353.3839],
        [ 208.1155],
        [ 338.6565],
        [ 233.6380],
        [ 508.6717],
        [ 287.5850],
        [1142.0408],
        [ 431.4978],
        [ 485.1302],
        [ 253.2293],
        [ 507.6109],
        [ 290.5032],
        [ 890.4111],
        [ 264.2952],
        [ 648.9720],
        [ 302.5284],
        [ 266.0188],
        [ 293.2565],
        [ 609.0518],
        [ 308.0574],
        [ 699.6034],
        [ 387.5981],
        [ 479.4882],
        [ 254.7628],
        [ 367.0724],
        [ 291.7619],
        [ 874.4722],
        [ 257.5133],
        [ 544.6276],
        [ 231.3808],
        [ 955.9680],
        [ 355.9940],
        [ 477.0542],
        [ 242.7148],
        [ 455.6089],
        [ 215.1513],
        [ 744.9536],
        [ 477.5516],
        [ 790.6145],
        [ 267.1833],
        [ 257.5920],
        [ 384.5414],
        [ 918.5362],
        [ 213.8431],
        [ 552.9127],
        [ 225.1060],
        [1115.4550],
        [ 437.7921],
        [ 268.9976],
        [ 218.3395],
        [ 353.2640],
        [ 216.7974],
        [ 361.9969],
        [ 279.8110],
        [ 864.4032],
        [ 337.3271],
        [ 536.5404],
        [ 212.6580],
        [ 595.8605],
        [ 353.6540],
        [ 869.4089],
        [ 254.9544],
        [ 649.4726],
        [ 248.2852],
        [ 306.2673],
        [ 224.8589],
        [ 739.2178],
        [ 208.6338],
        [ 359.9909],
        [ 234.7716],
        [ 834.9881],
        [ 385.9499],
        [ 535.4398],
        [ 236.6095],
        [ 605.4338],
        [ 347.8165],
        [ 782.7859],
        [ 250.8664],
        [ 572.4687],
        [ 245.8936],
        [ 258.6980],
        [ 224.6800],
        [ 854.8137],
        [ 229.0887],
        [ 950.7227],
        [ 612.4682],
        [ 695.7585],
        [ 274.0948],
        [ 329.7954],
        [ 336.0406],
        [ 737.9261],
        [ 236.1343],
        [ 622.4377],
        [ 229.9319],
        [1058.9896],
        [ 502.5369],
        [ 310.1692],
        [ 210.2459],
        [ 316.1504],
        [ 277.4885],
        [ 544.1239],
        [ 311.8996],
        [ 560.6552],
        [ 251.7654],
        [ 279.2914],
        [ 331.5863],
        [1057.6481],
        [ 217.4737],
        [ 476.3936],
        [ 241.2640],
        [1003.9966],
        [ 305.6550],
        [ 382.1920],
        [ 213.1707],
        [ 515.8844],
        [ 219.4728],
        [ 507.2136],
        [ 405.9821],
        [1187.4446],
        [ 384.1820],
        [ 479.0030],
        [ 224.9591],
        [ 500.0943],
        [ 300.0733],
        [ 979.4465],
        [ 270.9479],
        [ 725.8740],
        [ 295.6834],
        [ 239.4581],
        [ 291.5624],
        [ 517.2599],
        [ 225.1514],
        [ 733.4340],
        [ 415.1431],
        [ 652.6596],
        [ 307.1870],
        [ 259.2258],
        [ 428.5850],
        [ 735.6864],
        [ 220.8350],
        [ 631.0227],
        [ 216.7612],
        [1129.9170],
        [ 432.9373],
        [ 287.3730],
        [ 207.3649],
        [ 415.3922],
        [ 208.1530],
        [ 482.0887],
        [ 276.9002],
        [ 883.5158],
        [ 328.9202],
        [ 720.5836],
        [ 217.7536],
        [ 612.0532],
        [ 437.7525],
        [ 778.1976],
        [ 276.7538],
        [ 535.4316],
        [ 267.6013],
        [ 268.0603],
        [ 222.2382],
        [ 664.6146],
        [ 218.1515],
        [ 385.3468],
        [ 282.5902],
        [1097.8939],
        [ 451.7059],
        [ 349.2029],
        [ 266.1290],
        [ 498.1664],
        [ 238.1893],
        [1011.7184],
        [ 242.5229],
        [ 794.1659],
        [ 260.9961],
        [ 247.6930],
        [ 296.4770],
        [ 697.8018],
        [ 288.0480],
        [ 704.2819],
        [ 462.0384],
        [ 611.1413],
        [ 235.3341],
        [ 367.7490],
        [ 264.9074],
        [1078.9409],
        [ 254.7779],
        [ 467.2409],
        [ 240.5933],
        [ 925.7394],
        [ 364.1905],
        [ 433.9994],
        [ 211.2265],
        [ 375.4625]], device='cuda:0', dtype=torch.float64), tensor([[ 786.0336],
        [1286.2122],
        [ 629.9547],
        [1200.3352],
        [1846.6318],
        [ 556.5151],
        [ 670.5195],
        [ 686.0749],
        [ 863.2797],
        [2659.4780],
        [ 742.1825],
        [ 663.9486],
        [1730.5789],
        [ 698.4226],
        [3052.0704],
        [ 537.2282],
        [1378.9269],
        [ 532.6657],
        [1523.6958],
        [ 581.9248],
        [1245.9344],
        [2722.9246],
        [ 549.0892],
        [1986.8390],
        [2728.4037],
        [ 549.0772],
        [ 665.6855],
        [1153.6109],
        [ 536.9843],
        [1112.9557],
        [ 627.8049],
        [1202.3614],
        [1843.2484],
        [ 547.9736],
        [1732.4256],
        [ 645.1952],
        [ 576.3649],
        [1608.2062],
        [ 693.9636],
        [ 600.0687],
        [2636.6564],
        [1424.8106],
        [1013.0121],
        [ 543.7343],
        [ 563.9929],
        [1647.5081],
        [ 528.1831],
        [2847.7640],
        [ 738.1237],
        [1573.2173],
        [ 561.0245],
        [1757.3621],
        [3006.4886],
        [ 721.9791],
        [1428.2858],
        [ 764.9233],
        [ 548.8524],
        [2958.0984],
        [1060.0888],
        [ 893.8874],
        [ 734.6736],
        [ 747.8821],
        [ 823.1668],
        [ 639.8332],
        [1089.2650],
        [ 599.6053],
        [1181.7208],
        [ 905.7355],
        [ 794.6377],
        [ 677.0942],
        [ 864.4041],
        [2526.0811],
        [1135.6392],
        [ 550.3511],
        [2177.2393],
        [ 983.4398],
        [ 519.0768],
        [2740.5877],
        [ 643.2529],
        [1916.6809],
        [ 581.6395],
        [1781.6386],
        [ 559.6553],
        [1295.2705],
        [1287.7005],
        [ 781.4434],
        [3580.9691],
        [1015.0477],
        [ 799.9249],
        [ 634.4895],
        [ 626.5855],
        [1864.3941],
        [1297.2953],
        [ 607.3376],
        [1190.0611],
        [ 508.4362],
        [ 613.1792],
        [1606.0908],
        [ 837.5192],
        [1302.9646],
        [ 589.6975],
        [ 798.5329],
        [1846.0593],
        [ 624.2671],
        [ 512.7487],
        [1260.8085],
        [1524.1683],
        [2287.9371],
        [1864.2208],
        [ 591.6229],
        [2017.1496],
        [ 538.9758],
        [2565.3659],
        [ 781.4157],
        [1142.1742],
        [ 899.1645],
        [ 869.7175],
        [1123.9416],
        [ 685.3202],
        [3346.2383],
        [ 880.2026],
        [ 934.6587],
        [2686.8310],
        [ 513.1962],
        [ 611.1597],
        [ 927.8326],
        [ 539.0755],
        [1114.6633],
        [ 831.0117],
        [ 577.2903],
        [ 648.1175],
        [2172.3487],
        [1792.3750],
        [ 621.5788],
        [1499.8698],
        [ 656.8859],
        [ 564.9236],
        [2180.9214],
        [ 542.0414],
        [1839.9509],
        [1425.2404],
        [ 524.7087],
        [2120.9421],
        [1687.7285],
        [ 942.7314],
        [1077.9476],
        [3334.1787],
        [ 643.8830],
        [ 709.3307],
        [2252.9441],
        [ 858.5840],
        [1314.5021],
        [ 813.4851],
        [ 611.5852],
        [ 936.8798],
        [ 620.9029],
        [ 908.6958],
        [ 939.6384],
        [ 520.1486],
        [2347.3509],
        [ 628.3522],
        [ 758.7669],
        [2283.5623],
        [ 668.1865],
        [ 582.3414],
        [1120.5341],
        [ 985.2656],
        [ 984.1837],
        [2437.6254],
        [ 520.9465],
        [2026.4785],
        [ 588.7838],
        [ 580.5702],
        [ 934.1767],
        [ 934.4598],
        [2405.8596],
        [ 709.4369],
        [1520.8351],
        [1091.4357],
        [3250.6835],
        [2087.0973],
        [ 648.3011],
        [1266.6151],
        [ 602.1133],
        [ 596.0355],
        [1234.7747],
        [ 507.5293],
        [1394.9391],
        [ 687.7837],
        [ 957.5473],
        [2174.1111],
        [ 559.6582],
        [1300.2068],
        [ 582.8226],
        [ 609.7300],
        [ 649.2005],
        [ 598.5269],
        [1751.1178],
        [ 615.7547],
        [1763.9063],
        [1819.0114],
        [ 557.6124],
        [2399.0870],
        [ 536.9646],
        [1550.9564],
        [2720.9256],
        [ 597.1887],
        [ 964.8038],
        [ 663.6023],
        [2922.3248],
        [ 676.7226],
        [1513.9856],
        [1387.6085],
        [ 832.0035],
        [2089.7937],
        [ 604.1362],
        [ 671.1506],
        [ 775.8986],
        [ 608.8782],
        [ 806.4957],
        [3391.0988],
        [ 597.4065],
        [ 872.3007],
        [1060.7484],
        [ 610.7971],
        [1934.1705],
        [ 743.9629],
        [ 660.0336],
        [1588.3513],
        [ 698.0533],
        [1232.3444],
        [ 652.4380],
        [ 662.6131],
        [1646.9634],
        [ 584.4934],
        [3188.5898],
        [2468.6046],
        [ 959.3640],
        [ 821.9189],
        [ 670.9528],
        [3093.4298],
        [1093.6825],
        [1674.9259],
        [ 593.9231],
        [ 543.4032],
        [1429.2994],
        [ 564.1167],
        [1432.9304],
        [ 909.4638],
        [ 589.9852],
        [1208.6507],
        [ 639.6064],
        [ 541.0197],
        [2592.6702],
        [1021.5578],
        [ 669.5383],
        [ 536.3054],
        [2172.9251],
        [ 550.4336],
        [2080.0841],
        [1127.3781],
        [ 546.5620],
        [2350.3894],
        [1207.5092],
        [ 751.5900],
        [ 617.3377],
        [ 618.7542],
        [1638.5830],
        [1916.8223],
        [ 603.0080],
        [1491.3809],
        [ 697.5562],
        [ 767.2408],
        [ 594.5356],
        [ 943.1762],
        [ 603.3564],
        [ 903.3424],
        [1001.4603],
        [ 527.2183],
        [2879.7750],
        [1288.2399],
        [ 767.8849],
        [3358.5572],
        [ 845.9072],
        [ 655.5448],
        [2338.0925],
        [ 684.6765],
        [1212.2584],
        [2875.0433],
        [ 557.6611],
        [1866.7005],
        [ 784.2721],
        [ 611.5660],
        [ 969.5132],
        [ 737.9856],
        [2102.3472],
        [ 599.6468],
        [ 858.0043],
        [2357.9807],
        [ 727.0370],
        [ 617.8692],
        [1318.1470],
        [ 816.6790],
        [1320.4295],
        [ 614.8048],
        [1110.6737],
        [ 534.5291],
        [1091.2585],
        [ 735.1251],
        [ 858.5933],
        [2132.5964],
        [ 568.8380],
        [ 671.4451],
        [1437.6242],
        [1409.4360],
        [3515.7170],
        [1596.4862],
        [ 593.5991],
        [1223.1314],
        [ 516.4841],
        [1624.6391],
        [ 569.0684],
        [2542.5362],
        [ 543.8173],
        [1855.2403],
        [2505.2757],
        [ 513.3637],
        [1171.9300],
        [1892.3770],
        [ 576.2882],
        [ 611.7061],
        [ 723.5249],
        [ 601.2239],
        [1669.0372],
        [ 664.3837],
        [1493.3002],
        [ 678.7205],
        [ 853.0281],
        [ 646.8442],
        [ 994.3523],
        [2652.7434],
        [ 530.0746],
        [ 743.7862],
        [1076.3065],
        [ 590.4911],
        [2925.5954],
        [ 870.4722],
        [1172.0217],
        [1523.0285],
        [ 892.8923],
        [1953.8374],
        [ 600.8762],
        [ 587.4263],
        [1777.2901],
        [ 516.2160],
        [2795.1982],
        [2778.1142],
        [1042.8492],
        [ 756.4914],
        [ 688.0633],
        [ 586.0163],
        [1994.6463],
        [ 665.7165],
        [ 771.3159],
        [1077.3762],
        [ 870.0831],
        [ 899.8953],
        [ 597.4493],
        [1243.9616],
        [ 510.7829],
        [1487.8181],
        [ 619.7189],
        [ 565.9371],
        [2468.8499],
        [1125.4796],
        [ 613.4775],
        [2811.7734],
        [ 984.9144],
        [1847.2704],
        [ 584.3839],
        [ 617.7824],
        [1453.2063],
        [ 578.1040],
        [1779.2640],
        [1247.4261],
        [2549.8011],
        [ 597.9339],
        [ 973.3367],
        [1701.6100],
        [ 592.7390],
        [2995.5515],
        [ 546.7532],
        [ 768.4257],
        [1415.8636],
        [ 638.5089],
        [ 995.5850],
        [2133.1445],
        [ 683.5595],
        [ 779.6932],
        [ 700.8860],
        [2250.1347],
        [ 576.3937],
        [ 610.9708],
        [ 978.2594],
        [ 543.7379],
        [1009.4905],
        [ 639.3843],
        [1458.0168],
        [1496.8203],
        [ 618.9525],
        [1636.2620],
        [ 546.3581],
        [ 821.7006],
        [3123.9790],
        [ 671.3689],
        [1483.0401],
        [2637.0442],
        [1872.8884],
        [1086.5617],
        [ 546.7033],
        [ 589.6312],
        [1739.4605],
        [ 573.2189],
        [2012.4522],
        [1538.1245],
        [ 697.3625],
        [1440.9570],
        [ 632.4866],
        [ 567.8269],
        [1514.3606],
        [ 685.8848],
        [ 613.9898],
        [ 549.6706],
        [3156.0648],
        [1103.1341],
        [ 764.6641],
        [ 930.2227],
        [ 592.4961],
        [1025.4564],
        [ 620.8810],
        [1094.3070],
        [1284.5724],
        [ 706.6437],
        [2322.6156],
        [2876.1839],
        [ 576.5568],
        [1305.8880],
        [ 751.9928],
        [ 832.4548],
        [ 634.6386],
        [2311.3483],
        [ 752.5249],
        [ 507.9425],
        [2673.3667],
        [ 740.1409],
        [1991.1895],
        [1452.1332],
        [ 610.8849],
        [1143.3563],
        [ 868.3103],
        [ 784.5225],
        [ 589.4130],
        [ 621.2883],
        [2127.0122],
        [ 972.3688],
        [ 783.6935],
        [ 528.2728],
        [2381.2137],
        [1009.8674],
        [ 611.7096],
        [1267.7642],
        [ 523.6740],
        [ 630.2887],
        [1833.6869],
        [ 530.3268],
        [1225.6646],
        [1630.2047],
        [ 633.2378],
        [3201.0521],
        [1417.6794],
        [ 508.4760],
        [1275.6195],
        [1246.3732],
        [2240.9151],
        [2444.4404],
        [ 527.7861],
        [1865.2760],
        [ 554.6048],
        [ 598.4146],
        [2029.5473],
        [ 578.4476],
        [1627.8691],
        [ 632.3508],
        [ 783.9407],
        [1874.0320],
        [ 633.9033],
        [1119.3754],
        [ 876.7480],
        [2598.3523],
        [ 515.3287],
        [ 597.1479],
        [ 705.1579],
        [ 687.3471],
        [ 820.8879],
        [2064.5951],
        [ 630.4436],
        [1372.3521],
        [ 691.8257],
        [ 939.6402],
        [1129.8398],
        [ 811.5929],
        [3441.9420]], device='cuda:0', dtype=torch.float64), tensor([[ 696.2180],
        [1994.7820],
        [2862.5616],
        [1557.5485],
        [ 636.3605],
        [ 868.3196],
        [2905.8036],
        [ 941.0335],
        [ 994.6313],
        [5264.2472],
        [1702.4137],
        [1094.5871],
        [ 955.4785],
        [2760.5469],
        [3183.6237],
        [ 657.2298],
        [3223.3047],
        [ 639.9364],
        [ 623.9731],
        [2841.6237],
        [5023.9351],
        [ 762.3439],
        [1589.5473],
        [1332.6263],
        [1009.3585],
        [ 674.9571],
        [ 841.4867],
        [3048.3915],
        [1263.1769],
        [ 754.4617],
        [1038.8665],
        [1591.8072],
        [3947.0767],
        [ 612.3334],
        [1145.7238],
        [2027.8720],
        [4366.7350],
        [ 736.5719],
        [ 739.1376],
        [1781.3267],
        [1616.4813],
        [ 714.4562],
        [ 662.5374],
        [ 886.9811],
        [ 775.5707],
        [ 676.9476],
        [1191.1993],
        [4405.9668],
        [ 649.9407],
        [ 754.9469],
        [4470.6625],
        [1339.2988],
        [ 690.1456],
        [2713.4576],
        [1816.8003],
        [1045.1038],
        [ 752.3402],
        [3794.8856],
        [2185.0388],
        [ 866.9822],
        [ 690.5726],
        [4178.9346],
        [2407.3459],
        [ 902.5194],
        [ 714.9577],
        [3761.0701],
        [2577.9342],
        [1243.4562],
        [ 696.7852],
        [5204.1665],
        [1717.2314],
        [ 659.7591],
        [ 807.4182],
        [1472.7686],
        [1147.9396],
        [ 629.7369],
        [ 711.8571],
        [ 981.2276],
        [4015.5204],
        [1626.0369],
        [ 833.5092],
        [ 753.1344],
        [1524.3130],
        [3460.0156],
        [2005.1171],
        [ 712.1377],
        [ 798.5919],
        [2116.8364],
        [3884.6628],
        [ 858.6628],
        [ 853.1415],
        [1728.8700],
        [3470.1639],
        [ 718.3045],
        [1071.8210],
        [2539.8146],
        [1530.8777],
        [ 672.8599],
        [1197.7618],
        [3160.8665],
        [ 930.2490],
        [ 629.0140],
        [1003.9908],
        [2218.2632],
        [4244.7476],
        [1095.0962],
        [1422.4212],
        [1862.7544],
        [2966.9443],
        [1224.4258],
        [ 634.1920],
        [2504.2177],
        [ 663.4580],
        [4042.6766],
        [2610.3915],
        [ 670.8878],
        [1046.1339],
        [4695.6218],
        [1843.7851],
        [1770.3392],
        [ 666.1042],
        [1281.4381],
        [2871.6051],
        [1070.2467],
        [ 721.3602],
        [1182.0311],
        [2020.3008],
        [ 977.7749],
        [ 857.3429],
        [ 635.0251],
        [ 901.6355],
        [2852.7727],
        [1807.6085],
        [ 742.6944],
        [1387.0073],
        [2662.4333],
        [2347.3732],
        [1172.2681],
        [ 753.0174],
        [2818.1640],
        [5102.7552],
        [ 924.8211],
        [1212.0696],
        [1587.1472],
        [ 909.8331],
        [5523.1983],
        [1612.8924],
        [1270.4349],
        [ 635.7007],
        [3373.4092],
        [2917.8624],
        [ 629.4347],
        [ 742.3022],
        [1277.0779],
        [1584.2011],
        [1059.9482],
        [ 701.3823],
        [1098.5908],
        [3325.8516],
        [ 961.0300],
        [ 801.9305],
        [4777.7417],
        [2094.0749],
        [ 677.9629],
        [ 616.5863],
        [4064.0140],
        [2054.4627],
        [1156.5239],
        [ 675.9954],
        [ 818.1536],
        [4614.3946],
        [1221.5069],
        [ 747.5011],
        [1968.0477],
        [1074.7155],
        [ 764.9176],
        [2537.0405],
        [ 690.8143],
        [ 982.9291],
        [1673.8247],
        [ 704.2659],
        [ 675.6907],
        [1185.8155],
        [3912.7287],
        [3757.5388],
        [ 652.7826],
        [ 940.5712],
        [2192.2827],
        [3717.0745],
        [ 748.9551],
        [ 889.8127],
        [2092.4129],
        [4989.8142],
        [ 669.4694],
        [ 665.2173],
        [1654.7865],
        [3381.5620],
        [ 635.7328],
        [1525.5875],
        [2203.2246],
        [ 913.9988],
        [ 770.8855],
        [1400.7943],
        [3717.8036],
        [1433.1974],
        [ 787.4034],
        [ 625.1421],
        [1155.0448],
        [ 792.0997],
        [2229.6479],
        [2298.2880],
        [ 868.2401],
        [ 734.0893],
        [ 835.9134],
        [3504.5984],
        [1593.9613],
        [ 758.8971],
        [3567.5176],
        [2674.9161],
        [ 987.3028],
        [ 748.4588],
        [4456.7763],
        [1998.4642],
        [ 714.0932],
        [ 625.1584],
        [1132.3793],
        [2643.0094],
        [1143.8432],
        [ 662.8966],
        [1626.6056],
        [3363.3525],
        [1261.3888],
        [1234.1372],
        [3008.6912],
        [2576.6549],
        [ 636.0078],
        [1225.4847],
        [4760.0877],
        [2086.6140],
        [1314.9080],
        [4522.1191],
        [1018.5279],
        [1790.8285],
        [1788.9611],
        [3710.5122],
        [ 675.1887],
        [ 651.7773],
        [2276.9714],
        [ 980.9652],
        [ 724.3764],
        [ 821.3593],
        [1639.5786],
        [1165.7072],
        [ 654.0505],
        [1029.0364],
        [2693.5265],
        [ 961.7001],
        [1669.3281],
        [4664.5630],
        [1031.5783],
        [ 625.5766],
        [2957.3764],
        [2862.5133],
        [ 841.3501],
        [1342.9534],
        [2236.2599],
        [1687.2561],
        [ 744.1082],
        [ 840.2433],
        [2331.8192],
        [ 727.1903],
        [ 602.6325],
        [3614.2361],
        [ 847.8172],
        [ 764.1292],
        [1301.2029],
        [2149.6353],
        [1335.5053],
        [ 729.7053],
        [1636.0843],
        [3149.3167],
        [ 601.7883],
        [ 694.8128],
        [3259.9250],
        [1318.6236],
        [1841.5896],
        [ 746.2612],
        [5331.3528],
        [1263.6970],
        [ 785.7995],
        [ 751.2071],
        [2022.5457],
        [4916.8984],
        [1246.4740],
        [ 696.9236],
        [ 978.3393],
        [1892.5380],
        [1309.5727],
        [ 610.8083],
        [4273.0732],
        [2182.1652],
        [ 720.6967],
        [ 735.5854],
        [4342.0941],
        [ 867.1030],
        [2084.8157],
        [3725.7659],
        [ 698.4059],
        [ 751.6625],
        [2349.1172],
        [3888.5357],
        [ 710.2063],
        [1274.6200],
        [3647.3956],
        [ 713.3883],
        [ 677.9065],
        [ 851.1835],
        [1441.9560],
        [2171.7239],
        [ 713.9561],
        [ 664.2472],
        [1278.8266],
        [1583.4226],
        [ 767.5916],
        [1337.8769],
        [4190.8566],
        [1035.4215],
        [ 742.1426],
        [1846.3826],
        [2176.2450],
        [3362.0423],
        [ 636.2408],
        [ 664.4270],
        [1614.9097],
        [4786.7767],
        [ 652.0148],
        [1854.0341],
        [ 664.8875],
        [ 703.7114],
        [4696.0180],
        [3033.7261],
        [ 828.7441],
        [ 901.5907],
        [3491.4147],
        [3444.7516],
        [1611.2310],
        [ 710.6234],
        [ 766.1684],
        [1863.9046],
        [ 797.8504],
        [ 787.8100],
        [2023.1628],
        [2145.7114],
        [1022.1454],
        [1332.5778],
        [4405.4950],
        [2744.3487],
        [ 598.1086],
        [ 860.6369],
        [3540.1892],
        [2919.8772],
        [1180.5278],
        [ 698.7296],
        [1468.1957],
        [2097.9889],
        [1086.1555],
        [ 619.9703],
        [ 856.3599],
        [ 925.6032],
        [2878.6094],
        [1421.1016],
        [ 696.7466],
        [1004.7010],
        [2285.2258],
        [1225.9834],
        [ 717.8662],
        [ 606.1676],
        [2525.0169],
        [3543.0516],
        [ 812.7058],
        [2489.1676],
        [1436.4047],
        [4402.7685],
        [ 804.9301],
        [3060.8287],
        [ 622.5277],
        [ 849.4344],
        [2918.5096],
        [1893.4456],
        [ 890.6857],
        [1151.4465],
        [5248.2132],
        [2772.7151],
        [ 954.8573],
        [ 613.4770],
        [ 791.5412],
        [2399.5326],
        [1427.9764],
        [ 727.8198],
        [1791.4732],
        [1115.5675],
        [1770.7053],
        [1367.5276],
        [ 772.5669],
        [ 824.4894],
        [3424.9090],
        [1189.8153],
        [ 731.6080],
        [1853.4885],
        [1278.3918],
        [5152.0932],
        [ 732.1218],
        [ 618.5180],
        [2786.4270],
        [2984.5104],
        [ 703.5846],
        [1060.0165],
        [4551.3785],
        [ 898.8544],
        [ 716.9181],
        [ 771.7823],
        [1255.9553],
        [1961.7015],
        [ 737.5962],
        [ 759.9215],
        [2101.5908],
        [4137.6186],
        [ 704.2532],
        [1613.5354],
        [1584.5370],
        [3842.0569],
        [ 626.3322],
        [2457.3670],
        [ 707.3636],
        [ 746.5269],
        [3967.4450],
        [2365.9846],
        [ 732.7292],
        [ 706.2087],
        [4249.0606],
        [1566.7209],
        [ 932.7033],
        [ 755.5857],
        [2405.2686],
        [3692.0850],
        [1318.9164],
        [ 667.3739],
        [ 716.4568],
        [4368.2527],
        [1370.5391],
        [ 731.6442],
        [1109.6134],
        [1578.4890],
        [ 756.0553],
        [ 834.5880],
        [1916.3483],
        [1889.0669],
        [ 626.0580],
        [ 670.1993],
        [5203.1043],
        [2204.4334],
        [1871.1909],
        [ 642.6965],
        [3460.0968],
        [ 868.7848],
        [2756.8689],
        [3079.3288],
        [ 825.6517],
        [ 678.8728],
        [1755.5710],
        [4586.5198],
        [ 697.5100],
        [ 752.1566],
        [1719.3285],
        [1874.7853],
        [ 770.7757],
        [1405.8452],
        [2959.8771],
        [ 719.6507],
        [ 814.0986],
        [ 609.4913],
        [2447.3083],
        [3079.8465],
        [1046.5104],
        [1129.4461],
        [2025.8255],
        [4288.2792],
        [1238.8080],
        [1045.0577],
        [2058.3442],
        [ 849.2112],
        [ 628.8332],
        [1068.1650],
        [2726.6540],
        [1329.5326],
        [ 698.1237],
        [2291.5284],
        [1023.8588],
        [ 719.2519],
        [1247.1386],
        [3172.7010],
        [1086.5175],
        [ 706.4234],
        [1564.3482],
        [1743.5267],
        [2012.6644],
        [ 970.5299],
        [4891.7338],
        [2602.0719],
        [ 617.7233],
        [ 759.6550],
        [3709.6309]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION:
[tensor([[13.4022],
        [51.7719],
        [11.1263],
        [16.2205],
        [11.1864],
        [ 9.0888],
        [ 9.5458],
        [11.7591],
        [17.5841],
        [ 9.2736]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.7699],
        [ 9.7254],
        [20.3432],
        [16.9273],
        [13.1980],
        [17.5228],
        [ 9.0824],
        [14.2890],
        [31.3519],
        [13.2608]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0840],
        [11.6744],
        [ 9.4851],
        [39.9549],
        [10.4871],
        [13.2344],
        [ 9.2371],
        [10.5828],
        [17.5037],
        [ 9.8607]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[ 302.5284],
        [1142.0408],
        [ 252.7324],
        [ 364.1905],
        [ 254.0459],
        [ 208.1530],
        [ 218.1515],
        [ 266.5778],
        [ 394.0256],
        [ 212.1967]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 601.2239],
        [ 543.8173],
        [1127.3781],
        [ 939.6402],
        [ 734.6736],
        [ 972.3688],
        [ 508.4760],
        [ 794.6377],
        [1732.4256],
        [ 738.1237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 664.4270],
        [ 767.5916],
        [ 625.5766],
        [2602.0719],
        [ 690.5726],
        [ 868.7848],
        [ 609.4913],
        [ 696.7852],
        [1145.7238],
        [ 649.9407]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[13.4011],
        [51.7701],
        [11.1263],
        [16.2205],
        [11.1863],
        [ 9.0889],
        [ 9.5442],
        [11.7592],
        [17.5833],
        [ 9.2737]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.7693],
        [ 9.7253],
        [20.3387],
        [16.9260],
        [13.1933],
        [17.5171],
        [ 9.0826],
        [14.2863],
        [31.3494],
        [13.2544]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0833],
        [11.6741],
        [ 9.4844],
        [39.9515],
        [10.4841],
        [13.2260],
        [ 9.2366],
        [10.5810],
        [17.5021],
        [ 9.8611]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[ 302.5037],
        [1142.0029],
        [ 252.7328],
        [ 364.1906],
        [ 254.0454],
        [ 208.1550],
        [ 218.1172],
        [ 266.5788],
        [ 394.0096],
        [ 212.1983]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 601.1889],
        [ 543.8132],
        [1127.1350],
        [ 939.5654],
        [ 734.4165],
        [ 972.0557],
        [ 508.4886],
        [ 794.4854],
        [1732.2893],
        [ 737.7754]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 664.3798],
        [ 767.5704],
        [ 625.5310],
        [2601.8487],
        [ 690.3768],
        [ 868.2375],
        [ 609.4577],
        [ 696.6639],
        [1145.6201],
        [ 649.9657]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[13.4000],
        [51.7684],
        [11.1264],
        [16.2205],
        [11.1863],
        [ 9.0890],
        [ 9.5427],
        [11.7592],
        [17.5826],
        [ 9.2738]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.7686],
        [ 9.7252],
        [20.3343],
        [16.9246],
        [13.1886],
        [17.5114],
        [ 9.0828],
        [14.2835],
        [31.3469],
        [13.2481]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0826],
        [11.6738],
        [ 9.4837],
        [39.9481],
        [10.4810],
        [13.2175],
        [ 9.2361],
        [10.5791],
        [17.5005],
        [ 9.8615]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[ 302.4789],
        [1141.9650],
        [ 252.7332],
        [ 364.1908],
        [ 254.0448],
        [ 208.1570],
        [ 218.0831],
        [ 266.5797],
        [ 393.9937],
        [ 212.1998]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 601.1540],
        [ 543.8090],
        [1126.8918],
        [ 939.4907],
        [ 734.1594],
        [ 971.7426],
        [ 508.5011],
        [ 794.3331],
        [1732.1530],
        [ 737.4274]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 664.3327],
        [ 767.5492],
        [ 625.4855],
        [2601.6255],
        [ 690.1811],
        [ 867.6908],
        [ 609.4241],
        [ 696.5428],
        [1145.5164],
        [ 649.9907]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[13.3954],
        [51.7615],
        [11.1264],
        [16.2205],
        [11.1862],
        [ 9.0894],
        [ 9.5365],
        [11.7594],
        [17.5797],
        [ 9.2741]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.7661],
        [ 9.7249],
        [20.3166],
        [16.9192],
        [13.1700],
        [17.4886],
        [ 9.0837],
        [14.2724],
        [31.3370],
        [13.2228]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0797],
        [11.6724],
        [ 9.4809],
        [39.9343],
        [10.4690],
        [13.1839],
        [ 9.2340],
        [10.5717],
        [17.4941],
        [ 9.8630]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[ 302.3799],
        [1141.8134],
        [ 252.7350],
        [ 364.1914],
        [ 254.0424],
        [ 208.1650],
        [ 217.9471],
        [ 266.5835],
        [ 393.9298],
        [ 212.2060]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 601.0144],
        [ 543.7926],
        [1125.9196],
        [ 939.1919],
        [ 733.1327],
        [ 970.4913],
        [ 508.5517],
        [ 793.7245],
        [1731.6077],
        [ 736.0386]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 664.1444],
        [ 767.4645],
        [ 625.3038],
        [2600.7327],
        [ 689.4006],
        [ 865.5102],
        [ 609.2906],
        [ 696.0595],
        [1145.1016],
        [ 650.0907]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[13.3773],
        [51.7337],
        [11.1267],
        [16.2206],
        [11.1858],
        [ 9.0909],
        [ 9.5121],
        [11.7600],
        [17.5680],
        [ 9.2752]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.7560],
        [ 9.7237],
        [20.2460],
        [16.8974],
        [13.0957],
        [17.3979],
        [ 9.0875],
        [14.2283],
        [31.2973],
        [13.1226]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0681],
        [11.6672],
        [ 9.4698],
        [39.8793],
        [10.4214],
        [13.0509],
        [ 9.2259],
        [10.5421],
        [17.4686],
        [ 9.8692]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[ 301.9835],
        [1141.2071],
        [ 252.7415],
        [ 364.1938],
        [ 254.0328],
        [ 208.1976],
        [ 217.4147],
        [ 266.5971],
        [ 393.6746],
        [ 212.2311]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 600.4582],
        [ 543.7267],
        [1122.0389],
        [ 937.9977],
        [ 729.0496],
        [ 965.5052],
        [ 508.7590],
        [ 791.2996],
        [1729.4277],
        [ 730.5317]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 663.3947],
        [ 767.1264],
        [ 624.5848],
        [2597.1628],
        [ 686.3102],
        [ 856.8837],
        [ 608.7649],
        [ 694.1450],
        [1143.4444],
        [ 650.4925]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[13.3046],
        [51.6229],
        [11.1276],
        [16.2211],
        [11.1837],
        [ 9.0970],
        [ 9.4231],
        [11.7615],
        [17.5215],
        [ 9.2799]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.7161],
        [ 9.7190],
        [19.9660],
        [16.8108],
        [12.8054],
        [17.0406],
        [ 9.1041],
        [14.0545],
        [31.1390],
        [12.7358]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0228],
        [11.6466],
        [ 9.4274],
        [39.6594],
        [10.2386],
        [12.5426],
        [ 9.1956],
        [10.4287],
        [17.3669],
        [ 9.8944]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[ 300.3930],
        [1138.7826],
        [ 252.7613],
        [ 364.2036],
        [ 253.9885],
        [ 208.3324],
        [ 215.4658],
        [ 266.6304],
        [ 392.6556],
        [ 212.3325]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 598.2684],
        [ 543.4636],
        [1106.6465],
        [ 933.2365],
        [ 713.0944],
        [ 945.8654],
        [ 509.6705],
        [ 781.7482],
        [1720.7237],
        [ 709.2701]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 660.4547],
        [ 765.7864],
        [ 621.8320],
        [2582.9033],
        [ 674.4569],
        [ 823.9088],
        [ 606.7998],
        [ 686.7887],
        [1136.8450],
        [ 652.1259]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[13.0107],
        [51.1801],
        [11.1265],
        [16.2229],
        [11.1716],
        [ 9.1251],
        [ 9.1937],
        [11.7522],
        [17.3367],
        [ 9.2994]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.5671],
        [ 9.7000],
        [18.8837],
        [16.4689],
        [11.7540],
        [15.7008],
        [ 9.1930],
        [13.4026],
        [30.5102],
        [11.4045]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8560],
        [11.5670],
        [ 9.2874],
        [38.7851],
        [ 9.6347],
        [10.8760],
        [ 9.1074],
        [10.0498],
        [16.9671],
        [10.0006]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[ 293.9619],
        [1129.0939],
        [ 252.7367],
        [ 364.2427],
        [ 253.7222],
        [ 208.9468],
        [ 210.4467],
        [ 266.4263],
        [ 388.6133],
        [ 212.7599]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 590.0796],
        [ 542.4199],
        [1047.1666],
        [ 914.4447],
        [ 655.3116],
        [ 872.2314],
        [ 514.5546],
        [ 745.9179],
        [1686.1674],
        [ 636.0997]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 649.6362],
        [ 760.6228],
        [ 612.7528],
        [2526.1904],
        [ 635.2794],
        [ 715.8044],
        [ 601.0792],
        [ 662.2091],
        [1110.9158],
        [ 659.0153]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[11.8174],
        [49.4162],
        [11.0489],
        [16.2300],
        [11.0590],
        [ 9.2870],
        [ 9.9403],
        [11.4770],
        [16.6218],
        [ 9.3930]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.1528],
        [ 9.6265],
        [15.1702],
        [15.1753],
        [ 9.3098],
        [11.8375],
        [ 9.8151],
        [11.4895],
        [28.0729],
        [ 9.1306]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.4206],
        [11.2970],
        [ 9.1693],
        [35.3716],
        [ 9.3501],
        [ 9.3563],
        [ 9.2169],
        [ 9.7508],
        [15.4820],
        [10.4549]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[ 267.8537],
        [1090.5004],
        [ 251.0385],
        [ 364.3988],
        [ 251.2587],
        [ 212.4889],
        [ 226.7826],
        [ 260.4042],
        [ 372.9711],
        [ 214.8087]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 567.3054],
        [ 538.3839],
        [ 843.0693],
        [ 843.3491],
        [ 520.9755],
        [ 659.8982],
        [ 548.7459],
        [ 640.7747],
        [1552.2097],
        [ 511.1250]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 621.3919],
        [ 743.1113],
        [ 605.0903],
        [2304.7649],
        [ 616.8223],
        [ 617.2216],
        [ 608.1826],
        [ 642.8103],
        [1014.5782],
        [ 688.4884]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5714],
        [45.0971],
        [10.4824],
        [16.1017],
        [10.2305],
        [ 9.8793],
        [11.7981],
        [ 9.8058],
        [15.0705],
        [ 9.7229]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.6976],
        [ 9.4820],
        [10.3568],
        [12.6046],
        [10.1118],
        [11.0053],
        [10.7843],
        [10.9059],
        [22.8372],
        [10.9016]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.1628],
        [10.9846],
        [ 9.6338],
        [27.2010],
        [11.3776],
        [10.1941],
        [ 9.1064],
        [10.1902],
        [12.7978],
        [10.9560]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[218.7114],
        [995.9992],
        [238.6442],
        [361.5911],
        [233.1319],
        [225.4487],
        [267.4313],
        [223.8405],
        [339.0298],
        [222.0268]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 597.2479],
        [ 530.4388],
        [ 578.5208],
        [ 702.0620],
        [ 565.0544],
        [ 614.1639],
        [ 602.0164],
        [ 608.6971],
        [1264.4515],
        [ 608.4630]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 604.6704],
        [ 722.8446],
        [ 635.2252],
        [1774.7564],
        [ 748.3361],
        [ 671.5669],
        [ 601.0124],
        [ 671.3131],
        [ 840.4661],
        [ 720.9907]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.4041],
        [42.1056],
        [10.0646],
        [15.6155],
        [ 9.8602],
        [ 9.8842],
        [11.0267],
        [ 9.4954],
        [14.1308],
        [ 9.5254]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.1540],
        [ 9.4173],
        [10.7832],
        [11.2813],
        [ 9.7057],
        [10.0063],
        [10.6543],
        [11.0562],
        [19.8379],
        [10.9068]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.1008],
        [10.9578],
        [ 9.0874],
        [20.7582],
        [ 9.6202],
        [ 9.3113],
        [ 9.1360],
        [ 9.0455],
        [11.6991],
        [10.7855]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[215.0504],
        [930.5463],
        [229.5016],
        [350.9541],
        [225.0310],
        [225.5544],
        [250.5526],
        [217.0492],
        [318.4701],
        [217.7041]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 622.3320],
        [ 526.8836],
        [ 601.9523],
        [ 629.3300],
        [ 542.7326],
        [ 559.2539],
        [ 594.8687],
        [ 616.9597],
        [1099.6064],
        [ 608.7463]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 600.6507],
        [ 721.1081],
        [ 599.7807],
        [1356.8298],
        [ 634.3391],
        [ 614.3039],
        [ 602.9347],
        [ 597.0621],
        [ 769.1955],
        [ 709.9334]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.1378],
        [31.3582],
        [ 9.0465],
        [13.0514],
        [ 9.1171],
        [ 9.6610],
        [ 9.5316],
        [ 9.0437],
        [11.2356],
        [ 9.0707]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0639],
        [ 9.2140],
        [10.4377],
        [ 9.2387],
        [10.8850],
        [11.0519],
        [10.3793],
        [10.3021],
        [12.0018],
        [11.2594]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.1747],
        [11.3378],
        [12.2755],
        [ 9.8370],
        [11.2951],
        [10.9676],
        [10.0162],
        [10.1727],
        [ 9.4813],
        [ 9.8553]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[209.2249],
        [695.3982],
        [207.2278],
        [294.8515],
        [208.7716],
        [220.6707],
        [217.8396],
        [207.1653],
        [255.1234],
        [207.7566]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[507.4603],
        [515.7121],
        [582.9659],
        [517.0657],
        [607.5484],
        [616.7205],
        [579.7589],
        [575.5132],
        [668.9301],
        [628.1296]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[670.3092],
        [745.7565],
        [806.5859],
        [648.4018],
        [742.9867],
        [721.7404],
        [660.0280],
        [670.1792],
        [625.3281],
        [649.5889]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.2378],
        [36.4219],
        [ 9.3270],
        [14.2805],
        [ 9.2845],
        [ 9.7677],
        [10.1148],
        [ 9.1555],
        [12.5051],
        [ 9.1703]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.1690],
        [ 9.3066],
        [10.8913],
        [ 9.5585],
        [10.0888],
        [ 9.9291],
        [10.5179],
        [10.9831],
        [15.0362],
        [11.2062]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.4505],
        [11.0563],
        [ 9.7975],
        [10.9377],
        [ 9.1874],
        [ 9.3795],
        [ 9.4612],
        [ 9.3796],
        [10.2174],
        [10.3518]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[211.4115],
        [806.1905],
        [213.3635],
        [321.7437],
        [212.4343],
        [223.0059],
        [230.6016],
        [209.6111],
        [282.9004],
        [209.9351]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[568.1964],
        [520.8024],
        [607.8956],
        [534.6424],
        [563.7876],
        [555.0129],
        [587.3755],
        [612.9416],
        [835.7050],
        [625.2060]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[623.3318],
        [727.4956],
        [645.8398],
        [719.8031],
        [606.2674],
        [618.7301],
        [624.0301],
        [618.7310],
        [673.0785],
        [681.7974]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.2548],
        [29.4114],
        [ 9.0933],
        [11.4305],
        [ 9.1579],
        [ 9.4491],
        [ 9.3248],
        [ 9.0645],
        [10.8401],
        [ 9.0683]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0510],
        [ 9.2024],
        [ 9.7886],
        [ 9.3417],
        [11.2188],
        [11.7752],
        [10.3581],
        [10.0225],
        [11.4975],
        [10.8733]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.3606],
        [11.3102],
        [ 9.7020],
        [13.0246],
        [ 9.4397],
        [10.6451],
        [ 9.6942],
        [ 9.7674],
        [ 9.4250],
        [ 9.3202]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[211.7849],
        [652.8020],
        [208.2516],
        [259.3872],
        [209.6634],
        [216.0366],
        [213.3169],
        [207.6196],
        [246.4690],
        [207.7031]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[506.7501],
        [515.0749],
        [547.2919],
        [522.7276],
        [625.8947],
        [656.4756],
        [578.5902],
        [560.1446],
        [641.2119],
        [606.9058]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[617.5039],
        [743.9664],
        [639.6487],
        [855.1741],
        [622.6309],
        [700.8224],
        [639.1394],
        [643.8910],
        [621.6773],
        [614.8830]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5646],
        [28.7335],
        [ 9.4419],
        [11.4525],
        [ 9.4594],
        [ 9.4694],
        [ 9.2614],
        [ 9.2151],
        [10.8280],
        [ 9.1650]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9579],
        [ 9.2297],
        [10.4157],
        [ 9.3773],
        [11.0478],
        [10.9376],
        [10.1490],
        [10.3027],
        [11.8593],
        [10.3656]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0764],
        [11.1090],
        [ 9.0764],
        [ 9.1624],
        [ 9.0469],
        [ 9.3679],
        [ 9.1129],
        [ 9.1569],
        [ 9.5708],
        [ 9.3779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[218.5615],
        [637.9706],
        [215.8775],
        [259.8697],
        [216.2617],
        [216.4802],
        [211.9278],
        [210.9146],
        [246.2063],
        [209.8196]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[556.5980],
        [516.5761],
        [581.7555],
        [524.6873],
        [616.4975],
        [610.4395],
        [567.0980],
        [575.5440],
        [661.0963],
        [579.0059]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[599.0674],
        [730.9186],
        [599.0680],
        [604.6461],
        [597.1495],
        [617.9756],
        [601.4352],
        [604.2865],
        [631.1393],
        [618.6208]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.3437],
        [22.8887],
        [ 9.4809],
        [10.6386],
        [ 9.6065],
        [ 9.7334],
        [ 9.5510],
        [ 9.1276],
        [ 9.9954],
        [ 9.3663]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8033],
        [ 9.2006],
        [10.1791],
        [ 9.9200],
        [10.0460],
        [ 9.5427],
        [10.0752],
        [ 9.6244],
        [11.1360],
        [10.4144]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0506],
        [10.9918],
        [ 9.0658],
        [ 9.7572],
        [ 9.6829],
        [ 9.3420],
        [ 9.0499],
        [ 9.4677],
        [ 9.4038],
        [ 9.3701]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[213.7293],
        [510.0891],
        [216.7314],
        [242.0607],
        [219.4788],
        [222.2566],
        [218.2661],
        [209.0007],
        [227.9890],
        [214.2239]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[548.0974],
        [514.9747],
        [568.7541],
        [554.5125],
        [561.4370],
        [533.7777],
        [563.0413],
        [538.2655],
        [621.3452],
        [581.6830]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[597.3930],
        [723.3115],
        [598.3760],
        [643.2272],
        [638.4076],
        [616.2950],
        [597.3464],
        [624.4500],
        [620.3068],
        [618.1181]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5158],
        [19.2512],
        [ 9.5388],
        [ 9.9093],
        [ 9.6478],
        [ 9.5731],
        [ 9.4005],
        [ 9.2790],
        [ 9.5950],
        [ 9.4268]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8714],
        [ 9.1869],
        [10.0275],
        [ 9.9085],
        [10.2301],
        [ 9.6611],
        [ 9.9136],
        [ 9.5910],
        [10.9415],
        [10.1795]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0512],
        [10.8505],
        [ 9.0472],
        [ 9.0985],
        [ 9.1694],
        [ 9.0881],
        [ 9.0416],
        [ 9.1237],
        [ 9.3060],
        [ 9.1527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.4953],
        [430.5010],
        [217.9971],
        [226.1047],
        [220.3838],
        [218.7485],
        [214.9721],
        [212.3133],
        [219.2278],
        [215.5482]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[551.8439],
        [514.2210],
        [560.4219],
        [553.8781],
        [571.5560],
        [540.2840],
        [554.1591],
        [536.4322],
        [610.6559],
        [568.7746]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[597.4339],
        [714.1469],
        [597.1703],
        [600.4989],
        [605.0978],
        [599.8246],
        [596.8078],
        [602.1353],
        [613.9625],
        [604.0141]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6486],
        [12.7870],
        [ 9.5716],
        [ 9.2816],
        [ 9.6471],
        [ 9.3981],
        [ 9.4481],
        [ 9.6351],
        [ 9.1155],
        [ 9.6317]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9875],
        [ 9.1917],
        [ 9.8416],
        [10.1098],
        [10.2317],
        [10.0442],
        [ 9.7725],
        [ 9.7033],
        [10.9919],
        [ 9.9025]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0716],
        [10.2229],
        [ 9.1071],
        [ 9.2984],
        [ 9.0401],
        [ 9.2035],
        [ 9.0904],
        [ 9.0558],
        [ 9.1848],
        [ 9.0476]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[220.4010],
        [289.0665],
        [218.7152],
        [212.3714],
        [220.3673],
        [214.9204],
        [216.0147],
        [220.1054],
        [208.7366],
        [220.0314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[558.2251],
        [514.4827],
        [550.2040],
        [564.9459],
        [571.6459],
        [561.3413],
        [546.4078],
        [542.6043],
        [613.4267],
        [553.5483]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[598.7524],
        [673.4359],
        [601.0571],
        [613.4642],
        [596.7132],
        [607.3090],
        [599.9748],
        [597.7281],
        [606.0999],
        [597.1971]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5836],
        [15.4799],
        [ 9.5557],
        [ 9.5102],
        [ 9.6473],
        [ 9.4775],
        [ 9.4243],
        [ 9.4507],
        [ 9.2827],
        [ 9.5307]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9323],
        [ 9.1894],
        [ 9.9294],
        [10.0139],
        [10.2252],
        [ 9.8400],
        [ 9.8392],
        [ 9.6481],
        [10.9296],
        [10.0347]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0606],
        [10.5324],
        [ 9.0642],
        [ 9.1626],
        [ 9.0670],
        [ 9.0512],
        [ 9.0580],
        [ 9.0811],
        [ 9.2373],
        [ 9.0698]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[218.9780],
        [347.9871],
        [218.3688],
        [217.3719],
        [220.3725],
        [216.6577],
        [215.4920],
        [216.0716],
        [212.3951],
        [217.8207]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[555.1902],
        [514.3574],
        [555.0271],
        [559.6714],
        [571.2864],
        [550.1183],
        [550.0699],
        [539.5702],
        [610.0020],
        [560.8172]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[598.0405],
        [693.5145],
        [598.2717],
        [604.6579],
        [598.4575],
        [597.4297],
        [597.8709],
        [599.3687],
        [609.5040],
        [598.6406]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5302],
        [15.1091],
        [ 9.5121],
        [ 9.5276],
        [ 9.5433],
        [ 9.4767],
        [ 9.5513],
        [ 9.5600],
        [ 9.1130],
        [ 9.5376]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9409],
        [ 9.2116],
        [ 9.8916],
        [ 9.9914],
        [10.0273],
        [10.0393],
        [ 9.9318],
        [ 9.8950],
        [10.8868],
        [10.0607]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0790],
        [10.1023],
        [ 9.0993],
        [ 9.1057],
        [ 9.0479],
        [ 9.1174],
        [ 9.0972],
        [ 9.0492],
        [ 9.2000],
        [ 9.0507]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.8107],
        [339.8737],
        [217.4144],
        [217.7521],
        [218.0963],
        [216.6387],
        [218.2727],
        [218.4615],
        [208.6820],
        [217.9724]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[555.6601],
        [515.5771],
        [552.9501],
        [558.4393],
        [560.4120],
        [561.0721],
        [555.1593],
        [553.1375],
        [607.6512],
        [562.2448]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[599.2350],
        [665.6126],
        [600.5504],
        [600.9665],
        [597.2181],
        [601.7254],
        [600.4136],
        [597.3038],
        [607.0836],
        [597.3979]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5138],
        [13.9534],
        [ 9.5153],
        [ 9.3788],
        [ 9.4666],
        [ 9.5030],
        [ 9.6437],
        [ 9.7089],
        [ 9.1054],
        [ 9.5596]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0415],
        [ 9.2630],
        [ 9.8838],
        [10.0574],
        [ 9.7883],
        [10.2292],
        [ 9.9987],
        [10.1730],
        [10.7956],
        [ 9.9439]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0789],
        [9.4052],
        [9.0867],
        [9.0770],
        [9.0515],
        [9.1093],
        [9.0943],
        [9.0495],
        [9.1229],
        [9.0813]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.4506],
        [314.5886],
        [217.4848],
        [214.4972],
        [216.4187],
        [217.2149],
        [220.2934],
        [221.7197],
        [208.5144],
        [218.4536]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[561.1928],
        [518.4061],
        [552.5212],
        [562.0668],
        [547.2748],
        [571.5049],
        [558.8408],
        [568.4161],
        [602.6351],
        [555.8256]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[599.2291],
        [620.3951],
        [599.7339],
        [599.1069],
        [597.4527],
        [601.1988],
        [600.2276],
        [597.3206],
        [602.0820],
        [599.3868]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.4579],
        [10.5524],
        [ 9.5686],
        [ 9.1005],
        [ 9.2352],
        [ 9.6131],
        [10.1046],
        [10.3333],
        [11.4066],
        [ 9.6583]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.4487],
        [ 9.5225],
        [ 9.9728],
        [10.3279],
        [ 9.1734],
        [11.1438],
        [10.2675],
        [11.0200],
        [10.1523],
        [ 9.5079]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0789],
        [10.6157],
        [ 9.0514],
        [ 9.3181],
        [ 9.0832],
        [ 9.0956],
        [ 9.0837],
        [ 9.0518],
        [ 9.2595],
        [ 9.4445]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[216.2277],
        [240.1758],
        [218.6495],
        [208.4086],
        [211.3558],
        [219.6237],
        [230.3781],
        [235.3817],
        [258.8657],
        [220.6117]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[583.5722],
        [532.6655],
        [557.4174],
        [576.9300],
        [513.4771],
        [621.7755],
        [573.6097],
        [614.9714],
        [567.2798],
        [531.8630]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[599.2277],
        [698.9137],
        [597.4460],
        [614.7443],
        [599.5069],
        [600.3149],
        [599.5421],
        [597.4678],
        [610.9418],
        [622.9436]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5015],
        [13.1185],
        [ 9.5207],
        [ 9.2807],
        [ 9.4111],
        [ 9.5242],
        [ 9.7234],
        [ 9.8323],
        [ 9.3962],
        [ 9.5778]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.1223],
        [ 9.3080],
        [ 9.8860],
        [10.1102],
        [ 9.6159],
        [10.3918],
        [10.0519],
        [10.3868],
        [10.6996],
        [ 9.8522]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0789],
        [9.1484],
        [9.0778],
        [9.0824],
        [9.0556],
        [9.1042],
        [9.0921],
        [9.0498],
        [9.0900],
        [9.1226]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.1813],
        [296.3201],
        [217.6020],
        [212.3509],
        [215.2032],
        [217.6782],
        [222.0375],
        [224.4189],
        [214.8777],
        [218.8507]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[565.6295],
        [520.8762],
        [552.6424],
        [564.9669],
        [537.7974],
        [580.4447],
        [561.7644],
        [580.1658],
        [597.3601],
        [550.7844]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[599.2260],
        [603.7351],
        [599.1579],
        [599.4551],
        [597.7160],
        [600.8696],
        [600.0847],
        [597.3395],
        [599.9508],
        [602.0618]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.4626],
        [ 9.5856],
        [ 9.5465],
        [ 9.1650],
        [ 9.2572],
        [ 9.6307],
        [ 9.9685],
        [10.2086],
        [11.6628],
        [ 9.6928]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.3287],
        [ 9.6790],
        [ 9.7692],
        [10.3228],
        [ 9.2192],
        [10.7289],
        [10.1909],
        [10.8350],
        [10.1711],
        [ 9.4970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0612],
        [11.6940],
        [ 9.0422],
        [ 9.1540],
        [ 9.1215],
        [ 9.0627],
        [ 9.0594],
        [ 9.0687],
        [ 9.2971],
        [ 9.4657]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[216.3300],
        [219.0219],
        [218.1672],
        [209.8201],
        [211.8372],
        [220.0093],
        [227.4004],
        [232.6535],
        [264.4710],
        [221.3680]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[576.9757],
        [541.2666],
        [546.2232],
        [576.6484],
        [515.9944],
        [598.9715],
        [569.3997],
        [604.8039],
        [568.3146],
        [531.2648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[598.0789],
        [768.8631],
        [596.8498],
        [604.0978],
        [601.9944],
        [598.1761],
        [597.9629],
        [598.5648],
        [613.3826],
        [624.3203]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.4936],
        [12.0118],
        [ 9.5239],
        [ 9.2024],
        [ 9.3785],
        [ 9.5437],
        [ 9.7661],
        [ 9.9034],
        [ 9.8203],
        [ 9.5986]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.1604],
        [ 9.3668],
        [ 9.8551],
        [10.1512],
        [ 9.5201],
        [10.4540],
        [10.0782],
        [10.4858],
        [10.6032],
        [ 9.7815]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0751],
        [9.1127],
        [9.0677],
        [9.0914],
        [9.0640],
        [9.0904],
        [9.0846],
        [9.0526],
        [9.0752],
        [9.1571]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.0087],
        [272.1074],
        [217.6729],
        [210.6372],
        [214.4899],
        [218.1046],
        [222.9721],
        [225.9763],
        [224.1568],
        [219.3063]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[567.7234],
        [524.1082],
        [550.9447],
        [567.2185],
        [532.5317],
        [583.8639],
        [563.2072],
        [585.6123],
        [592.0641],
        [546.9015]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[598.9812],
        [601.4181],
        [598.4996],
        [600.0408],
        [598.2638],
        [599.9744],
        [599.5979],
        [597.5215],
        [598.9879],
        [604.3010]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.4986],
        [10.7339],
        [ 9.5259],
        [ 9.1820],
        [ 9.3939],
        [ 9.5721],
        [ 9.6661],
        [ 9.8090],
        [10.4808],
        [ 9.5920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.1418],
        [ 9.5566],
        [ 9.8366],
        [10.1512],
        [ 9.5956],
        [10.2708],
        [10.0691],
        [10.4043],
        [10.3934],
        [ 9.7303]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0615],
        [9.1106],
        [9.0486],
        [9.0594],
        [9.0932],
        [9.0573],
        [9.0572],
        [9.0816],
        [9.0848],
        [9.1826]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.1194],
        [244.1460],
        [217.7155],
        [210.1919],
        [214.8272],
        [218.7265],
        [220.7839],
        [223.9094],
        [238.6091],
        [219.1622]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[566.7048],
        [534.5400],
        [549.9287],
        [567.2181],
        [536.6840],
        [573.7912],
        [562.7094],
        [581.1289],
        [580.5309],
        [544.0863]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[598.0968],
        [601.2828],
        [597.2657],
        [597.9608],
        [600.1528],
        [597.8292],
        [597.8193],
        [599.4063],
        [599.6083],
        [605.9525]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5273],
        [ 9.8196],
        [ 9.5242],
        [ 9.3395],
        [ 9.4546],
        [ 9.6021],
        [ 9.3834],
        [ 9.4636],
        [11.4754],
        [ 9.5363]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.1349],
        [10.6928],
        [10.0229],
        [10.0481],
        [10.0279],
        [ 9.8575],
        [10.0710],
        [10.1695],
        [ 9.1284],
        [ 9.7077]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0618],
        [9.5960],
        [9.0514],
        [9.1328],
        [9.1493],
        [9.0472],
        [9.0405],
        [9.2169],
        [9.6505],
        [9.1136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.7464],
        [224.1429],
        [217.6790],
        [213.6378],
        [216.1564],
        [219.3824],
        [214.5981],
        [216.3524],
        [260.3704],
        [217.9438]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[566.3264],
        [596.9862],
        [560.1673],
        [561.5531],
        [560.4452],
        [551.0751],
        [562.8145],
        [568.2278],
        [511.0050],
        [542.8468]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[598.1162],
        [632.7725],
        [597.4464],
        [602.7256],
        [603.7936],
        [597.1699],
        [596.7398],
        [608.1783],
        [636.3070],
        [601.4771]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5130],
        [ 9.4070],
        [ 9.5114],
        [ 9.4871],
        [ 9.5188],
        [ 9.5460],
        [ 9.4253],
        [ 9.4284],
        [11.7002],
        [ 9.4665]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0335],
        [10.2196],
        [10.0603],
        [10.0445],
        [10.1322],
        [ 9.8479],
        [10.0211],
        [ 9.9689],
        [ 9.3668],
        [ 9.9903]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0555],
        [9.1935],
        [9.0509],
        [9.0844],
        [9.0993],
        [9.0478],
        [9.0567],
        [9.0730],
        [9.1696],
        [9.1208]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.4337],
        [215.1141],
        [217.3981],
        [216.8676],
        [217.5612],
        [218.1562],
        [215.5157],
        [215.5834],
        [265.2883],
        [216.4162]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[560.7488],
        [570.9817],
        [562.2248],
        [561.3561],
        [566.1743],
        [550.5509],
        [560.0683],
        [557.1985],
        [524.1098],
        [558.3758]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[597.7090],
        [606.6625],
        [597.4091],
        [599.5833],
        [600.5491],
        [597.2136],
        [597.7883],
        [598.8425],
        [605.1093],
        [601.9462]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.4956],
        [ 9.5013],
        [ 9.4974],
        [ 9.5316],
        [ 9.5657],
        [ 9.5160],
        [ 9.4793],
        [ 9.4075],
        [11.2507],
        [ 9.4228]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9196],
        [10.1882],
        [10.0465],
        [10.0685],
        [10.1982],
        [ 9.8574],
        [10.0004],
        [ 9.8280],
        [ 9.2448],
        [10.2247]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0675],
        [9.0926],
        [9.0691],
        [9.0600],
        [9.0679],
        [9.0662],
        [9.0763],
        [9.0537],
        [9.1434],
        [9.1553]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.0527],
        [217.1770],
        [217.0915],
        [217.8406],
        [218.5858],
        [217.5000],
        [216.6956],
        [215.1252],
        [255.4535],
        [215.4593]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[554.4908],
        [569.2508],
        [561.4680],
        [562.6762],
        [569.8040],
        [551.0708],
        [558.9296],
        [549.4588],
        [517.4015],
        [571.2611]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[598.4910],
        [600.1194],
        [598.5942],
        [598.0055],
        [598.5149],
        [598.4016],
        [599.0619],
        [597.5969],
        [603.4143],
        [604.1834]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5241],
        [9.6082],
        [9.5080],
        [9.5456],
        [9.5668],
        [9.4857],
        [9.5759],
        [9.4776],
        [9.4130],
        [9.5274]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8575],
        [10.1436],
        [ 9.9591],
        [ 9.9708],
        [10.0849],
        [10.0673],
        [ 9.9989],
        [ 9.8551],
        [10.0376],
        [10.1903]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0629],
        [9.0616],
        [9.0620],
        [9.0807],
        [9.0794],
        [9.0686],
        [9.0570],
        [9.1137],
        [9.1308],
        [9.0714]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6769],
        [219.5176],
        [217.3235],
        [218.1470],
        [218.6111],
        [216.8368],
        [218.8107],
        [216.6600],
        [215.2462],
        [217.7491]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[551.0802],
        [566.7994],
        [556.6594],
        [557.3068],
        [563.5770],
        [562.6099],
        [558.8511],
        [550.9433],
        [560.9742],
        [569.3706]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[598.1928],
        [598.1067],
        [598.1322],
        [599.3432],
        [599.2605],
        [598.5612],
        [597.8071],
        [601.4862],
        [602.5954],
        [598.7413]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5112],
        [9.4985],
        [9.5067],
        [9.4989],
        [9.5227],
        [9.5116],
        [9.5394],
        [9.5012],
        [9.9826],
        [9.5255]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9530],
        [10.0958],
        [ 9.9725],
        [ 9.9841],
        [10.0138],
        [ 9.9985],
        [ 9.9969],
        [ 9.9659],
        [ 9.8628],
        [10.0235]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0727],
        [9.0759],
        [9.0744],
        [9.0636],
        [9.0623],
        [9.0774],
        [9.0761],
        [9.0571],
        [9.0566],
        [9.0718]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.3953],
        [217.1169],
        [217.2965],
        [217.1248],
        [217.6462],
        [217.4031],
        [218.0105],
        [217.1747],
        [227.7092],
        [217.7066]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[556.3246],
        [564.1753],
        [557.3971],
        [558.0379],
        [559.6685],
        [558.8281],
        [558.7420],
        [557.0342],
        [551.3703],
        [560.2031]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[598.8244],
        [599.0308],
        [598.9361],
        [598.2338],
        [598.1538],
        [599.1313],
        [599.0475],
        [597.8142],
        [597.7824],
        [598.7692]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5087],
        [9.5151],
        [9.5066],
        [9.5237],
        [9.5239],
        [9.5104],
        [9.5238],
        [9.4934],
        [9.6050],
        [9.5096]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9640],
        [10.0558],
        [ 9.9890],
        [ 9.9779],
        [10.0307],
        [ 9.9777],
        [ 9.9875],
        [ 9.9483],
        [10.0222],
        [10.0324]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0697],
        [9.0707],
        [9.0713],
        [9.0676],
        [9.0637],
        [9.0737],
        [9.0739],
        [9.0574],
        [9.0644],
        [9.0802]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.3385],
        [217.4805],
        [217.2944],
        [217.6679],
        [217.6716],
        [217.3776],
        [217.6704],
        [217.0058],
        [219.4467],
        [217.3603]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[556.9334],
        [561.9777],
        [558.3029],
        [557.6963],
        [560.5958],
        [557.6818],
        [558.2247],
        [556.0663],
        [560.1312],
        [560.6926]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[598.6320],
        [598.6982],
        [598.7380],
        [598.4953],
        [598.2416],
        [598.8879],
        [598.9029],
        [597.8319],
        [598.2899],
        [599.3104]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5087],
        [9.5151],
        [9.5066],
        [9.5237],
        [9.5239],
        [9.5104],
        [9.5238],
        [9.4934],
        [9.6050],
        [9.5096]], device='cuda:0', dtype=torch.float64), tensor([[ 9.9640],
        [10.0558],
        [ 9.9890],
        [ 9.9779],
        [10.0307],
        [ 9.9777],
        [ 9.9875],
        [ 9.9483],
        [10.0222],
        [10.0324]], device='cuda:0', dtype=torch.float64), tensor([[9.0697],
        [9.0707],
        [9.0713],
        [9.0676],
        [9.0637],
        [9.0737],
        [9.0739],
        [9.0574],
        [9.0644],
        [9.0802]], device='cuda:0', dtype=torch.float64)]
AFTER NORMALIZATION:
[tensor([[217.3385],
        [217.4805],
        [217.2944],
        [217.6679],
        [217.6716],
        [217.3776],
        [217.6704],
        [217.0058],
        [219.4467],
        [217.3603]], device='cuda:0', dtype=torch.float64), tensor([[556.9334],
        [561.9777],
        [558.3029],
        [557.6963],
        [560.5958],
        [557.6818],
        [558.2247],
        [556.0663],
        [560.1312],
        [560.6926]], device='cuda:0', dtype=torch.float64), tensor([[598.6320],
        [598.6982],
        [598.7380],
        [598.4953],
        [598.2416],
        [598.8879],
        [598.9029],
        [597.8319],
        [598.2899],
        [599.3104]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION:
[tensor([[10.1295],
        [20.2208],
        [10.9614],
        [47.8558],
        [22.9517],
        [18.3202],
        [11.4761],
        [20.0891],
        [12.4660],
        [46.7500],
        [13.3969],
        [31.8442],
        [12.0517],
        [10.9634],
        [12.5175],
        [32.4592],
        [12.3087],
        [33.2333],
        [20.3985],
        [25.7378],
        [10.8770],
        [20.6208],
        [11.7175],
        [41.4979],
        [12.1486],
        [21.8984],
        [10.1548],
        [37.3951],
        [17.0506],
        [16.7393],
        [10.0882],
        [18.2296],
        [ 9.6985],
        [29.5249],
        [17.5841],
        [32.9993],
        [13.2213],
        [10.6331],
        [18.5347],
        [36.7856],
        [ 9.6035],
        [29.1248],
        [ 9.3855],
        [54.3843],
        [16.7485],
        [13.7755],
        [ 9.5611],
        [18.4433],
        [ 9.2736],
        [17.3599],
        [13.5858],
        [45.0141],
        [13.6064],
        [29.5763],
        [ 9.4384],
        [28.7704],
        [17.2854],
        [35.9411],
        [10.3679],
        [24.8113],
        [11.1864],
        [11.3162],
        [10.4196],
        [30.7871],
        [11.9555],
        [25.5339],
        [13.5761],
        [23.6193],
        [11.7591],
        [14.9892],
        [14.5221],
        [41.1183],
        [ 9.9497],
        [22.3754],
        [ 9.7866],
        [40.6962],
        [14.5865],
        [14.5083],
        [ 9.7964],
        [25.0445],
        [ 9.7814],
        [26.6319],
        [15.1204],
        [51.0715],
        [19.5320],
        [25.5396],
        [ 9.7710],
        [20.1597],
        [15.9942],
        [45.7338],
        [15.4820],
        [29.5534],
        [13.7910],
        [10.6256],
        [12.3895],
        [23.9716],
        [ 9.0593],
        [12.7526],
        [10.7848],
        [41.1921],
        [16.2819],
        [21.5005],
        [10.2283],
        [28.0159],
        [13.3041],
        [37.0945],
        [ 9.6939],
        [27.6225],
        [10.5207],
        [11.1651],
        [10.5827],
        [40.0308],
        [ 9.8528],
        [39.2575],
        [26.3997],
        [35.7660],
        [11.3305],
        [12.7950],
        [13.9655],
        [37.9389],
        [10.1515],
        [28.3418],
        [ 9.8219],
        [50.2312],
        [20.4128],
        [14.5777],
        [ 9.3634],
        [13.7337],
        [ 9.2243],
        [39.0990],
        [17.8657],
        [34.5486],
        [12.7531],
        [12.8879],
        [16.3020],
        [38.3472],
        [ 9.8171],
        [25.1159],
        [ 9.6270],
        [45.3690],
        [21.1945],
        [11.7902],
        [ 9.3624],
        [16.1707],
        [ 9.3438],
        [16.8144],
        [12.1796],
        [36.5148],
        [17.1895],
        [29.9668],
        [ 9.6171],
        [21.6193],
        [17.3427],
        [41.2390],
        [13.0824],
        [26.0159],
        [11.0999],
        [12.3482],
        [ 9.2799],
        [36.2584],
        [10.4990],
        [20.3891],
        [12.3579],
        [57.2928],
        [18.4599],
        [18.3552],
        [10.6118],
        [25.7339],
        [12.3591],
        [40.9135],
        [10.6124],
        [31.1547],
        [11.8917],
        [11.0420],
        [16.2426],
        [27.1173],
        [13.9176],
        [25.4522],
        [19.5939],
        [24.6754],
        [10.8249],
        [14.7458],
        [12.6302],
        [40.7912],
        [10.3439],
        [25.2630],
        [ 9.9755],
        [44.8244],
        [14.1386],
        [20.1276],
        [ 9.8610],
        [21.1683],
        [ 9.3430],
        [16.6421],
        [10.8497],
        [42.8306],
        [15.5929],
        [28.0982],
        [10.1577],
        [28.5893],
        [17.4582],
        [33.5037],
        [ 9.8223],
        [21.8150],
        [11.3626],
        [10.9485],
        [10.6431],
        [36.9579],
        [10.8370],
        [39.1349],
        [21.2197],
        [28.9712],
        [13.5108],
        [13.4200],
        [16.6499],
        [30.0982],
        [10.3211],
        [31.8533],
        [11.5553],
        [52.4354],
        [19.3950],
        [15.7892],
        [ 9.2106],
        [15.6380],
        [10.7556],
        [24.7758],
        [17.2079],
        [28.9910],
        [10.9439],
        [14.3791],
        [12.7551],
        [49.7020],
        [ 9.9832],
        [19.7618],
        [11.6965],
        [39.0483],
        [14.9613],
        [14.2921],
        [ 9.1414],
        [21.6741],
        [ 9.2684],
        [20.8385],
        [13.8000],
        [50.1922],
        [19.7094],
        [19.0741],
        [10.3032],
        [20.3759],
        [12.5214],
        [50.2685],
        [14.6764],
        [36.3513],
        [11.7829],
        [10.9531],
        [12.0618],
        [26.3759],
        [10.6896],
        [30.8996],
        [15.2110],
        [26.0214],
        [11.1263],
        [15.8189],
        [13.0695],
        [48.1798],
        [11.1152],
        [18.7385],
        [10.6009],
        [36.8775],
        [16.9917],
        [15.0529],
        [ 9.1833],
        [20.9748],
        [ 9.1475],
        [23.4587],
        [14.3581],
        [44.9813],
        [21.1813],
        [22.5023],
        [10.8733],
        [17.6898],
        [13.0076],
        [49.5557],
        [16.4884],
        [34.2973],
        [12.7029],
        [10.8954],
        [10.2135],
        [26.8293],
        [ 9.1911],
        [15.7560],
        [10.9815],
        [45.0535],
        [14.2466],
        [21.9970],
        [ 9.7310],
        [33.8109],
        [15.5642],
        [32.2477],
        [ 9.3340],
        [25.0946],
        [10.7852],
        [11.0771],
        [12.0937],
        [34.7377],
        [11.5666],
        [34.4087],
        [25.8157],
        [31.0898],
        [12.0772],
        [11.6450],
        [17.2947],
        [33.4096],
        [ 9.8955],
        [30.7452],
        [ 9.8755],
        [56.5336],
        [18.2993],
        [15.7266],
        [ 9.0871],
        [15.0535],
        [10.2536],
        [22.8239],
        [12.7192],
        [51.7719],
        [19.2967],
        [21.7480],
        [11.1490],
        [22.7755],
        [12.8526],
        [40.2712],
        [11.6548],
        [29.2363],
        [13.4022],
        [11.7336],
        [12.9785],
        [27.4118],
        [13.6549],
        [31.5504],
        [17.2903],
        [21.4901],
        [11.2191],
        [16.3522],
        [12.9101],
        [39.5427],
        [11.3448],
        [24.4673],
        [10.1505],
        [43.2675],
        [15.8459],
        [21.3789],
        [10.6685],
        [20.3987],
        [ 9.4087],
        [33.6231],
        [21.4016],
        [35.7100],
        [11.7868],
        [11.3484],
        [17.1506],
        [41.5566],
        [ 9.3489],
        [24.8460],
        [ 9.8637],
        [50.5568],
        [19.5844],
        [11.8697],
        [ 9.5544],
        [15.7211],
        [ 9.4839],
        [16.1202],
        [12.3639],
        [39.0825],
        [14.9927],
        [24.0977],
        [ 9.2947],
        [26.8089],
        [15.7389],
        [39.3113],
        [11.2279],
        [29.2592],
        [10.9231],
        [13.5731],
        [ 9.8524],
        [33.3610],
        [ 9.1108],
        [16.0285],
        [10.3054],
        [37.7381],
        [17.2150],
        [24.0474],
        [10.3894],
        [27.2464],
        [15.4721],
        [35.3522],
        [11.0410],
        [25.7398],
        [10.8138],
        [11.3990],
        [ 9.8442],
        [38.6442],
        [10.0457],
        [43.0277],
        [27.5679],
        [31.3747],
        [12.1027],
        [14.6485],
        [14.9339],
        [33.3019],
        [10.3677],
        [28.0236],
        [10.0842],
        [47.9760],
        [22.5435],
        [13.7514],
        [ 9.1845],
        [14.0248],
        [12.2578],
        [24.4443],
        [13.8305],
        [25.1998],
        [11.0821],
        [12.3402],
        [14.7303],
        [47.9147],
        [ 9.5148],
        [21.3487],
        [10.6022],
        [45.4626],
        [13.5451],
        [17.0432],
        [ 9.3182],
        [23.1536],
        [ 9.6062],
        [22.7573],
        [18.1305],
        [53.8470],
        [17.1342],
        [21.4679],
        [ 9.8569],
        [22.4319],
        [13.2900],
        [44.3405],
        [11.9589],
        [32.7511],
        [13.0894],
        [10.5196],
        [12.9010],
        [23.2165],
        [ 9.8657],
        [33.0966],
        [18.5492],
        [29.4049],
        [13.6151],
        [11.4231],
        [19.1636],
        [33.1996],
        [ 9.6685],
        [28.4159],
        [ 9.4823],
        [51.2177],
        [19.3625],
        [12.7096],
        [ 9.0528],
        [18.5606],
        [ 9.0888],
        [21.6090],
        [12.2309],
        [39.9561],
        [14.6085],
        [32.5093],
        [ 9.5276],
        [27.5490],
        [19.5826],
        [35.1425],
        [12.2242],
        [24.0470],
        [11.8059],
        [11.8269],
        [ 9.7326],
        [29.9513],
        [ 9.5458],
        [17.1874],
        [12.4910],
        [49.7541],
        [20.2203],
        [15.5355],
        [11.7386],
        [22.3438],
        [10.4616],
        [45.8155],
        [10.6597],
        [35.8723],
        [11.5040],
        [10.8960],
        [13.1257],
        [31.4681],
        [12.7404],
        [31.7642],
        [20.6926],
        [27.5073],
        [10.3311],
        [16.3831],
        [11.6828],
        [48.8879],
        [11.2198],
        [20.9304],
        [10.5715],
        [41.8859],
        [16.2205],
        [19.4111],
        [ 9.2293],
        [16.7357]], device='cuda:0', dtype=torch.float64), tensor([[14.1325],
        [23.2331],
        [11.2927],
        [21.6706],
        [33.4299],
        [ 9.9564],
        [12.0307],
        [12.3137],
        [15.5380],
        [48.2194],
        [13.3346],
        [11.9112],
        [31.3183],
        [12.5384],
        [55.3626],
        [ 9.6055],
        [24.9201],
        [ 9.5225],
        [27.5541],
        [10.4188],
        [22.5003],
        [49.3738],
        [ 9.8213],
        [35.9809],
        [49.4735],
        [ 9.8211],
        [11.9428],
        [20.8205],
        [ 9.6011],
        [20.0808],
        [11.2535],
        [21.7075],
        [33.3683],
        [ 9.8010],
        [31.3519],
        [11.5699],
        [10.3176],
        [29.0917],
        [12.4573],
        [10.7489],
        [47.8042],
        [25.7549],
        [18.2623],
        [ 9.7239],
        [10.0925],
        [29.8068],
        [ 9.4409],
        [51.6453],
        [13.2608],
        [28.4551],
        [10.0385],
        [31.8056],
        [54.5332],
        [12.9670],
        [25.8181],
        [13.7484],
        [ 9.8170],
        [53.6528],
        [19.1189],
        [16.0949],
        [13.1980],
        [13.4383],
        [14.8081],
        [11.4724],
        [19.6497],
        [10.7404],
        [21.3319],
        [16.3104],
        [14.2890],
        [12.1503],
        [15.5584],
        [45.7923],
        [20.4935],
        [ 9.8443],
        [39.4452],
        [17.7242],
        [ 9.2752],
        [49.6952],
        [11.5346],
        [34.7044],
        [10.4136],
        [32.2473],
        [10.0136],
        [23.3979],
        [23.2602],
        [14.0490],
        [64.9858],
        [18.2993],
        [14.3852],
        [11.3752],
        [11.2313],
        [33.7530],
        [23.4348],
        [10.8811],
        [21.4837],
        [ 9.0816],
        [10.9874],
        [29.0533],
        [15.0692],
        [23.5379],
        [10.5602],
        [14.3599],
        [33.4194],
        [11.1892],
        [ 9.1601],
        [22.7709],
        [27.5627],
        [41.4593],
        [33.7499],
        [10.5952],
        [36.5324],
        [ 9.6373],
        [46.5071],
        [14.0485],
        [20.6124],
        [16.1909],
        [15.6551],
        [20.2806],
        [12.3000],
        [60.7149],
        [15.8459],
        [16.8367],
        [48.7171],
        [ 9.1683],
        [10.9507],
        [16.7125],
        [ 9.6391],
        [20.1118],
        [14.9508],
        [10.3344],
        [11.6231],
        [39.3562],
        [32.4427],
        [11.1403],
        [27.1206],
        [11.7827],
        [10.1094],
        [39.5122],
        [ 9.6931],
        [33.3083],
        [25.7627],
        [ 9.3777],
        [38.4209],
        [30.5386],
        [16.9836],
        [19.4438],
        [60.4955],
        [11.5461],
        [12.7369],
        [40.8226],
        [15.4525],
        [23.7479],
        [14.6320],
        [10.9584],
        [16.8771],
        [11.1280],
        [16.3643],
        [16.9273],
        [ 9.2948],
        [42.5403],
        [11.2635],
        [13.6364],
        [41.3797],
        [11.9883],
        [10.4263],
        [20.2186],
        [17.7575],
        [17.7378],
        [44.1829],
        [ 9.3093],
        [36.7021],
        [10.5436],
        [10.3941],
        [16.8279],
        [16.8331],
        [43.6049],
        [12.7388],
        [27.5020],
        [19.6892],
        [58.9763],
        [37.8051],
        [11.6265],
        [22.8766],
        [10.7861],
        [10.6755],
        [22.2972],
        [ 9.0651],
        [25.2114],
        [12.3448],
        [17.2531],
        [39.3883],
        [10.0136],
        [23.4878],
        [10.4351],
        [10.9247],
        [11.6428],
        [10.7208],
        [31.6920],
        [11.0343],
        [31.9247],
        [32.9273],
        [ 9.9764],
        [43.4817],
        [ 9.6007],
        [28.0501],
        [49.3375],
        [10.6965],
        [17.3852],
        [11.9049],
        [53.0019],
        [12.1436],
        [27.3774],
        [25.0780],
        [14.9689],
        [37.8541],
        [10.8229],
        [12.0422],
        [13.9481],
        [10.9092],
        [14.5048],
        [61.5311],
        [10.7004],
        [15.7021],
        [19.1309],
        [10.9441],
        [35.0226],
        [13.3670],
        [11.8399],
        [28.7305],
        [12.5317],
        [22.2530],
        [11.7017],
        [11.8869],
        [29.7969],
        [10.4655],
        [57.8465],
        [44.7465],
        [17.2862],
        [14.7854],
        [12.0386],
        [56.1151],
        [19.7301],
        [30.3057],
        [10.6371],
        [ 9.7179],
        [25.8366],
        [10.0947],
        [25.9026],
        [16.3783],
        [10.5654],
        [21.8219],
        [11.4683],
        [ 9.6745],
        [47.0039],
        [18.4178],
        [12.0129],
        [ 9.5887],
        [39.3667],
        [ 9.8458],
        [37.6775],
        [20.3432],
        [ 9.7753],
        [42.5956],
        [21.8011],
        [13.5058],
        [11.0631],
        [11.0889],
        [29.6444],
        [34.7070],
        [10.8024],
        [26.9661],
        [12.5226],
        [13.7905],
        [10.6482],
        [16.9917],
        [10.8087],
        [16.2669],
        [18.0521],
        [ 9.4234],
        [52.2277],
        [23.2700],
        [13.8023],
        [60.9390],
        [15.2219],
        [11.7583],
        [42.3719],
        [12.2883],
        [21.8876],
        [52.1416],
        [ 9.9773],
        [33.7950],
        [14.1004],
        [10.9581],
        [17.4709],
        [13.2583],
        [38.0825],
        [10.7412],
        [15.4420],
        [42.7338],
        [13.0590],
        [11.0728],
        [23.8142],
        [14.6901],
        [23.8557],
        [11.0170],
        [20.0392],
        [ 9.5564],
        [19.6860],
        [13.2062],
        [15.4527],
        [38.6329],
        [10.1806],
        [12.0476],
        [25.9880],
        [25.4752],
        [63.7985],
        [28.8785],
        [10.6312],
        [22.0854],
        [ 9.2281],
        [29.3907],
        [10.1848],
        [46.0917],
        [ 9.7254],
        [33.5865],
        [45.4138],
        [ 9.1713],
        [21.1538],
        [34.2622],
        [10.3162],
        [10.9606],
        [12.9951],
        [10.7699],
        [30.1986],
        [11.9191],
        [27.0011],
        [12.1799],
        [15.3514],
        [11.6000],
        [17.9228],
        [48.0969],
        [ 9.4754],
        [13.3638],
        [19.4139],
        [10.5746],
        [53.0614],
        [15.6688],
        [21.1555],
        [27.5420],
        [16.0768],
        [35.3804],
        [10.7636],
        [10.5189],
        [32.1682],
        [ 9.2232],
        [50.6888],
        [50.3780],
        [18.8052],
        [13.5950],
        [12.3499],
        [10.4932],
        [36.1230],
        [11.9433],
        [13.8647],
        [19.4334],
        [15.6617],
        [16.2042],
        [10.7012],
        [22.4644],
        [ 9.1243],
        [26.9013],
        [11.1064],
        [10.1279],
        [44.7510],
        [20.3086],
        [10.9929],
        [50.9904],
        [17.7511],
        [33.4415],
        [10.4635],
        [11.0712],
        [26.2716],
        [10.3492],
        [32.2041],
        [22.5274],
        [46.2239],
        [10.7100],
        [17.5404],
        [30.7912],
        [10.6155],
        [54.3342],
        [ 9.7788],
        [13.8121],
        [25.5921],
        [11.4483],
        [17.9452],
        [38.6429],
        [12.2680],
        [14.0171],
        [12.5832],
        [40.7715],
        [10.3181],
        [10.9472],
        [17.6300],
        [ 9.7240],
        [18.1982],
        [11.4642],
        [26.3591],
        [27.0651],
        [11.0925],
        [29.6022],
        [ 9.7716],
        [14.7814],
        [56.6709],
        [12.0462],
        [26.8144],
        [47.8113],
        [33.9076],
        [19.6005],
        [ 9.7779],
        [10.5590],
        [31.4799],
        [10.2604],
        [36.4469],
        [27.8166],
        [12.5191],
        [26.0487],
        [11.3387],
        [10.1622],
        [27.3842],
        [12.3103],
        [11.0022],
        [ 9.8319],
        [57.2547],
        [19.9021],
        [13.7437],
        [16.7560],
        [10.6111],
        [18.4887],
        [11.1276],
        [19.7415],
        [23.2033],
        [12.6880],
        [42.0903],
        [52.1624],
        [10.3211],
        [23.5911],
        [13.5131],
        [14.9771],
        [11.3779],
        [41.8853],
        [13.5228],
        [ 9.0727],
        [48.4721],
        [13.2975],
        [36.0601],
        [26.2520],
        [10.9457],
        [20.6339],
        [15.6295],
        [14.1050],
        [10.5550],
        [11.1350],
        [38.5313],
        [17.5228],
        [14.0899],
        [ 9.4426],
        [43.1565],
        [18.2051],
        [10.9607],
        [22.8975],
        [ 9.3589],
        [11.2987],
        [33.1943],
        [ 9.4799],
        [22.1315],
        [29.4920],
        [11.3524],
        [58.0733],
        [25.6251],
        [ 9.0824],
        [23.0404],
        [22.5083],
        [40.6038],
        [44.3069],
        [ 9.4337],
        [33.7691],
        [ 9.9217],
        [10.7188],
        [36.7580],
        [10.3555],
        [29.4495],
        [11.3362],
        [14.0944],
        [33.9284],
        [11.3645],
        [20.1976],
        [15.7830],
        [47.1073],
        [ 9.2071],
        [10.6957],
        [12.6610],
        [12.3369],
        [14.7666],
        [37.3957],
        [11.3015],
        [24.8004],
        [12.4184],
        [16.9273],
        [20.3880],
        [14.5975],
        [62.4562]], device='cuda:0', dtype=torch.float64), tensor([[10.5741],
        [30.5929],
        [43.9707],
        [23.8525],
        [ 9.6513],
        [13.2272],
        [44.6373],
        [14.3482],
        [15.1745],
        [80.9953],
        [26.0857],
        [16.7154],
        [14.5709],
        [42.3980],
        [48.9202],
        [ 9.9731],
        [49.5319],
        [ 9.7065],
        [ 9.4604],
        [43.6479],
        [77.2906],
        [11.5935],
        [24.3458],
        [20.3850],
        [15.4015],
        [10.2463],
        [12.8136],
        [46.8354],
        [19.3144],
        [11.4720],
        [15.8564],
        [24.3806],
        [60.6897],
        [ 9.2809],
        [17.5037],
        [31.1030],
        [67.1592],
        [11.1962],
        [11.2358],
        [27.3022],
        [24.7610],
        [10.8553],
        [10.0549],
        [13.5149],
        [11.7974],
        [10.2770],
        [18.2048],
        [67.7640],
        [ 9.8607],
        [11.4795],
        [68.7613],
        [20.4879],
        [10.4805],
        [41.6721],
        [27.8491],
        [15.9526],
        [11.4393],
        [58.3435],
        [33.5259],
        [13.2066],
        [10.4871],
        [64.2640],
        [36.9530],
        [13.7545],
        [10.8630],
        [57.8222],
        [39.5828],
        [19.0104],
        [10.5828],
        [80.0691],
        [26.3141],
        [10.0120],
        [12.2884],
        [22.5455],
        [17.5379],
        [ 9.5492],
        [10.8152],
        [14.9678],
        [61.7448],
        [24.9083],
        [12.6906],
        [11.4515],
        [23.3401],
        [53.1811],
        [30.7522],
        [10.8195],
        [12.1523],
        [32.4745],
        [59.7275],
        [13.0784],
        [12.9933],
        [26.4936],
        [53.3375],
        [10.9146],
        [16.3644],
        [38.9952],
        [23.4413],
        [10.2140],
        [18.3060],
        [48.5694],
        [14.1819],
        [ 9.5381],
        [15.3188],
        [34.0381],
        [65.2786],
        [16.7232],
        [21.7693],
        [28.5575],
        [45.5798],
        [18.7170],
        [ 9.6179],
        [38.4464],
        [10.0691],
        [62.1634],
        [40.0832],
        [10.1836],
        [15.9684],
        [72.2293],
        [28.2651],
        [27.1329],
        [10.1099],
        [19.5959],
        [44.1101],
        [16.3402],
        [10.9617],
        [18.0634],
        [30.9863],
        [14.9146],
        [13.0580],
        [ 9.6307],
        [13.7408],
        [43.8198],
        [27.7074],
        [11.2906],
        [21.2234],
        [40.8855],
        [36.0285],
        [17.9129],
        [11.4497],
        [43.2862],
        [78.5057],
        [14.0983],
        [18.5265],
        [24.3088],
        [13.8672],
        [84.9873],
        [24.7056],
        [19.4263],
        [ 9.6412],
        [51.8459],
        [44.8232],
        [ 9.5446],
        [11.2845],
        [19.5287],
        [24.2633],
        [16.1814],
        [10.6537],
        [16.7771],
        [51.1128],
        [14.6565],
        [12.2038],
        [73.4953],
        [32.1236],
        [10.2927],
        [ 9.3465],
        [62.4924],
        [31.5129],
        [17.6702],
        [10.2623],
        [12.4539],
        [70.9771],
        [18.6720],
        [11.3647],
        [30.1808],
        [16.4091],
        [11.6332],
        [38.9524],
        [10.4908],
        [14.9941],
        [25.6450],
        [10.6982],
        [10.2577],
        [18.1218],
        [60.1601],
        [57.7677],
        [ 9.9045],
        [14.3411],
        [33.6376],
        [57.1439],
        [11.3871],
        [13.5586],
        [32.0980],
        [76.7646],
        [10.1617],
        [10.0962],
        [25.3515],
        [51.9716],
        [ 9.6417],
        [23.3597],
        [33.8063],
        [13.9314],
        [11.7252],
        [21.4359],
        [57.1552],
        [21.9354],
        [11.9798],
        [ 9.4784],
        [17.6474],
        [12.0522],
        [34.2136],
        [35.2718],
        [13.2260],
        [11.1579],
        [12.7277],
        [53.8684],
        [24.4138],
        [11.5404],
        [54.8383],
        [41.0779],
        [15.0615],
        [11.3795],
        [68.5472],
        [30.6497],
        [10.8497],
        [ 9.4786],
        [17.2980],
        [40.5860],
        [17.4747],
        [10.0604],
        [24.9170],
        [51.6909],
        [19.2868],
        [18.8667],
        [46.2234],
        [39.5631],
        [ 9.6459],
        [18.7333],
        [73.2231],
        [32.0086],
        [20.1119],
        [69.5546],
        [15.5429],
        [27.4487],
        [27.4199],
        [57.0428],
        [10.2499],
        [ 9.8890],
        [34.9432],
        [14.9638],
        [11.0082],
        [12.5033],
        [25.1170],
        [17.8118],
        [ 9.9240],
        [15.7049],
        [41.3648],
        [14.6668],
        [25.5757],
        [71.7505],
        [15.7440],
        [ 9.4851],
        [45.4323],
        [43.9699],
        [12.8115],
        [20.5442],
        [34.3155],
        [25.8520],
        [11.3124],
        [12.7944],
        [35.7887],
        [11.0516],
        [ 9.1314],
        [55.5586],
        [12.9112],
        [11.6210],
        [19.9006],
        [32.9801],
        [20.4294],
        [11.0903],
        [25.0632],
        [48.3913],
        [ 9.1184],
        [10.5524],
        [50.0965],
        [20.1692],
        [28.2313],
        [11.3456],
        [82.0298],
        [19.3224],
        [11.9551],
        [11.4218],
        [31.0209],
        [75.6405],
        [19.0569],
        [10.5850],
        [14.9233],
        [29.0167],
        [20.0296],
        [ 9.2574],
        [65.7153],
        [33.4816],
        [10.9515],
        [11.1810],
        [66.7793],
        [13.2085],
        [31.9809],
        [57.2779],
        [10.6078],
        [11.4288],
        [36.0554],
        [59.7872],
        [10.7897],
        [19.4908],
        [56.0697],
        [10.8388],
        [10.2918],
        [12.9631],
        [22.0705],
        [33.3206],
        [10.8476],
        [10.0812],
        [19.5557],
        [24.2513],
        [11.6744],
        [20.4660],
        [64.4478],
        [15.8033],
        [11.2821],
        [28.3052],
        [33.3903],
        [51.6707],
        [ 9.6495],
        [10.0840],
        [24.7367],
        [73.6346],
        [ 9.8927],
        [28.4231],
        [10.0911],
        [10.6896],
        [72.2354],
        [46.6094],
        [12.6171],
        [13.7401],
        [53.6651],
        [52.9458],
        [24.6800],
        [10.7962],
        [11.6525],
        [28.5753],
        [12.1409],
        [11.9861],
        [31.0304],
        [32.9196],
        [15.5986],
        [20.3843],
        [67.7567],
        [42.1483],
        [ 9.0616],
        [13.1088],
        [54.4170],
        [44.8543],
        [18.0403],
        [10.6128],
        [22.4750],
        [32.1839],
        [16.5854],
        [ 9.3987],
        [13.0429],
        [14.1103],
        [44.2181],
        [21.7490],
        [10.5823],
        [15.3297],
        [35.0704],
        [18.7410],
        [10.9078],
        [ 9.1859],
        [38.7670],
        [54.4612],
        [12.3699],
        [38.2144],
        [21.9849],
        [67.7147],
        [12.2500],
        [47.0272],
        [ 9.4381],
        [12.9361],
        [44.8332],
        [29.0307],
        [13.5720],
        [17.5919],
        [80.7481],
        [42.5856],
        [14.5613],
        [ 9.2986],
        [12.0436],
        [36.8326],
        [21.8550],
        [11.0613],
        [27.4587],
        [17.0388],
        [27.1385],
        [20.9231],
        [11.7511],
        [12.5515],
        [52.6399],
        [18.1834],
        [11.1197],
        [28.4147],
        [19.5490],
        [79.2663],
        [11.1276],
        [ 9.3763],
        [42.7970],
        [45.8506],
        [10.6877],
        [16.1825],
        [70.0056],
        [13.6980],
        [10.8932],
        [11.7390],
        [19.2031],
        [30.0829],
        [11.2120],
        [11.5562],
        [32.2395],
        [63.6271],
        [10.6980],
        [24.7156],
        [24.2685],
        [59.0707],
        [ 9.4967],
        [37.7241],
        [10.7459],
        [11.3497],
        [61.0037],
        [36.3154],
        [11.1370],
        [10.7281],
        [65.3451],
        [23.9939],
        [14.2198],
        [11.4893],
        [36.9210],
        [56.7587],
        [20.1737],
        [10.1294],
        [10.8861],
        [67.1826],
        [20.9695],
        [11.1202],
        [16.9470],
        [24.1753],
        [11.4966],
        [12.7072],
        [29.3838],
        [28.9632],
        [ 9.4925],
        [10.1730],
        [80.0527],
        [33.8249],
        [28.6876],
        [ 9.7490],
        [53.1823],
        [13.2344],
        [42.3413],
        [47.3124],
        [12.5695],
        [10.3067],
        [26.9052],
        [70.5474],
        [10.5940],
        [11.4365],
        [26.3465],
        [28.7430],
        [11.7235],
        [21.5138],
        [45.4709],
        [10.9353],
        [12.3914],
        [ 9.2371],
        [37.5691],
        [47.3204],
        [15.9742],
        [17.2528],
        [31.0715],
        [65.9497],
        [18.9387],
        [15.9518],
        [31.5728],
        [12.9327],
        [ 9.5353],
        [16.3081],
        [41.8755],
        [20.3373],
        [10.6035],
        [35.1676],
        [15.6250],
        [10.9292],
        [19.0671],
        [48.7518],
        [16.5910],
        [10.7314],
        [23.9573],
        [26.7195],
        [30.8686],
        [14.8029],
        [75.2526],
        [39.9549],
        [ 9.3640],
        [11.5521],
        [57.0292]], device='cuda:0', dtype=torch.float64)]
AFTER NORMALIZATION:
[tensor([[ 230.9215],
        [ 451.7155],
        [ 249.1231],
        [1056.3599],
        [ 511.4682],
        [ 410.1327],
        [ 260.3860],
        [ 448.8336],
        [ 282.0436],
        [1032.1638],
        [ 302.4124],
        [ 706.0317],
        [ 272.9797],
        [ 249.1669],
        [ 283.1710],
        [ 719.4868],
        [ 278.6032],
        [ 736.4237],
        [ 455.6033],
        [ 572.4258],
        [ 247.2767],
        [ 460.4685],
        [ 265.6662],
        [ 917.2511],
        [ 275.0987],
        [ 488.4219],
        [ 231.4752],
        [ 827.4825],
        [ 382.3530],
        [ 375.5421],
        [ 230.0190],
        [ 408.1493],
        [ 221.4924],
        [ 655.2859],
        [ 394.0256],
        [ 731.3039],
        [ 298.5688],
        [ 241.9404],
        [ 414.8254],
        [ 814.1474],
        [ 219.4148],
        [ 646.5330],
        [ 214.6449],
        [1199.2011],
        [ 375.7435],
        [ 310.6962],
        [ 218.4865],
        [ 412.8247],
        [ 212.1967],
        [ 389.1206],
        [ 306.5446],
        [ 994.1828],
        [ 306.9953],
        [ 656.4111],
        [ 215.8008],
        [ 638.7790],
        [ 387.4901],
        [ 795.6700],
        [ 236.1382],
        [ 552.1540],
        [ 254.0459],
        [ 256.8876],
        [ 237.2702],
        [ 682.9030],
        [ 270.8745],
        [ 567.9640],
        [ 306.3334],
        [ 526.0750],
        [ 266.5778],
        [ 337.2511],
        [ 327.0316],
        [ 908.9444],
        [ 226.9875],
        [ 498.8569],
        [ 223.4195],
        [ 899.7105],
        [ 328.4388],
        [ 326.7288],
        [ 223.6351],
        [ 557.2567],
        [ 223.3058],
        [ 591.9876],
        [ 340.1214],
        [1126.7173],
        [ 436.6464],
        [ 568.0902],
        [ 223.0788],
        [ 450.3797],
        [ 359.2390],
        [1009.9316],
        [ 348.0327],
        [ 655.9090],
        [ 311.0347],
        [ 241.7761],
        [ 280.3693],
        [ 533.7831],
        [ 207.5063],
        [ 288.3157],
        [ 245.2612],
        [ 910.5599],
        [ 365.5347],
        [ 479.7151],
        [ 233.0849],
        [ 622.2701],
        [ 300.3819],
        [ 820.9063],
        [ 221.3917],
        [ 613.6626],
        [ 239.4826],
        [ 253.5810],
        [ 240.8389],
        [ 885.1504],
        [ 224.8693],
        [ 868.2320],
        [ 586.9081],
        [ 791.8380],
        [ 257.2006],
        [ 289.2422],
        [ 314.8527],
        [ 839.3818],
        [ 231.4047],
        [ 629.4003],
        [ 224.1912],
        [1108.3310],
        [ 455.9181],
        [ 328.2476],
        [ 214.1603],
        [ 309.7799],
        [ 211.1179],
        [ 864.7638],
        [ 400.1868],
        [ 765.2025],
        [ 288.3268],
        [ 291.2762],
        [ 365.9750],
        [ 848.3151],
        [ 224.0880],
        [ 558.8191],
        [ 219.9281],
        [1001.9489],
        [ 473.0200],
        [ 267.2571],
        [ 214.1385],
        [ 363.1008],
        [ 213.7326],
        [ 377.1849],
        [ 275.7778],
        [ 808.2229],
        [ 385.3924],
        [ 664.9555],
        [ 219.7107],
        [ 482.3140],
        [ 388.7447],
        [ 911.5871],
        [ 295.5302],
        [ 578.5096],
        [ 252.1546],
        [ 279.4671],
        [ 212.3339],
        [ 802.6121],
        [ 239.0071],
        [ 455.3993],
        [ 279.6788],
        [1262.8373],
        [ 413.1873],
        [ 410.8975],
        [ 241.4746],
        [ 572.3416],
        [ 279.7061],
        [ 904.4646],
        [ 241.4876],
        [ 690.9449],
        [ 269.4778],
        [ 250.8885],
        [ 364.6757],
        [ 602.6089],
        [ 313.8040],
        [ 566.1776],
        [ 437.9994],
        [ 549.1802],
        [ 246.1379],
        [ 331.9247],
        [ 285.6368],
        [ 901.7882],
        [ 235.6143],
        [ 562.0365],
        [ 227.5525],
        [ 990.0326],
        [ 318.6399],
        [ 449.6771],
        [ 225.0480],
        [ 472.4464],
        [ 213.7132],
        [ 373.4161],
        [ 246.6811],
        [ 946.4092],
        [ 350.4591],
        [ 624.0709],
        [ 231.5393],
        [ 634.8164],
        [ 391.2705],
        [ 742.3408],
        [ 224.2020],
        [ 486.5958],
        [ 257.9021],
        [ 248.8412],
        [ 242.1598],
        [ 817.9176],
        [ 246.4024],
        [ 865.5489],
        [ 473.5721],
        [ 643.1718],
        [ 304.9039],
        [ 302.9168],
        [ 373.5852],
        [ 667.8301],
        [ 235.1143],
        [ 706.2302],
        [ 262.1189],
        [1156.5587],
        [ 433.6477],
        [ 354.7551],
        [ 210.8163],
        [ 351.4458],
        [ 244.6207],
        [ 551.3778],
        [ 385.7950],
        [ 643.6037],
        [ 248.7417],
        [ 323.9012],
        [ 288.3688],
        [1096.7524],
        [ 227.7216],
        [ 441.6742],
        [ 265.2079],
        [ 863.6535],
        [ 336.6394],
        [ 321.9977],
        [ 209.3039],
        [ 483.5139],
        [ 212.0811],
        [ 465.2310],
        [ 311.2306],
        [1107.4785],
        [ 440.5261],
        [ 426.6276],
        [ 234.7220],
        [ 455.1088],
        [ 283.2556],
        [1109.1480],
        [ 330.4069],
        [ 804.6458],
        [ 267.0991],
        [ 248.9422],
        [ 273.1994],
        [ 586.3881],
        [ 243.1768],
        [ 685.3642],
        [ 342.1029],
        [ 578.6313],
        [ 252.7324],
        [ 355.4049],
        [ 295.2477],
        [1063.4483],
        [ 252.4896],
        [ 419.2830],
        [ 241.2359],
        [ 816.1584],
        [ 381.0656],
        [ 338.6439],
        [ 210.2195],
        [ 468.2131],
        [ 209.4368],
        [ 522.5597],
        [ 323.4420],
        [ 993.4672],
        [ 472.7309],
        [ 501.6341],
        [ 247.1975],
        [ 396.3396],
        [ 293.8946],
        [1093.5514],
        [ 370.0517],
        [ 759.7045],
        [ 287.2273],
        [ 247.6802],
        [ 232.7593],
        [ 596.3081],
        [ 210.3912],
        [ 354.0273],
        [ 249.5636],
        [ 995.0453],
        [ 321.0035],
        [ 490.5777],
        [ 222.2041],
        [ 749.0625],
        [ 349.8306],
        [ 714.8591],
        [ 213.5179],
        [ 558.3522],
        [ 245.2693],
        [ 251.6555],
        [ 273.8976],
        [ 769.3400],
        [ 262.3649],
        [ 762.1418],
        [ 574.1310],
        [ 689.5258],
        [ 273.5383],
        [ 264.0817],
        [ 387.6948],
        [ 740.2812],
        [ 225.8025],
        [ 681.9867],
        [ 225.3643],
        [1246.2262],
        [ 409.6752],
        [ 353.3839],
        [ 208.1155],
        [ 338.6565],
        [ 233.6380],
        [ 508.6717],
        [ 287.5850],
        [1142.0408],
        [ 431.4978],
        [ 485.1302],
        [ 253.2293],
        [ 507.6109],
        [ 290.5032],
        [ 890.4111],
        [ 264.2952],
        [ 648.9720],
        [ 302.5284],
        [ 266.0188],
        [ 293.2565],
        [ 609.0518],
        [ 308.0574],
        [ 699.6034],
        [ 387.5981],
        [ 479.4882],
        [ 254.7628],
        [ 367.0724],
        [ 291.7619],
        [ 874.4722],
        [ 257.5133],
        [ 544.6276],
        [ 231.3808],
        [ 955.9680],
        [ 355.9940],
        [ 477.0542],
        [ 242.7148],
        [ 455.6089],
        [ 215.1513],
        [ 744.9536],
        [ 477.5516],
        [ 790.6145],
        [ 267.1833],
        [ 257.5920],
        [ 384.5414],
        [ 918.5362],
        [ 213.8431],
        [ 552.9127],
        [ 225.1060],
        [1115.4550],
        [ 437.7921],
        [ 268.9976],
        [ 218.3395],
        [ 353.2640],
        [ 216.7974],
        [ 361.9969],
        [ 279.8110],
        [ 864.4032],
        [ 337.3271],
        [ 536.5404],
        [ 212.6580],
        [ 595.8605],
        [ 353.6540],
        [ 869.4089],
        [ 254.9544],
        [ 649.4726],
        [ 248.2852],
        [ 306.2673],
        [ 224.8589],
        [ 739.2178],
        [ 208.6338],
        [ 359.9909],
        [ 234.7716],
        [ 834.9881],
        [ 385.9499],
        [ 535.4398],
        [ 236.6095],
        [ 605.4338],
        [ 347.8165],
        [ 782.7859],
        [ 250.8664],
        [ 572.4687],
        [ 245.8936],
        [ 258.6980],
        [ 224.6800],
        [ 854.8137],
        [ 229.0887],
        [ 950.7227],
        [ 612.4682],
        [ 695.7585],
        [ 274.0948],
        [ 329.7954],
        [ 336.0406],
        [ 737.9261],
        [ 236.1343],
        [ 622.4377],
        [ 229.9319],
        [1058.9896],
        [ 502.5369],
        [ 310.1692],
        [ 210.2459],
        [ 316.1504],
        [ 277.4885],
        [ 544.1239],
        [ 311.8996],
        [ 560.6552],
        [ 251.7654],
        [ 279.2914],
        [ 331.5863],
        [1057.6481],
        [ 217.4737],
        [ 476.3936],
        [ 241.2640],
        [1003.9966],
        [ 305.6550],
        [ 382.1920],
        [ 213.1707],
        [ 515.8844],
        [ 219.4728],
        [ 507.2136],
        [ 405.9821],
        [1187.4446],
        [ 384.1820],
        [ 479.0030],
        [ 224.9591],
        [ 500.0943],
        [ 300.0733],
        [ 979.4465],
        [ 270.9479],
        [ 725.8740],
        [ 295.6834],
        [ 239.4581],
        [ 291.5624],
        [ 517.2599],
        [ 225.1514],
        [ 733.4340],
        [ 415.1431],
        [ 652.6596],
        [ 307.1870],
        [ 259.2258],
        [ 428.5850],
        [ 735.6864],
        [ 220.8350],
        [ 631.0227],
        [ 216.7612],
        [1129.9170],
        [ 432.9373],
        [ 287.3730],
        [ 207.3649],
        [ 415.3922],
        [ 208.1530],
        [ 482.0887],
        [ 276.9002],
        [ 883.5158],
        [ 328.9202],
        [ 720.5836],
        [ 217.7536],
        [ 612.0532],
        [ 437.7525],
        [ 778.1976],
        [ 276.7538],
        [ 535.4316],
        [ 267.6013],
        [ 268.0603],
        [ 222.2382],
        [ 664.6146],
        [ 218.1515],
        [ 385.3468],
        [ 282.5902],
        [1097.8939],
        [ 451.7059],
        [ 349.2029],
        [ 266.1290],
        [ 498.1664],
        [ 238.1893],
        [1011.7184],
        [ 242.5229],
        [ 794.1659],
        [ 260.9961],
        [ 247.6930],
        [ 296.4770],
        [ 697.8018],
        [ 288.0480],
        [ 704.2819],
        [ 462.0384],
        [ 611.1413],
        [ 235.3341],
        [ 367.7490],
        [ 264.9074],
        [1078.9409],
        [ 254.7779],
        [ 467.2409],
        [ 240.5933],
        [ 925.7394],
        [ 364.1905],
        [ 433.9994],
        [ 211.2265],
        [ 375.4625]], device='cuda:0', dtype=torch.float64), tensor([[ 786.0336],
        [1286.2122],
        [ 629.9547],
        [1200.3352],
        [1846.6318],
        [ 556.5151],
        [ 670.5195],
        [ 686.0749],
        [ 863.2797],
        [2659.4780],
        [ 742.1825],
        [ 663.9486],
        [1730.5789],
        [ 698.4226],
        [3052.0704],
        [ 537.2282],
        [1378.9269],
        [ 532.6657],
        [1523.6958],
        [ 581.9248],
        [1245.9344],
        [2722.9246],
        [ 549.0892],
        [1986.8390],
        [2728.4037],
        [ 549.0772],
        [ 665.6855],
        [1153.6109],
        [ 536.9843],
        [1112.9557],
        [ 627.8049],
        [1202.3614],
        [1843.2484],
        [ 547.9736],
        [1732.4256],
        [ 645.1952],
        [ 576.3649],
        [1608.2062],
        [ 693.9636],
        [ 600.0687],
        [2636.6564],
        [1424.8106],
        [1013.0121],
        [ 543.7343],
        [ 563.9929],
        [1647.5081],
        [ 528.1831],
        [2847.7640],
        [ 738.1237],
        [1573.2173],
        [ 561.0245],
        [1757.3621],
        [3006.4886],
        [ 721.9791],
        [1428.2858],
        [ 764.9233],
        [ 548.8524],
        [2958.0984],
        [1060.0888],
        [ 893.8874],
        [ 734.6736],
        [ 747.8821],
        [ 823.1668],
        [ 639.8332],
        [1089.2650],
        [ 599.6053],
        [1181.7208],
        [ 905.7355],
        [ 794.6377],
        [ 677.0942],
        [ 864.4041],
        [2526.0811],
        [1135.6392],
        [ 550.3511],
        [2177.2393],
        [ 983.4398],
        [ 519.0768],
        [2740.5877],
        [ 643.2529],
        [1916.6809],
        [ 581.6395],
        [1781.6386],
        [ 559.6553],
        [1295.2705],
        [1287.7005],
        [ 781.4434],
        [3580.9691],
        [1015.0477],
        [ 799.9249],
        [ 634.4895],
        [ 626.5855],
        [1864.3941],
        [1297.2953],
        [ 607.3376],
        [1190.0611],
        [ 508.4362],
        [ 613.1792],
        [1606.0908],
        [ 837.5192],
        [1302.9646],
        [ 589.6975],
        [ 798.5329],
        [1846.0593],
        [ 624.2671],
        [ 512.7487],
        [1260.8085],
        [1524.1683],
        [2287.9371],
        [1864.2208],
        [ 591.6229],
        [2017.1496],
        [ 538.9758],
        [2565.3659],
        [ 781.4157],
        [1142.1742],
        [ 899.1645],
        [ 869.7175],
        [1123.9416],
        [ 685.3202],
        [3346.2383],
        [ 880.2026],
        [ 934.6587],
        [2686.8310],
        [ 513.1962],
        [ 611.1597],
        [ 927.8326],
        [ 539.0755],
        [1114.6633],
        [ 831.0117],
        [ 577.2903],
        [ 648.1175],
        [2172.3487],
        [1792.3750],
        [ 621.5788],
        [1499.8698],
        [ 656.8859],
        [ 564.9236],
        [2180.9214],
        [ 542.0414],
        [1839.9509],
        [1425.2404],
        [ 524.7087],
        [2120.9421],
        [1687.7285],
        [ 942.7314],
        [1077.9476],
        [3334.1787],
        [ 643.8830],
        [ 709.3307],
        [2252.9441],
        [ 858.5840],
        [1314.5021],
        [ 813.4851],
        [ 611.5852],
        [ 936.8798],
        [ 620.9029],
        [ 908.6958],
        [ 939.6384],
        [ 520.1486],
        [2347.3509],
        [ 628.3522],
        [ 758.7669],
        [2283.5623],
        [ 668.1865],
        [ 582.3414],
        [1120.5341],
        [ 985.2656],
        [ 984.1837],
        [2437.6254],
        [ 520.9465],
        [2026.4785],
        [ 588.7838],
        [ 580.5702],
        [ 934.1767],
        [ 934.4598],
        [2405.8596],
        [ 709.4369],
        [1520.8351],
        [1091.4357],
        [3250.6835],
        [2087.0973],
        [ 648.3011],
        [1266.6151],
        [ 602.1133],
        [ 596.0355],
        [1234.7747],
        [ 507.5293],
        [1394.9391],
        [ 687.7837],
        [ 957.5473],
        [2174.1111],
        [ 559.6582],
        [1300.2068],
        [ 582.8226],
        [ 609.7300],
        [ 649.2005],
        [ 598.5269],
        [1751.1178],
        [ 615.7547],
        [1763.9063],
        [1819.0114],
        [ 557.6124],
        [2399.0870],
        [ 536.9646],
        [1550.9564],
        [2720.9256],
        [ 597.1887],
        [ 964.8038],
        [ 663.6023],
        [2922.3248],
        [ 676.7226],
        [1513.9856],
        [1387.6085],
        [ 832.0035],
        [2089.7937],
        [ 604.1362],
        [ 671.1506],
        [ 775.8986],
        [ 608.8782],
        [ 806.4957],
        [3391.0988],
        [ 597.4065],
        [ 872.3007],
        [1060.7484],
        [ 610.7971],
        [1934.1705],
        [ 743.9629],
        [ 660.0336],
        [1588.3513],
        [ 698.0533],
        [1232.3444],
        [ 652.4380],
        [ 662.6131],
        [1646.9634],
        [ 584.4934],
        [3188.5898],
        [2468.6046],
        [ 959.3640],
        [ 821.9189],
        [ 670.9528],
        [3093.4298],
        [1093.6825],
        [1674.9259],
        [ 593.9231],
        [ 543.4032],
        [1429.2994],
        [ 564.1167],
        [1432.9304],
        [ 909.4638],
        [ 589.9852],
        [1208.6507],
        [ 639.6064],
        [ 541.0197],
        [2592.6702],
        [1021.5578],
        [ 669.5383],
        [ 536.3054],
        [2172.9251],
        [ 550.4336],
        [2080.0841],
        [1127.3781],
        [ 546.5620],
        [2350.3894],
        [1207.5092],
        [ 751.5900],
        [ 617.3377],
        [ 618.7542],
        [1638.5830],
        [1916.8223],
        [ 603.0080],
        [1491.3809],
        [ 697.5562],
        [ 767.2408],
        [ 594.5356],
        [ 943.1762],
        [ 603.3564],
        [ 903.3424],
        [1001.4603],
        [ 527.2183],
        [2879.7750],
        [1288.2399],
        [ 767.8849],
        [3358.5572],
        [ 845.9072],
        [ 655.5448],
        [2338.0925],
        [ 684.6765],
        [1212.2584],
        [2875.0433],
        [ 557.6611],
        [1866.7005],
        [ 784.2721],
        [ 611.5660],
        [ 969.5132],
        [ 737.9856],
        [2102.3472],
        [ 599.6468],
        [ 858.0043],
        [2357.9807],
        [ 727.0370],
        [ 617.8692],
        [1318.1470],
        [ 816.6790],
        [1320.4295],
        [ 614.8048],
        [1110.6737],
        [ 534.5291],
        [1091.2585],
        [ 735.1251],
        [ 858.5933],
        [2132.5964],
        [ 568.8380],
        [ 671.4451],
        [1437.6242],
        [1409.4360],
        [3515.7170],
        [1596.4862],
        [ 593.5991],
        [1223.1314],
        [ 516.4841],
        [1624.6391],
        [ 569.0684],
        [2542.5362],
        [ 543.8173],
        [1855.2403],
        [2505.2757],
        [ 513.3637],
        [1171.9300],
        [1892.3770],
        [ 576.2882],
        [ 611.7061],
        [ 723.5249],
        [ 601.2239],
        [1669.0372],
        [ 664.3837],
        [1493.3002],
        [ 678.7205],
        [ 853.0281],
        [ 646.8442],
        [ 994.3523],
        [2652.7434],
        [ 530.0746],
        [ 743.7862],
        [1076.3065],
        [ 590.4911],
        [2925.5954],
        [ 870.4722],
        [1172.0217],
        [1523.0285],
        [ 892.8923],
        [1953.8374],
        [ 600.8762],
        [ 587.4263],
        [1777.2901],
        [ 516.2160],
        [2795.1982],
        [2778.1142],
        [1042.8492],
        [ 756.4914],
        [ 688.0633],
        [ 586.0163],
        [1994.6463],
        [ 665.7165],
        [ 771.3159],
        [1077.3762],
        [ 870.0831],
        [ 899.8953],
        [ 597.4493],
        [1243.9616],
        [ 510.7829],
        [1487.8181],
        [ 619.7189],
        [ 565.9371],
        [2468.8499],
        [1125.4796],
        [ 613.4775],
        [2811.7734],
        [ 984.9144],
        [1847.2704],
        [ 584.3839],
        [ 617.7824],
        [1453.2063],
        [ 578.1040],
        [1779.2640],
        [1247.4261],
        [2549.8011],
        [ 597.9339],
        [ 973.3367],
        [1701.6100],
        [ 592.7390],
        [2995.5515],
        [ 546.7532],
        [ 768.4257],
        [1415.8636],
        [ 638.5089],
        [ 995.5850],
        [2133.1445],
        [ 683.5595],
        [ 779.6932],
        [ 700.8860],
        [2250.1347],
        [ 576.3937],
        [ 610.9708],
        [ 978.2594],
        [ 543.7379],
        [1009.4905],
        [ 639.3843],
        [1458.0168],
        [1496.8203],
        [ 618.9525],
        [1636.2620],
        [ 546.3581],
        [ 821.7006],
        [3123.9790],
        [ 671.3689],
        [1483.0401],
        [2637.0442],
        [1872.8884],
        [1086.5617],
        [ 546.7033],
        [ 589.6312],
        [1739.4605],
        [ 573.2189],
        [2012.4522],
        [1538.1245],
        [ 697.3625],
        [1440.9570],
        [ 632.4866],
        [ 567.8269],
        [1514.3606],
        [ 685.8848],
        [ 613.9898],
        [ 549.6706],
        [3156.0648],
        [1103.1341],
        [ 764.6641],
        [ 930.2227],
        [ 592.4961],
        [1025.4564],
        [ 620.8810],
        [1094.3070],
        [1284.5724],
        [ 706.6437],
        [2322.6156],
        [2876.1839],
        [ 576.5568],
        [1305.8880],
        [ 751.9928],
        [ 832.4548],
        [ 634.6386],
        [2311.3483],
        [ 752.5249],
        [ 507.9425],
        [2673.3667],
        [ 740.1409],
        [1991.1895],
        [1452.1332],
        [ 610.8849],
        [1143.3563],
        [ 868.3103],
        [ 784.5225],
        [ 589.4130],
        [ 621.2883],
        [2127.0122],
        [ 972.3688],
        [ 783.6935],
        [ 528.2728],
        [2381.2137],
        [1009.8674],
        [ 611.7096],
        [1267.7642],
        [ 523.6740],
        [ 630.2887],
        [1833.6869],
        [ 530.3268],
        [1225.6646],
        [1630.2047],
        [ 633.2378],
        [3201.0521],
        [1417.6794],
        [ 508.4760],
        [1275.6195],
        [1246.3732],
        [2240.9151],
        [2444.4404],
        [ 527.7861],
        [1865.2760],
        [ 554.6048],
        [ 598.4146],
        [2029.5473],
        [ 578.4476],
        [1627.8691],
        [ 632.3508],
        [ 783.9407],
        [1874.0320],
        [ 633.9033],
        [1119.3754],
        [ 876.7480],
        [2598.3523],
        [ 515.3287],
        [ 597.1479],
        [ 705.1579],
        [ 687.3471],
        [ 820.8879],
        [2064.5951],
        [ 630.4436],
        [1372.3521],
        [ 691.8257],
        [ 939.6402],
        [1129.8398],
        [ 811.5929],
        [3441.9420]], device='cuda:0', dtype=torch.float64), tensor([[ 708.0655],
        [2031.4019],
        [2915.7359],
        [1585.8275],
        [ 647.0661],
        [ 883.4503],
        [2959.8029],
        [ 957.5514],
        [1012.1716],
        [5363.2380],
        [1733.4562],
        [1114.0342],
        [ 972.2719],
        [2811.7752],
        [3242.9229],
        [ 668.3336],
        [3283.3609],
        [ 650.7103],
        [ 634.4424],
        [2894.3986],
        [5118.3414],
        [ 775.4529],
        [1618.4367],
        [1356.6144],
        [1027.1797],
        [ 686.3990],
        [ 856.1055],
        [3105.1109],
        [1285.8402],
        [ 767.4203],
        [1057.2506],
        [1620.7397],
        [4020.9401],
        [ 622.5807],
        [1166.1465],
        [2065.1232],
        [4448.6041],
        [ 749.1892],
        [ 751.8039],
        [1813.8747],
        [1645.8845],
        [ 726.6516],
        [ 673.7424],
        [ 902.4678],
        [ 788.9320],
        [ 688.4275],
        [1212.4894],
        [4488.5844],
        [ 660.9054],
        [ 767.9148],
        [4554.5143],
        [1363.4143],
        [ 701.8773],
        [2763.7875],
        [1850.0250],
        [1063.6069],
        [ 765.2583],
        [3865.8456],
        [2225.2882],
        [ 882.0873],
        [ 702.3124],
        [4257.2211],
        [2451.8363],
        [ 918.3025],
        [ 727.1627],
        [3831.3851],
        [2625.6788],
        [1265.7433],
        [ 708.6436],
        [5302.0111],
        [1748.5566],
        [ 670.9112],
        [ 821.3871],
        [1499.4303],
        [1168.4045],
        [ 640.3162],
        [ 724.0030],
        [ 998.5122],
        [4090.6895],
        [1655.6224],
        [ 847.9758],
        [ 766.0677],
        [1551.9579],
        [3524.5875],
        [2041.9342],
        [ 724.2890],
        [ 812.3924],
        [2155.7848],
        [3957.3355],
        [ 873.6093],
        [ 867.9827],
        [1760.4172],
        [3534.9293],
        [ 730.5734],
        [1090.8339],
        [2586.8320],
        [1558.6479],
        [ 684.2619],
        [1219.1772],
        [3219.7315],
        [ 946.5611],
        [ 639.5795],
        [1021.7096],
        [2259.1464],
        [4324.2896],
        [1114.5531],
        [1448.1223],
        [1896.8557],
        [3022.1099],
        [1246.3499],
        [ 644.8563],
        [2550.5560],
        [ 674.6806],
        [4118.3637],
        [2658.7553],
        [ 682.2521],
        [1064.6567],
        [4783.7650],
        [1877.5245],
        [1802.6775],
        [ 677.3773],
        [1304.4498],
        [2924.9520],
        [1089.2295],
        [ 733.6874],
        [1203.1464],
        [2057.4076],
        [ 994.9936],
        [ 872.2641],
        [ 645.7052],
        [ 917.4017],
        [2905.7603],
        [1840.6578],
        [ 755.4286],
        [1412.0328],
        [2711.7898],
        [2390.7195],
        [1193.1971],
        [ 765.9485],
        [2870.4914],
        [5198.6652],
        [ 941.0297],
        [1233.7580],
        [1615.9908],
        [ 925.7558],
        [5627.1290],
        [1642.2272],
        [1293.2367],
        [ 646.3938],
        [3436.3289],
        [2972.0917],
        [ 640.0082],
        [ 755.0289],
        [1300.0064],
        [1612.9885],
        [1078.7345],
        [ 713.3283],
        [1118.1143],
        [3387.8641],
        [ 977.9293],
        [ 815.7947],
        [4867.4515],
        [2132.5891],
        [ 689.4622],
        [ 626.9148],
        [4140.1082],
        [2092.2212],
        [1177.1525],
        [ 687.4571],
        [ 832.3273],
        [4700.9883],
        [1243.3752],
        [ 760.3269],
        [2004.1576],
        [1093.7835],
        [ 778.0757],
        [2584.0050],
        [ 702.5588],
        [1000.2461],
        [1704.3218],
        [ 716.2670],
        [ 687.1467],
        [1207.0030],
        [3985.9369],
        [3827.7864],
        [ 663.8015],
        [ 957.0802],
        [2232.6704],
        [3786.5503],
        [ 761.8087],
        [ 905.3534],
        [2130.8954],
        [5083.5696],
        [ 680.8066],
        [ 676.4734],
        [1684.9204],
        [3444.6372],
        [ 646.4265],
        [1553.2567],
        [2243.8210],
        [ 930.0009],
        [ 784.1575],
        [1426.0829],
        [3787.2932],
        [1459.1041],
        [ 800.9905],
        [ 635.6337],
        [1175.6453],
        [ 805.7763],
        [2270.7483],
        [2340.6978],
        [ 883.3693],
        [ 746.6593],
        [ 850.4259],
        [3570.0208],
        [1622.9349],
        [ 771.9403],
        [3634.1403],
        [2724.5108],
        [1004.7033],
        [ 761.3029],
        [4540.3632],
        [2035.1544],
        [ 726.2817],
        [ 635.6503],
        [1152.5474],
        [2691.9955],
        [1164.2300],
        [ 674.1085],
        [1656.2020],
        [3426.0804],
        [1284.0179],
        [1256.2465],
        [3064.6533],
        [2624.3751],
        [ 646.7067],
        [1247.4290],
        [4849.4607],
        [2124.9857],
        [1338.5581],
        [4606.9524],
        [1036.5241],
        [1823.5577],
        [1821.6547],
        [3779.8628],
        [ 686.6350],
        [ 662.7770],
        [2318.9746],
        [ 998.2448],
        [ 736.7611],
        [ 835.5941],
        [1669.4224],
        [1186.5111],
        [ 665.0936],
        [1047.2330],
        [2743.4763],
        [ 978.6121],
        [1699.7394],
        [4752.1137],
        [1049.8234],
        [ 636.0765],
        [3012.3595],
        [2915.6867],
        [ 855.9663],
        [1367.1386],
        [2277.4864],
        [1718.0094],
        [ 756.8693],
        [ 854.8384],
        [2374.8687],
        [ 739.6287],
        [ 612.6947],
        [3681.7500],
        [ 862.5568],
        [ 777.2723],
        [1324.5916],
        [2189.2094],
        [1359.5483],
        [ 742.1916],
        [1665.8614],
        [3207.9614],
        [ 611.8345],
        [ 706.6336],
        [3320.6798],
        [1342.3447],
        [1875.2872],
        [ 759.0634],
        [5431.6238],
        [1286.3702],
        [ 799.3560],
        [ 764.1036],
        [2059.6953],
        [5009.2629],
        [1268.8187],
        [ 708.7846],
        [ 995.5688],
        [1927.2074],
        [1333.1210],
        [ 621.0265],
        [4353.1556],
        [2222.3598],
        [ 733.0112],
        [ 748.1840],
        [4423.4932],
        [ 882.2105],
        [2123.1532],
        [3795.4074],
        [ 710.2952],
        [ 764.5678],
        [2392.4967],
        [3961.2823],
        [ 722.3207],
        [1297.5015],
        [3715.5421],
        [ 725.5634],
        [ 689.4048],
        [ 865.9873],
        [1468.0298],
        [2211.7193],
        [ 726.1421],
        [ 675.4848],
        [1301.7884],
        [1612.1952],
        [ 780.8007],
        [1361.9652],
        [4269.3705],
        [1053.7400],
        [ 754.8662],
        [1880.1715],
        [2216.3266],
        [3424.7452],
        [ 646.9441],
        [ 675.6681],
        [1644.2829],
        [4876.6589],
        [ 663.0191],
        [1887.9690],
        [ 676.1374],
        [ 715.7019],
        [4784.1688],
        [3090.1657],
        [ 843.1198],
        [ 917.3561],
        [3556.5855],
        [3509.0323],
        [1640.5341],
        [ 722.7457],
        [ 779.3504],
        [1898.0279],
        [ 811.6367],
        [ 801.4048],
        [2060.3242],
        [2185.2106],
        [1040.2105],
        [1356.5650],
        [4488.1035],
        [2795.2680],
        [ 608.0845],
        [ 875.6210],
        [3606.2905],
        [2974.1450],
        [1201.6144],
        [ 710.6251],
        [1494.7701],
        [2136.5777],
        [1105.4418],
        [ 630.3633],
        [ 871.2625],
        [ 941.8266],
        [2932.0899],
        [1446.7776],
        [ 708.6042],
        [1022.4334],
        [2327.3865],
        [1247.9371],
        [ 730.1267],
        [ 616.2972],
        [2571.7520],
        [3609.2075],
        [ 826.7756],
        [2535.2188],
        [1462.3726],
        [4485.3251],
        [ 818.8516],
        [3117.7853],
        [ 632.9695],
        [ 864.2048],
        [2972.7513],
        [1928.1324],
        [ 906.2431],
        [1171.9783],
        [5346.8981],
        [2824.1755],
        [ 971.6388],
        [ 623.7461],
        [ 805.2072],
        [2443.8739],
        [1453.7836],
        [ 740.2702],
        [1824.2146],
        [1135.4149],
        [1803.0505],
        [1392.1816],
        [ 785.8709],
        [ 838.7840],
        [3488.8111],
        [1211.0791],
        [ 744.1307],
        [1887.4130],
        [1301.3453],
        [5248.9445],
        [ 744.6543],
        [ 628.8833],
        [2838.1490],
        [3040.0112],
        [ 715.5727],
        [1078.8042],
        [4636.7701],
        [ 914.5676],
        [ 729.1606],
        [ 785.0714],
        [1278.4808],
        [1997.6903],
        [ 750.2331],
        [ 772.9843],
        [2140.2483],
        [4215.1169],
        [ 716.2540],
        [1642.8824],
        [1613.3308],
        [3913.9169],
        [ 636.8466],
        [2502.8116],
        [ 719.4238],
        [ 759.3342],
        [4041.6969],
        [2409.6859],
        [ 745.2732],
        [ 718.2469],
        [4328.6849],
        [1595.1748],
        [ 949.0623],
        [ 768.5658],
        [2449.7193],
        [3761.0840],
        [1342.6430],
        [ 678.6712],
        [ 728.6904],
        [4450.1508],
        [1395.2505],
        [ 744.1676],
        [1129.3472],
        [1607.1674],
        [ 769.0443],
        [ 849.0752],
        [1951.4720],
        [1923.6701],
        [ 636.5671],
        [ 681.5505],
        [5300.9286],
        [2245.0528],
        [1905.4531],
        [ 653.5231],
        [3524.6702],
        [ 883.9244],
        [2808.0270],
        [3136.6384],
        [ 839.9685],
        [ 690.3895],
        [1787.6276],
        [4672.5817],
        [ 709.3822],
        [ 765.0713],
        [1750.6937],
        [1909.1161],
        [ 784.0455],
        [1431.2301],
        [3014.9079],
        [ 731.9453],
        [ 828.1950],
        [ 619.6844],
        [2492.5609],
        [3137.1660],
        [1065.0404],
        [1149.5582],
        [2063.0376],
        [4368.6517],
        [1261.0064],
        [1063.5600],
        [2096.1767],
        [ 863.9773],
        [ 639.3953],
        [1087.1081],
        [2777.2357],
        [1353.4618],
        [ 710.0076],
        [2333.8093],
        [1041.9567],
        [ 731.5389],
        [1269.4959],
        [3231.7918],
        [1105.8107],
        [ 718.4656],
        [1592.7569],
        [1775.3535],
        [2049.6255],
        [ 987.6104],
        [4983.6183],
        [2650.2769],
        [ 628.0734],
        [ 772.7127],
        [3778.9646]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION:
[tensor([[10.3211],
        [ 9.5458],
        [10.6896],
        [11.7591],
        [17.0506],
        [10.8370],
        [17.1895],
        [12.4660],
        [10.1295],
        [12.0618]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[12.0422],
        [ 9.0824],
        [ 9.5887],
        [14.2890],
        [ 9.6011],
        [11.9049],
        [12.7369],
        [15.5380],
        [14.1325],
        [18.4178]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.5404],
        [ 9.2371],
        [14.6668],
        [10.5828],
        [19.3144],
        [12.0522],
        [ 9.6412],
        [15.1745],
        [10.5741],
        [15.7049]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[235.1143],
        [218.1515],
        [243.1768],
        [266.5778],
        [382.3530],
        [246.4024],
        [385.3924],
        [282.0436],
        [230.9215],
        [273.1994]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 671.1506],
        [ 508.4760],
        [ 536.3054],
        [ 794.6377],
        [ 536.9843],
        [ 663.6023],
        [ 709.3307],
        [ 863.2797],
        [ 786.0336],
        [1021.5578]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 771.9403],
        [ 619.6844],
        [ 978.6121],
        [ 708.6436],
        [1285.8402],
        [ 805.7763],
        [ 646.3938],
        [1012.1716],
        [ 708.0655],
        [1047.2330]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[10.3207],
        [ 9.5459],
        [10.6883],
        [11.7592],
        [17.0498],
        [10.8360],
        [17.1880],
        [12.4646],
        [10.1284],
        [12.0622]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[12.0409],
        [ 9.0824],
        [ 9.5888],
        [14.2862],
        [ 9.6010],
        [11.9008],
        [12.7327],
        [15.5308],
        [14.1298],
        [18.4166]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.5352],
        [ 9.2370],
        [14.6573],
        [10.5814],
        [19.3095],
        [12.0505],
        [ 9.6410],
        [15.1692],
        [10.5734],
        [15.7043]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[235.1067],
        [218.1540],
        [243.1491],
        [266.5800],
        [382.3360],
        [246.3795],
        [385.3595],
        [282.0139],
        [230.8990],
        [273.2084]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 671.0815],
        [ 508.4782],
        [ 536.3090],
        [ 794.4799],
        [ 536.9793],
        [ 663.3772],
        [ 709.1024],
        [ 862.8840],
        [ 785.8855],
        [1021.4902]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 771.5984],
        [ 619.6765],
        [ 977.9853],
        [ 708.5457],
        [1285.5135],
        [ 805.6594],
        [ 646.3802],
        [1011.8229],
        [ 708.0183],
        [1047.1958]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[10.3204],
        [ 9.5460],
        [10.6871],
        [11.7593],
        [17.0490],
        [10.8349],
        [17.1865],
        [12.4633],
        [10.1274],
        [12.0626]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[12.0397],
        [ 9.0824],
        [ 9.5888],
        [14.2833],
        [ 9.6009],
        [11.8967],
        [12.7286],
        [15.5236],
        [14.1271],
        [18.4153]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.5300],
        [ 9.2369],
        [14.6478],
        [10.5799],
        [19.3045],
        [12.0487],
        [ 9.6408],
        [15.1639],
        [10.5727],
        [15.7037]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[235.0991],
        [218.1566],
        [243.1215],
        [266.5822],
        [382.3189],
        [246.3566],
        [385.3265],
        [281.9841],
        [230.8766],
        [273.2174]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 671.0125],
        [ 508.4804],
        [ 536.3125],
        [ 794.3222],
        [ 536.9742],
        [ 663.1523],
        [ 708.8743],
        [ 862.4882],
        [ 785.7376],
        [1021.4226]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 771.2568],
        [ 619.6686],
        [ 977.3589],
        [ 708.4478],
        [1285.1868],
        [ 805.5425],
        [ 646.3666],
        [1011.4740],
        [ 707.9710],
        [1047.1585]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[10.3190],
        [ 9.5465],
        [10.6820],
        [11.7597],
        [17.0459],
        [10.8307],
        [17.1805],
        [12.4578],
        [10.1233],
        [12.0642]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[12.0347],
        [ 9.0826],
        [ 9.5891],
        [14.2718],
        [ 9.6005],
        [11.8803],
        [12.7120],
        [15.4948],
        [14.1163],
        [18.4104]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.5094],
        [ 9.2364],
        [14.6100],
        [10.5740],
        [19.2848],
        [12.0416],
        [ 9.6399],
        [15.1428],
        [10.5698],
        [15.7015]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[235.0686],
        [218.1666],
        [243.0110],
        [266.5908],
        [382.2507],
        [246.2651],
        [385.1947],
        [281.8651],
        [230.7869],
        [273.2533]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 670.7369],
        [ 508.4891],
        [ 536.3266],
        [ 793.6918],
        [ 536.9541],
        [ 662.2545],
        [ 707.9634],
        [ 860.9080],
        [ 785.1461],
        [1021.1522]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 769.8935],
        [ 619.6372],
        [ 974.8592],
        [ 708.0568],
        [1283.8809],
        [ 805.0749],
        [ 646.3123],
        [1010.0801],
        [ 707.7821],
        [1047.0096]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[10.3134],
        [ 9.5483],
        [10.6619],
        [11.7612],
        [17.0334],
        [10.8141],
        [17.1563],
        [12.4361],
        [10.1070],
        [12.0708]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[12.0147],
        [ 9.0833],
        [ 9.5901],
        [14.2261],
        [ 9.5991],
        [11.8155],
        [12.6462],
        [15.3806],
        [14.0734],
        [18.3907]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4277],
        [ 9.2345],
        [14.4602],
        [10.5505],
        [19.2059],
        [12.0133],
        [ 9.6366],
        [15.0588],
        [10.5584],
        [15.6925]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[234.9464],
        [218.2069],
        [242.5707],
        [266.6239],
        [381.9776],
        [245.9002],
        [384.6666],
        [281.3901],
        [230.4301],
        [273.3973]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 669.6394],
        [ 508.5252],
        [ 536.3829],
        [ 791.1800],
        [ 536.8737],
        [ 658.6922],
        [ 704.3456],
        [ 854.6294],
        [ 782.7887],
        [1020.0713]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 764.4928],
        [ 619.5118],
        [ 964.9535],
        [ 706.5027],
        [1278.6694],
        [ 803.2048],
        [ 646.0952],
        [1004.5257],
        [ 707.0277],
        [1046.4141]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[10.2909],
        [ 9.5558],
        [10.5825],
        [11.7664],
        [16.9835],
        [10.7481],
        [17.0593],
        [12.3500],
        [10.0432],
        [12.0972]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.9363],
        [ 9.0862],
        [ 9.5942],
        [14.0461],
        [ 9.5933],
        [11.5646],
        [12.3903],
        [14.9358],
        [13.9043],
        [18.3123]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.1136],
        [ 9.2270],
        [13.8831],
        [10.4588],
        [18.8936],
        [11.9003],
        [ 9.6236],
        [14.7279],
        [10.5131],
        [15.6565]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[234.4547],
        [218.3690],
        [240.8336],
        [266.7364],
        [380.8848],
        [244.4576],
        [382.5431],
        [279.5051],
        [229.0342],
        [273.9751]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 665.3305],
        [ 508.6862],
        [ 536.6084],
        [ 781.2887],
        [ 536.5568],
        [ 644.9008],
        [ 690.2846],
        [ 830.1861],
        [ 773.4903],
        [1015.7622]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 743.7310],
        [ 619.0183],
        [ 926.8077],
        [ 700.4457],
        [1258.0238],
        [ 795.7346],
        [ 645.2326],
        [ 982.6539],
        [ 704.0298],
        [1044.0363]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[10.1990],
        [ 9.5860],
        [10.2832],
        [11.7722],
        [16.7831],
        [10.4968],
        [16.6630],
        [12.0164],
        [ 9.8104],
        [12.2042]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.6471],
        [ 9.1028],
        [ 9.6107],
        [13.3724],
        [ 9.5715],
        [10.6909],
        [11.4838],
        [13.3479],
        [13.2661],
        [18.0028]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0680],
        [ 9.1991],
        [11.9240],
        [10.1308],
        [17.6932],
        [11.4530],
        [ 9.5728],
        [13.4897],
        [10.3367],
        [15.5136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[232.4428],
        [219.0300],
        [234.2854],
        [266.8638],
        [376.5015],
        [238.9587],
        [373.8737],
        [272.2071],
        [223.9408],
        [276.3156]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[649.4348],
        [509.5977],
        [537.5148],
        [744.2603],
        [535.3614],
        [596.8809],
        [640.4630],
        [742.9101],
        [738.4145],
        [998.7518]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 674.6113],
        [ 617.1719],
        [ 797.3005],
        [ 678.7632],
        [1178.6711],
        [ 766.1666],
        [ 641.8735],
        [ 900.7984],
        [ 692.3706],
        [1034.5913]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.8143],
        [ 9.7162],
        [ 9.4044],
        [11.5638],
        [15.9754],
        [ 9.6906],
        [14.9748],
        [10.8628],
        [ 9.2173],
        [12.6514]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.9331],
        [ 9.2449],
        [ 9.6779],
        [11.4666],
        [ 9.5063],
        [ 9.0646],
        [ 9.5550],
        [ 9.7566],
        [11.3437],
        [16.8307]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.6918],
        [ 9.1174],
        [ 9.1067],
        [ 9.4350],
        [13.7030],
        [ 9.8972],
        [ 9.3951],
        [ 9.9942],
        [ 9.7257],
        [14.9583]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[224.0268],
        [221.8786],
        [215.0580],
        [262.3046],
        [358.8295],
        [221.3199],
        [336.9347],
        [246.9661],
        [210.9631],
        [286.1006]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[610.1912],
        [517.4106],
        [541.2065],
        [639.5161],
        [531.7731],
        [507.4983],
        [534.4515],
        [545.5335],
        [632.7622],
        [934.3289]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[649.7393],
        [611.7706],
        [611.0650],
        [632.7643],
        [914.9001],
        [663.3216],
        [630.1255],
        [669.7317],
        [651.9817],
        [997.8801]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.1596],
        [ 9.1942],
        [ 9.1569],
        [ 9.1895],
        [12.9101],
        [ 9.5011],
        [ 9.6192],
        [ 9.4881],
        [10.3381],
        [14.1443]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.0722],
        [ 9.7652],
        [ 9.9979],
        [11.6364],
        [ 9.7438],
        [12.1508],
        [14.2969],
        [13.1017],
        [11.8270],
        [13.6783]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[15.0003],
        [ 9.0582],
        [15.2248],
        [11.0771],
        [10.7813],
        [13.9332],
        [ 9.1702],
        [15.9249],
        [ 9.5031],
        [13.1653]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[209.7011],
        [210.4586],
        [209.6433],
        [210.3550],
        [291.7618],
        [217.1736],
        [219.7574],
        [216.8880],
        [235.4873],
        [318.7654]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[617.8371],
        [546.0062],
        [558.7919],
        [648.8480],
        [544.8313],
        [677.1207],
        [795.0677],
        [729.3797],
        [659.3240],
        [761.0717]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[1000.6592],
        [ 607.8575],
        [1015.4961],
        [ 741.3169],
        [ 721.7614],
        [ 930.1186],
        [ 615.2622],
        [1061.7775],
        [ 637.2649],
        [ 879.3582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.4463],
        [ 9.3316],
        [ 9.0721],
        [10.4389],
        [14.5129],
        [ 9.0603],
        [11.8338],
        [10.0820],
        [ 9.2552],
        [13.3439]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.9563],
        [ 9.4493],
        [ 9.8237],
        [10.9384],
        [ 9.5620],
        [ 9.9943],
        [10.3851],
        [ 9.8709],
        [10.7140],
        [15.2009]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4947],
        [ 9.0789],
        [10.7783],
        [ 9.5740],
        [10.2264],
        [ 9.2083],
        [ 9.1608],
        [ 9.4895],
        [ 9.1358],
        [14.0719]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[215.9736],
        [213.4641],
        [207.7873],
        [237.6914],
        [326.8291],
        [207.5288],
        [268.2109],
        [229.8832],
        [211.7936],
        [301.2531]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[611.4663],
        [528.6446],
        [549.2183],
        [610.4826],
        [534.8355],
        [558.5947],
        [580.0732],
        [551.8154],
        [598.1532],
        [844.7541]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[768.9207],
        [609.2272],
        [721.5668],
        [641.9537],
        [685.0812],
        [617.7767],
        [614.6419],
        [636.3677],
        [612.9896],
        [939.2874]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.3662],
        [ 9.1972],
        [ 9.0465],
        [ 9.7808],
        [12.8028],
        [ 9.1989],
        [11.2273],
        [13.0326],
        [ 9.7761],
        [13.9557]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.8373],
        [ 9.5034],
        [ 9.9109],
        [10.8652],
        [ 9.9209],
        [11.3046],
        [12.1576],
        [11.8542],
        [10.9537],
        [13.8437]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9712],
        [ 9.0923],
        [11.5283],
        [ 9.3690],
        [ 9.8562],
        [10.3471],
        [ 9.1625],
        [15.1612],
        [ 9.1444],
        [13.1598]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[214.2207],
        [210.5232],
        [207.2262],
        [223.2932],
        [289.4137],
        [210.5615],
        [254.9422],
        [294.4408],
        [223.1896],
        [314.6393]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[604.9265],
        [531.6183],
        [554.0102],
        [606.4625],
        [554.5622],
        [630.6122],
        [677.4911],
        [660.8161],
        [611.3237],
        [770.1649]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 668.2105],
        [ 610.1093],
        [ 771.1429],
        [ 628.4011],
        [ 660.6117],
        [ 693.0601],
        [ 614.7534],
        [1011.2911],
        [ 613.5541],
        [ 878.9905]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5196],
        [ 9.2062],
        [ 9.0705],
        [10.1901],
        [12.4876],
        [ 9.0956],
        [11.8205],
        [12.6959],
        [ 9.5483],
        [13.8860]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.0674],
        [ 9.4140],
        [ 9.8697],
        [11.0351],
        [10.1880],
        [10.3535],
        [10.9802],
        [10.4619],
        [11.2038],
        [13.8065]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.1092],
        [ 9.1377],
        [ 9.6388],
        [ 9.0771],
        [ 9.5623],
        [ 9.1885],
        [ 9.1633],
        [10.6759],
        [ 9.0685],
        [13.0143]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.5785],
        [210.7201],
        [207.7509],
        [232.2476],
        [282.5169],
        [208.3007],
        [267.9218],
        [287.0746],
        [218.2069],
        [313.1139]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[617.5732],
        [526.7040],
        [551.7470],
        [615.8005],
        [569.2439],
        [578.3402],
        [612.7829],
        [584.2943],
        [625.0702],
        [768.1164]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[611.2277],
        [613.1105],
        [646.2405],
        [609.1086],
        [641.1828],
        [616.4732],
        [614.8054],
        [714.7949],
        [608.5405],
        [869.3718]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[10.1070],
        [ 9.2466],
        [ 9.9728],
        [11.1250],
        [ 9.6999],
        [ 9.5606],
        [12.7709],
        [10.5000],
        [ 9.3831],
        [14.2611]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.0210],
        [ 9.3672],
        [ 9.9872],
        [12.0481],
        [11.2078],
        [ 9.1428],
        [ 9.9652],
        [ 9.3880],
        [12.7846],
        [12.3278]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.5145],
        [ 9.2791],
        [10.9141],
        [ 9.0991],
        [ 9.0716],
        [ 9.1287],
        [ 9.1657],
        [10.7668],
        [ 9.2082],
        [11.4289]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[230.4293],
        [211.6042],
        [227.4938],
        [252.7026],
        [221.5227],
        [218.4746],
        [288.7162],
        [239.0297],
        [214.5917],
        [321.3203]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[615.0249],
        [524.1279],
        [558.2046],
        [671.4746],
        [625.2919],
        [511.8000],
        [556.9979],
        [525.2724],
        [711.9533],
        [686.8464]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[638.0230],
        [622.4618],
        [730.5384],
        [610.5613],
        [608.7433],
        [612.5205],
        [614.9606],
        [720.8033],
        [617.7754],
        [764.5698]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.7522],
        [ 9.2225],
        [ 9.2909],
        [10.5891],
        [11.1265],
        [ 9.2038],
        [12.3450],
        [11.6545],
        [ 9.4740],
        [14.0688]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.2646],
        [ 9.3917],
        [ 9.9160],
        [11.4402],
        [10.8028],
        [ 9.7129],
        [10.4507],
        [ 9.8125],
        [11.6955],
        [13.1320]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0990],
        [ 9.1869],
        [ 9.0865],
        [ 9.0399],
        [ 9.2938],
        [ 9.0679],
        [ 9.1607],
        [ 9.0814],
        [ 9.1029],
        [12.3147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[222.6668],
        [211.0771],
        [212.5735],
        [240.9782],
        [252.7355],
        [210.6684],
        [279.3967],
        [264.2885],
        [216.5798],
        [317.1130]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[628.4149],
        [525.4764],
        [554.2915],
        [638.0620],
        [603.0310],
        [543.1301],
        [583.6798],
        [548.6060],
        [652.0973],
        [731.0494]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[610.5569],
        [616.3666],
        [609.7306],
        [606.6478],
        [623.4325],
        [608.5006],
        [614.6362],
        [609.3904],
        [610.8133],
        [823.1263]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.7459],
        [ 9.2242],
        [ 9.3516],
        [10.1989],
        [ 9.3552],
        [ 9.2410],
        [11.8123],
        [11.1366],
        [ 9.7123],
        [14.5477]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4355],
        [ 9.4386],
        [ 9.9573],
        [11.6154],
        [11.1405],
        [ 9.6350],
        [10.5771],
        [10.1017],
        [11.7935],
        [11.6986]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.0782],
        [ 9.2092],
        [ 9.3808],
        [ 9.0732],
        [ 9.2819],
        [ 9.0831],
        [ 9.1121],
        [ 9.0592],
        [ 9.1014],
        [10.8334]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[222.5284],
        [211.1147],
        [213.9014],
        [232.4417],
        [213.9808],
        [211.4825],
        [267.7411],
        [252.9570],
        [221.7950],
        [327.5915]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[637.8039],
        [528.0529],
        [556.5623],
        [647.6946],
        [621.5923],
        [538.8505],
        [590.6258],
        [564.4971],
        [657.4795],
        [652.2667]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[609.1772],
        [617.8409],
        [629.1801],
        [608.8509],
        [622.6449],
        [609.5059],
        [611.4215],
        [607.9244],
        [610.7103],
        [725.2044]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6209],
        [ 9.2866],
        [ 9.3086],
        [ 9.6895],
        [ 9.2425],
        [ 9.2888],
        [11.3471],
        [10.4471],
        [ 9.9566],
        [14.1827]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4768],
        [ 9.4323],
        [10.0883],
        [11.5102],
        [11.1029],
        [ 9.6783],
        [10.7561],
        [10.3478],
        [11.5943],
        [10.7703]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.1445],
        [9.1590],
        [9.2644],
        [9.1443],
        [9.5034],
        [9.1212],
        [9.0929],
        [9.0650],
        [9.1212],
        [9.4840]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[219.7953],
        [212.4800],
        [212.9614],
        [221.2948],
        [211.5154],
        [212.5284],
        [257.5635],
        [237.8721],
        [227.1403],
        [319.6048]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[640.0767],
        [527.7097],
        [563.7605],
        [641.9129],
        [619.5263],
        [541.2295],
        [600.4630],
        [578.0249],
        [646.5348],
        [601.2451]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[613.5597],
        [614.5211],
        [621.4875],
        [613.5489],
        [637.2889],
        [612.0206],
        [610.1491],
        [608.3038],
        [612.0210],
        [636.0030]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.4311],
        [ 9.8632],
        [ 9.3511],
        [ 9.0680],
        [10.8787],
        [ 9.5606],
        [10.5265],
        [ 9.3343],
        [10.5511],
        [10.1010]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.5274],
        [ 9.4381],
        [10.5721],
        [11.3427],
        [11.0313],
        [ 9.7340],
        [11.1056],
        [11.0647],
        [11.1664],
        [11.5180]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9376],
        [ 9.1026],
        [ 9.1984],
        [ 9.4485],
        [11.5555],
        [ 9.2236],
        [ 9.0944],
        [ 9.2670],
        [ 9.1397],
        [18.0384]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[215.6422],
        [225.0957],
        [213.8919],
        [207.6983],
        [247.3141],
        [218.4760],
        [239.6091],
        [213.5243],
        [240.1472],
        [230.2994]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[642.8570],
        [528.0250],
        [590.3547],
        [632.7058],
        [615.5886],
        [544.2887],
        [619.6766],
        [617.4285],
        [623.0184],
        [642.3418]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 665.9893],
        [ 610.7949],
        [ 617.1267],
        [ 633.6597],
        [ 772.9384],
        [ 618.7916],
        [ 610.2502],
        [ 621.6580],
        [ 613.2429],
        [1201.4910]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5718],
        [ 9.3789],
        [ 9.3184],
        [ 9.4395],
        [ 9.3680],
        [ 9.3438],
        [11.0962],
        [10.1068],
        [10.0921],
        [12.9438]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.5014],
        [ 9.4336],
        [10.2008],
        [11.4692],
        [11.1014],
        [ 9.6860],
        [10.8675],
        [10.5123],
        [11.4849],
        [10.5123]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.2476],
        [9.1419],
        [9.2409],
        [9.1957],
        [9.7543],
        [9.1396],
        [9.0865],
        [9.0885],
        [9.1253],
        [9.2586]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[218.7202],
        [214.4995],
        [213.1754],
        [215.8248],
        [214.2613],
        [213.7315],
        [252.0736],
        [230.4256],
        [230.1032],
        [292.4988]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[641.4279],
        [527.7824],
        [569.9476],
        [639.6562],
        [619.4431],
        [541.6519],
        [606.5862],
        [587.0664],
        [640.5213],
        [587.0641]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[620.3808],
        [613.3920],
        [619.9347],
        [616.9467],
        [653.8731],
        [613.2386],
        [609.7309],
        [609.8586],
        [612.2898],
        [621.1073]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5283],
        [ 9.5655],
        [ 9.2591],
        [ 9.2481],
        [ 9.2466],
        [ 9.3894],
        [10.7132],
        [ 9.6642],
        [10.0220],
        [10.6059]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.3934],
        [ 9.4337],
        [10.3888],
        [11.3101],
        [11.2627],
        [ 9.7389],
        [11.0195],
        [10.7362],
        [11.2427],
        [10.5369]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.5080],
        [9.1156],
        [9.0442],
        [9.2376],
        [9.3727],
        [9.1824],
        [9.0799],
        [9.3538],
        [9.1057],
        [9.2959]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.7679],
        [218.5830],
        [211.8793],
        [211.6382],
        [211.6057],
        [214.7297],
        [243.6937],
        [220.7415],
        [228.5712],
        [241.3450]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[635.4908],
        [527.7837],
        [580.2778],
        [630.9140],
        [628.3084],
        [544.5573],
        [614.9405],
        [599.3724],
        [627.2121],
        [588.4192]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[637.5893],
        [611.6518],
        [606.9294],
        [619.7169],
        [628.6464],
        [616.0674],
        [609.2900],
        [627.3994],
        [610.9990],
        [623.5720]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5896],
        [ 9.5507],
        [ 9.3100],
        [ 9.3887],
        [ 9.3478],
        [ 9.3866],
        [10.8048],
        [ 9.7666],
        [ 9.8188],
        [11.3346]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.3799],
        [ 9.4355],
        [10.4462],
        [11.3195],
        [11.3962],
        [ 9.7357],
        [11.0800],
        [10.6724],
        [11.2780],
        [10.8291]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.2351],
        [9.1357],
        [9.0452],
        [9.1482],
        [9.1106],
        [9.1383],
        [9.0849],
        [9.3079],
        [9.0901],
        [9.0898]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[219.1098],
        [218.2586],
        [212.9920],
        [214.7132],
        [213.8197],
        [214.6675],
        [245.6985],
        [222.9822],
        [224.1247],
        [257.2901]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[634.7502],
        [527.8868],
        [583.4326],
        [631.4307],
        [635.6473],
        [544.3843],
        [618.2699],
        [595.8640],
        [629.1473],
        [604.4764]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[619.5542],
        [612.9792],
        [606.9978],
        [613.8072],
        [611.3179],
        [613.1511],
        [609.6235],
        [624.3607],
        [609.9688],
        [609.9464]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6699],
        [ 9.5871],
        [ 9.3699],
        [ 9.5589],
        [ 9.6473],
        [ 9.3990],
        [10.8758],
        [ 9.7506],
        [ 9.6673],
        [11.3603]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.3897],
        [ 9.4353],
        [10.4619],
        [11.3603],
        [11.4225],
        [ 9.7280],
        [11.1985],
        [10.6134],
        [11.3592],
        [11.1164]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0892],
        [9.1616],
        [9.0865],
        [9.0925],
        [9.0765],
        [9.1104],
        [9.0902],
        [9.1809],
        [9.0903],
        [9.0450]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[220.8672],
        [219.0545],
        [214.3016],
        [218.4384],
        [220.3713],
        [214.9388],
        [247.2503],
        [222.6325],
        [220.8086],
        [257.8515]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[635.2888],
        [527.8748],
        [584.2985],
        [633.6711],
        [637.0926],
        [543.9625],
        [624.7814],
        [592.6199],
        [633.6144],
        [620.2673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[609.9092],
        [614.6932],
        [609.7291],
        [610.1279],
        [609.0660],
        [611.3109],
        [609.9706],
        [615.9656],
        [609.9803],
        [606.9848]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.7029],
        [ 9.7040],
        [ 9.4343],
        [ 9.6360],
        [ 9.7883],
        [ 9.3929],
        [10.7746],
        [ 9.6325],
        [ 9.6343],
        [10.8335]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4036],
        [ 9.4406],
        [10.5469],
        [11.4032],
        [11.4054],
        [ 9.7816],
        [11.3589],
        [10.7073],
        [11.4232],
        [11.2753]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0706],
        [9.1751],
        [9.1279],
        [9.0822],
        [9.1127],
        [9.1047],
        [9.0920],
        [9.1218],
        [9.0969],
        [9.1152]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[221.5877],
        [221.6123],
        [215.7116],
        [220.1257],
        [223.4567],
        [214.8064],
        [245.0358],
        [220.0490],
        [220.0877],
        [246.3258]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[636.0547],
        [528.1657],
        [588.9675],
        [636.0305],
        [636.1540],
        [546.9052],
        [633.5953],
        [597.7832],
        [637.1315],
        [629.0010]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[608.6739],
        [615.5850],
        [612.4631],
        [609.4454],
        [611.4585],
        [610.9340],
        [610.0920],
        [612.0605],
        [610.4171],
        [611.6262]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.7452],
        [ 9.9859],
        [ 9.5315],
        [ 9.7794],
        [ 9.9974],
        [ 9.3707],
        [10.4430],
        [ 9.4540],
        [ 9.6160],
        [ 9.8548]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4252],
        [ 9.4544],
        [10.7509],
        [11.4773],
        [11.4139],
        [ 9.9152],
        [11.4840],
        [10.8662],
        [11.5061],
        [11.5162]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0700],
        [9.1816],
        [9.1786],
        [9.0810],
        [9.1197],
        [9.1098],
        [9.0963],
        [9.0872],
        [9.1059],
        [9.2029]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[222.5141],
        [227.7796],
        [217.8392],
        [223.2627],
        [228.0319],
        [214.3193],
        [237.7814],
        [216.1431],
        [219.6862],
        [224.9131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[637.2371],
        [528.9225],
        [600.1808],
        [640.1027],
        [636.6189],
        [554.2482],
        [640.4725],
        [606.5161],
        [641.6872],
        [642.2423]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[608.6353],
        [616.0141],
        [615.8167],
        [609.3638],
        [611.9199],
        [611.2679],
        [610.3729],
        [609.7723],
        [611.0124],
        [617.4234]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.7673],
        [10.2661],
        [ 9.5773],
        [ 9.8753],
        [10.0018],
        [ 9.3262],
        [ 9.8550],
        [ 9.3686],
        [ 9.6410],
        [ 9.2610]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4216],
        [ 9.4742],
        [11.0371],
        [11.4743],
        [11.4135],
        [10.0229],
        [11.3695],
        [11.0992],
        [11.5166],
        [11.4750]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0694],
        [9.1631],
        [9.2093],
        [9.0850],
        [9.1523],
        [9.1106],
        [9.0928],
        [9.0766],
        [9.1031],
        [9.1617]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[222.9978],
        [233.9101],
        [218.8409],
        [225.3610],
        [228.1277],
        [213.3461],
        [224.9173],
        [214.2739],
        [220.2352],
        [211.9195]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[637.0413],
        [530.0128],
        [615.9106],
        [639.9363],
        [636.5976],
        [560.1676],
        [634.1780],
        [619.3237],
        [642.2649],
        [639.9761]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[608.5989],
        [614.7895],
        [617.8441],
        [609.6257],
        [614.0751],
        [611.3213],
        [610.1427],
        [609.0755],
        [610.8246],
        [614.6989]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.7135],
        [10.4477],
        [ 9.4627],
        [ 9.8470],
        [ 9.7872],
        [ 9.3540],
        [ 9.4799],
        [ 9.3888],
        [ 9.7230],
        [ 9.2432]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4081],
        [ 9.5548],
        [11.2313],
        [11.4364],
        [11.4383],
        [10.1498],
        [11.4128],
        [11.3403],
        [11.4499],
        [11.5318]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0895],
        [9.1386],
        [9.1619],
        [9.0930],
        [9.0968],
        [9.1143],
        [9.0886],
        [9.0781],
        [9.0988],
        [9.1167]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[221.8208],
        [237.8842],
        [216.3336],
        [224.7403],
        [223.4322],
        [213.9550],
        [216.7093],
        [214.7165],
        [222.0282],
        [211.5309]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[636.3000],
        [534.4431],
        [626.5811],
        [637.8537],
        [637.9592],
        [567.1442],
        [636.5561],
        [632.5709],
        [638.5971],
        [643.0961]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[609.9275],
        [613.1706],
        [614.7143],
        [610.1609],
        [610.4056],
        [611.5667],
        [609.8694],
        [609.1730],
        [610.5433],
        [611.7211]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6449],
        [10.7373],
        [ 9.4287],
        [ 9.8281],
        [ 9.7223],
        [ 9.3468],
        [ 9.1136],
        [ 9.4973],
        [ 9.7729],
        [ 9.2759]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.3874],
        [ 9.7593],
        [11.3670],
        [11.3773],
        [11.4773],
        [10.2515],
        [11.3978],
        [11.2180],
        [11.3442],
        [11.6029]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.1259],
        [9.1009],
        [9.1111],
        [9.1006],
        [9.0770],
        [9.1094],
        [9.0920],
        [9.1237],
        [9.0892],
        [9.0739]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[220.3206],
        [244.2198],
        [215.5888],
        [224.3272],
        [222.0139],
        [213.7979],
        [208.6944],
        [217.0907],
        [223.1192],
        [212.2456]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[635.1595],
        [545.6823],
        [634.0434],
        [634.6057],
        [640.1006],
        [572.7323],
        [635.7310],
        [625.8509],
        [632.7853],
        [647.0062]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[612.3339],
        [610.6827],
        [611.3546],
        [610.6618],
        [609.1027],
        [611.2419],
        [610.0934],
        [612.1853],
        [609.9049],
        [608.8921]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6783],
        [10.6077],
        [ 9.4407],
        [ 9.8369],
        [ 9.7536],
        [ 9.3503],
        [ 9.2604],
        [ 9.4337],
        [ 9.7482],
        [ 9.2424]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.3976],
        [ 9.6510],
        [11.3947],
        [11.4062],
        [11.4586],
        [10.2018],
        [11.4052],
        [11.3895],
        [11.3951],
        [11.5687]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.1058],
        [9.1180],
        [9.1330],
        [9.0965],
        [9.0812],
        [9.1117],
        [9.0903],
        [9.0988],
        [9.0937],
        [9.0923]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[221.0497],
        [241.3856],
        [215.8524],
        [224.5201],
        [222.6973],
        [213.8734],
        [211.9077],
        [215.6988],
        [222.5805],
        [211.5123]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[635.7211],
        [539.7289],
        [635.5660],
        [636.1973],
        [639.0766],
        [570.0030],
        [636.1424],
        [635.2782],
        [635.5833],
        [645.1264]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[611.0055],
        [611.8099],
        [612.8005],
        [610.3922],
        [609.3781],
        [611.3938],
        [609.9798],
        [610.5423],
        [610.2072],
        [610.1105]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.5842],
        [10.7727],
        [ 9.4333],
        [ 9.7171],
        [ 9.5570],
        [ 9.3547],
        [ 9.1786],
        [ 9.7628],
        [ 9.7772],
        [10.0545]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.3784],
        [ 9.9784],
        [11.0060],
        [11.3259],
        [11.4753],
        [10.2070],
        [11.4791],
        [10.9006],
        [11.2664],
        [11.4860]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.1521],
        [9.0742],
        [9.0691],
        [9.1117],
        [9.0997],
        [9.1000],
        [9.0952],
        [9.1804],
        [9.0809],
        [9.0564]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[218.9924],
        [244.9950],
        [215.6894],
        [221.8987],
        [218.3970],
        [213.9694],
        [210.1164],
        [222.8996],
        [223.2151],
        [229.2824]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[634.6681],
        [557.7229],
        [614.1988],
        [631.7846],
        [639.9939],
        [570.2880],
        [640.1999],
        [608.4085],
        [628.5128],
        [640.5816]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[614.0644],
        [608.9182],
        [608.5762],
        [611.3913],
        [610.6026],
        [610.6202],
        [610.3016],
        [615.9323],
        [609.3584],
        [607.7360]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6377],
        [10.6805],
        [ 9.4205],
        [ 9.7847],
        [ 9.6641],
        [ 9.3509],
        [ 9.2229],
        [ 9.5435],
        [ 9.7605],
        [ 9.5035]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.3894],
        [ 9.7800],
        [11.3831],
        [11.3713],
        [11.4687],
        [10.2017],
        [11.4540],
        [11.2925],
        [11.3386],
        [11.5456]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.1226],
        [9.0962],
        [9.0988],
        [9.1022],
        [9.0832],
        [9.1066],
        [9.0923],
        [9.1253],
        [9.0880],
        [9.0746]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[220.1622],
        [242.9781],
        [215.4108],
        [223.3793],
        [220.7391],
        [213.8861],
        [211.0864],
        [218.1014],
        [222.8486],
        [217.2267]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[635.2728],
        [546.8171],
        [634.9239],
        [634.2772],
        [639.6295],
        [569.9944],
        [638.8221],
        [629.9485],
        [632.4778],
        [643.8594]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[612.1120],
        [610.3685],
        [610.5434],
        [610.7632],
        [609.5074],
        [611.0548],
        [610.1112],
        [612.2920],
        [609.8247],
        [608.9417]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6255],
        [10.7362],
        [ 9.4571],
        [ 9.7014],
        [ 9.6829],
        [ 9.3932],
        [ 9.3563],
        [ 9.5709],
        [ 9.7105],
        [ 9.6529]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.3925],
        [ 9.9289],
        [11.3879],
        [11.3609],
        [11.4059],
        [10.2266],
        [11.4261],
        [11.3652],
        [11.3342],
        [11.4826]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.1282],
        [9.0934],
        [9.0724],
        [9.1044],
        [9.0920],
        [9.1155],
        [9.1055],
        [9.1429],
        [9.0914],
        [9.0803]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[219.8946],
        [244.1967],
        [216.2099],
        [221.5557],
        [221.1502],
        [214.8118],
        [214.0050],
        [218.7009],
        [221.7540],
        [220.4944]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[635.4440],
        [555.0042],
        [635.1870],
        [633.7045],
        [636.1815],
        [571.3616],
        [637.2898],
        [633.9419],
        [632.2360],
        [640.3934]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[612.4836],
        [610.1835],
        [608.7960],
        [610.9121],
        [610.0896],
        [611.6446],
        [610.9844],
        [613.4586],
        [610.0499],
        [609.3213]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6668],
        [10.7960],
        [ 9.6318],
        [ 9.6054],
        [ 9.6146],
        [ 9.4255],
        [ 9.7793],
        [ 9.6922],
        [ 9.6595],
        [ 9.8479]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4060],
        [10.2019],
        [11.4335],
        [11.3826],
        [11.3899],
        [10.2574],
        [11.4157],
        [11.5045],
        [11.3919],
        [11.4343]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.1040],
        [9.0974],
        [9.1062],
        [9.0984],
        [9.0776],
        [9.1104],
        [9.1017],
        [9.0944],
        [9.0996],
        [9.0762]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[220.7990],
        [245.5057],
        [220.0327],
        [219.4547],
        [219.6569],
        [215.5199],
        [223.2602],
        [221.3538],
        [220.6384],
        [224.7605]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[636.1850],
        [570.0046],
        [637.6966],
        [634.8996],
        [635.3003],
        [573.0574],
        [636.7193],
        [641.5979],
        [635.4102],
        [637.7415]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[610.8830],
        [610.4477],
        [611.0272],
        [610.5115],
        [609.1427],
        [611.3092],
        [610.7344],
        [610.2507],
        [610.5941],
        [609.0466]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.7011],
        [10.9716],
        [ 9.7847],
        [ 9.6193],
        [ 9.6115],
        [ 9.5159],
        [ 9.7233],
        [ 9.7724],
        [ 9.6687],
        [ 9.5754]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4177],
        [10.4803],
        [11.2967],
        [11.4206],
        [11.3891],
        [10.5168],
        [11.3578],
        [11.3241],
        [11.4414],
        [11.3341]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0821],
        [9.1013],
        [9.0989],
        [9.0923],
        [9.1126],
        [9.1267],
        [9.1013],
        [9.0833],
        [9.0982],
        [9.1157]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[221.5500],
        [249.3471],
        [223.3777],
        [219.7584],
        [219.5888],
        [217.4978],
        [222.0339],
        [223.1098],
        [220.8404],
        [218.7988]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[636.8254],
        [585.3072],
        [630.1798],
        [636.9874],
        [635.2570],
        [587.3132],
        [633.5363],
        [631.6844],
        [638.1291],
        [632.2322]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[609.4402],
        [610.7096],
        [610.5507],
        [610.1133],
        [611.4506],
        [612.3840],
        [610.7036],
        [609.5138],
        [610.5022],
        [611.6587]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6785],
        [10.8629],
        [ 9.6825],
        [ 9.6101],
        [ 9.6135],
        [ 9.4550],
        [ 9.7596],
        [ 9.7185],
        [ 9.6626],
        [ 9.7444]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4100],
        [10.2997],
        [11.3887],
        [11.3955],
        [11.3899],
        [10.3462],
        [11.3990],
        [11.4482],
        [11.4088],
        [11.4008]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0956],
        [9.0987],
        [9.1035],
        [9.0961],
        [9.0883],
        [9.1157],
        [9.1015],
        [9.0902],
        [9.0991],
        [9.0881]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[221.0543],
        [246.9682],
        [221.1424],
        [219.5573],
        [219.6335],
        [216.1653],
        [222.8299],
        [221.9294],
        [220.7072],
        [222.4959]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[636.4036],
        [575.3841],
        [635.2340],
        [635.6063],
        [635.3021],
        [577.9380],
        [635.8014],
        [638.5036],
        [636.3376],
        [635.8987]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[610.3298],
        [610.5364],
        [610.8545],
        [610.3608],
        [609.8482],
        [611.6614],
        [610.7216],
        [609.9701],
        [610.5607],
        [609.8338]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6938],
        [10.8718],
        [ 9.6689],
        [ 9.6462],
        [ 9.6632],
        [ 9.4699],
        [ 9.7234],
        [ 9.6845],
        [ 9.6783],
        [ 9.6187]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4137],
        [10.3303],
        [11.4365],
        [11.4180],
        [11.3926],
        [10.4501],
        [11.3971],
        [11.4260],
        [11.4256],
        [11.3809]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0878],
        [9.1029],
        [9.0923],
        [9.0936],
        [9.1117],
        [9.1199],
        [9.0992],
        [9.0955],
        [9.0966],
        [9.1068]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[221.3893],
        [247.1635],
        [220.8449],
        [220.3484],
        [220.7207],
        [216.4904],
        [222.0369],
        [221.1867],
        [221.0494],
        [219.7453]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[636.6082],
        [577.0612],
        [637.8619],
        [636.8451],
        [635.4479],
        [583.6485],
        [635.6934],
        [637.2843],
        [637.2621],
        [634.8046]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[609.8135],
        [610.8113],
        [610.1097],
        [610.1995],
        [611.3914],
        [611.9385],
        [610.5652],
        [610.3255],
        [610.3981],
        [611.0681]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6923],
        [10.9001],
        [ 9.6970],
        [ 9.6607],
        [ 9.6718],
        [ 9.4501],
        [ 9.6894],
        [ 9.7072],
        [ 9.6895],
        [ 9.6305]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.4117],
        [10.4080],
        [11.4028],
        [11.4177],
        [11.4072],
        [10.5155],
        [11.4072],
        [11.3907],
        [11.4180],
        [11.4002]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.0927],
        [9.0994],
        [9.0911],
        [9.0955],
        [9.1032],
        [9.1167],
        [9.0975],
        [9.0957],
        [9.0969],
        [9.1006]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[221.3559],
        [247.7837],
        [221.4603],
        [220.6647],
        [220.9075],
        [216.0579],
        [221.2929],
        [221.6818],
        [221.2958],
        [220.0037]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[636.4955],
        [581.3319],
        [636.0063],
        [636.8248],
        [636.2508],
        [587.2436],
        [636.2525],
        [635.3420],
        [636.8416],
        [635.8665]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[610.1384],
        [610.5793],
        [610.0304],
        [610.3218],
        [610.8333],
        [611.7234],
        [610.4548],
        [610.3378],
        [610.4144],
        [610.6629]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[ 9.6923],
        [10.9001],
        [ 9.6970],
        [ 9.6607],
        [ 9.6718],
        [ 9.4501],
        [ 9.6894],
        [ 9.7072],
        [ 9.6895],
        [ 9.6305]], device='cuda:0', dtype=torch.float64), tensor([[11.4117],
        [10.4080],
        [11.4028],
        [11.4177],
        [11.4072],
        [10.5155],
        [11.4072],
        [11.3907],
        [11.4180],
        [11.4002]], device='cuda:0', dtype=torch.float64), tensor([[9.0927],
        [9.0994],
        [9.0911],
        [9.0955],
        [9.1032],
        [9.1167],
        [9.0975],
        [9.0957],
        [9.0969],
        [9.1006]], device='cuda:0', dtype=torch.float64)]
AFTER NORMALIZATION:
[tensor([[221.3559],
        [247.7837],
        [221.4603],
        [220.6647],
        [220.9075],
        [216.0579],
        [221.2929],
        [221.6818],
        [221.2958],
        [220.0037]], device='cuda:0', dtype=torch.float64), tensor([[636.4955],
        [581.3319],
        [636.0063],
        [636.8248],
        [636.2508],
        [587.2436],
        [636.2525],
        [635.3420],
        [636.8416],
        [635.8665]], device='cuda:0', dtype=torch.float64), tensor([[610.1384],
        [610.5793],
        [610.0304],
        [610.3218],
        [610.8333],
        [611.7234],
        [610.4548],
        [610.3378],
        [610.4144],
        [610.6629]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64), tensor([[10.5741],
        [30.5929],
        [43.9707],
        [23.8525],
        [ 9.6513],
        [13.2272],
        [44.6373],
        [14.3482],
        [15.1745],
        [80.9953],
        [26.0857],
        [16.7154],
        [14.5709],
        [42.3980],
        [48.9202],
        [ 9.9731],
        [49.5319],
        [ 9.7065],
        [ 9.4604],
        [43.6479],
        [77.2906],
        [11.5935],
        [24.3458],
        [20.3850],
        [15.4015],
        [10.2463],
        [12.8136],
        [46.8354],
        [19.3144],
        [11.4720],
        [15.8564],
        [24.3806],
        [60.6897],
        [ 9.2809],
        [17.5037],
        [31.1030],
        [67.1592],
        [11.1962],
        [11.2358],
        [27.3022],
        [24.7610],
        [10.8553],
        [10.0549],
        [13.5149],
        [11.7974],
        [10.2770],
        [18.2048],
        [67.7640],
        [ 9.8607],
        [11.4795],
        [68.7613],
        [20.4879],
        [10.4805],
        [41.6721],
        [27.8491],
        [15.9526],
        [11.4393],
        [58.3435],
        [33.5259],
        [13.2066],
        [10.4871],
        [64.2640],
        [36.9530],
        [13.7545],
        [10.8630],
        [57.8222],
        [39.5828],
        [19.0104],
        [10.5828],
        [80.0691],
        [26.3141],
        [10.0120],
        [12.2884],
        [22.5455],
        [17.5379],
        [ 9.5492],
        [10.8152],
        [14.9678],
        [61.7448],
        [24.9083],
        [12.6906],
        [11.4515],
        [23.3401],
        [53.1811],
        [30.7522],
        [10.8195],
        [12.1523],
        [32.4745],
        [59.7275],
        [13.0784],
        [12.9933],
        [26.4936],
        [53.3375],
        [10.9146],
        [16.3644],
        [38.9952],
        [23.4413],
        [10.2140],
        [18.3060],
        [48.5694],
        [14.1819],
        [ 9.5381],
        [15.3188],
        [34.0381],
        [65.2786],
        [16.7232],
        [21.7693],
        [28.5575],
        [45.5798],
        [18.7170],
        [ 9.6179],
        [38.4464],
        [10.0691],
        [62.1634],
        [40.0832],
        [10.1836],
        [15.9684],
        [72.2293],
        [28.2651],
        [27.1329],
        [10.1099],
        [19.5959],
        [44.1101],
        [16.3402],
        [10.9617],
        [18.0634],
        [30.9863],
        [14.9146],
        [13.0580],
        [ 9.6307],
        [13.7408],
        [43.8198],
        [27.7074],
        [11.2906],
        [21.2234],
        [40.8855],
        [36.0285],
        [17.9129],
        [11.4497],
        [43.2862],
        [78.5057],
        [14.0983],
        [18.5265],
        [24.3088],
        [13.8672],
        [84.9873],
        [24.7056],
        [19.4263],
        [ 9.6412],
        [51.8459],
        [44.8232],
        [ 9.5446],
        [11.2845],
        [19.5287],
        [24.2633],
        [16.1814],
        [10.6537],
        [16.7771],
        [51.1128],
        [14.6565],
        [12.2038],
        [73.4953],
        [32.1236],
        [10.2927],
        [ 9.3465],
        [62.4924],
        [31.5129],
        [17.6702],
        [10.2623],
        [12.4539],
        [70.9771],
        [18.6720],
        [11.3647],
        [30.1808],
        [16.4091],
        [11.6332],
        [38.9524],
        [10.4908],
        [14.9941],
        [25.6450],
        [10.6982],
        [10.2577],
        [18.1218],
        [60.1601],
        [57.7677],
        [ 9.9045],
        [14.3411],
        [33.6376],
        [57.1439],
        [11.3871],
        [13.5586],
        [32.0980],
        [76.7646],
        [10.1617],
        [10.0962],
        [25.3515],
        [51.9716],
        [ 9.6417],
        [23.3597],
        [33.8063],
        [13.9314],
        [11.7252],
        [21.4359],
        [57.1552],
        [21.9354],
        [11.9798],
        [ 9.4784],
        [17.6474],
        [12.0522],
        [34.2136],
        [35.2718],
        [13.2260],
        [11.1579],
        [12.7277],
        [53.8684],
        [24.4138],
        [11.5404],
        [54.8383],
        [41.0779],
        [15.0615],
        [11.3795],
        [68.5472],
        [30.6497],
        [10.8497],
        [ 9.4786],
        [17.2980],
        [40.5860],
        [17.4747],
        [10.0604],
        [24.9170],
        [51.6909],
        [19.2868],
        [18.8667],
        [46.2234],
        [39.5631],
        [ 9.6459],
        [18.7333],
        [73.2231],
        [32.0086],
        [20.1119],
        [69.5546],
        [15.5429],
        [27.4487],
        [27.4199],
        [57.0428],
        [10.2499],
        [ 9.8890],
        [34.9432],
        [14.9638],
        [11.0082],
        [12.5033],
        [25.1170],
        [17.8118],
        [ 9.9240],
        [15.7049],
        [41.3648],
        [14.6668],
        [25.5757],
        [71.7505],
        [15.7440],
        [ 9.4851],
        [45.4323],
        [43.9699],
        [12.8115],
        [20.5442],
        [34.3155],
        [25.8520],
        [11.3124],
        [12.7944],
        [35.7887],
        [11.0516],
        [ 9.1314],
        [55.5586],
        [12.9112],
        [11.6210],
        [19.9006],
        [32.9801],
        [20.4294],
        [11.0903],
        [25.0632],
        [48.3913],
        [ 9.1184],
        [10.5524],
        [50.0965],
        [20.1692],
        [28.2313],
        [11.3456],
        [82.0298],
        [19.3224],
        [11.9551],
        [11.4218],
        [31.0209],
        [75.6405],
        [19.0569],
        [10.5850],
        [14.9233],
        [29.0167],
        [20.0296],
        [ 9.2574],
        [65.7153],
        [33.4816],
        [10.9515],
        [11.1810],
        [66.7793],
        [13.2085],
        [31.9809],
        [57.2779],
        [10.6078],
        [11.4288],
        [36.0554],
        [59.7872],
        [10.7897],
        [19.4908],
        [56.0697],
        [10.8388],
        [10.2918],
        [12.9631],
        [22.0705],
        [33.3206],
        [10.8476],
        [10.0812],
        [19.5557],
        [24.2513],
        [11.6744],
        [20.4660],
        [64.4478],
        [15.8033],
        [11.2821],
        [28.3052],
        [33.3903],
        [51.6707],
        [ 9.6495],
        [10.0840],
        [24.7367],
        [73.6346],
        [ 9.8927],
        [28.4231],
        [10.0911],
        [10.6896],
        [72.2354],
        [46.6094],
        [12.6171],
        [13.7401],
        [53.6651],
        [52.9458],
        [24.6800],
        [10.7962],
        [11.6525],
        [28.5753],
        [12.1409],
        [11.9861],
        [31.0304],
        [32.9196],
        [15.5986],
        [20.3843],
        [67.7567],
        [42.1483],
        [ 9.0616],
        [13.1088],
        [54.4170],
        [44.8543],
        [18.0403],
        [10.6128],
        [22.4750],
        [32.1839],
        [16.5854],
        [ 9.3987],
        [13.0429],
        [14.1103],
        [44.2181],
        [21.7490],
        [10.5823],
        [15.3297],
        [35.0704],
        [18.7410],
        [10.9078],
        [ 9.1859],
        [38.7670],
        [54.4612],
        [12.3699],
        [38.2144],
        [21.9849],
        [67.7147],
        [12.2500],
        [47.0272],
        [ 9.4381],
        [12.9361],
        [44.8332],
        [29.0307],
        [13.5720],
        [17.5919],
        [80.7481],
        [42.5856],
        [14.5613],
        [ 9.2986],
        [12.0436],
        [36.8326],
        [21.8550],
        [11.0613],
        [27.4587],
        [17.0388],
        [27.1385],
        [20.9231],
        [11.7511],
        [12.5515],
        [52.6399],
        [18.1834],
        [11.1197],
        [28.4147],
        [19.5490],
        [79.2663],
        [11.1276],
        [ 9.3763],
        [42.7970],
        [45.8506],
        [10.6877],
        [16.1825],
        [70.0056],
        [13.6980],
        [10.8932],
        [11.7390],
        [19.2031],
        [30.0829],
        [11.2120],
        [11.5562],
        [32.2395],
        [63.6271],
        [10.6980],
        [24.7156],
        [24.2685],
        [59.0707],
        [ 9.4967],
        [37.7241],
        [10.7459],
        [11.3497],
        [61.0037],
        [36.3154],
        [11.1370],
        [10.7281],
        [65.3451],
        [23.9939],
        [14.2198],
        [11.4893],
        [36.9210],
        [56.7587],
        [20.1737],
        [10.1294],
        [10.8861],
        [67.1826],
        [20.9695],
        [11.1202],
        [16.9470],
        [24.1753],
        [11.4966],
        [12.7072],
        [29.3838],
        [28.9632],
        [ 9.4925],
        [10.1730],
        [80.0527],
        [33.8249],
        [28.6876],
        [ 9.7490],
        [53.1823],
        [13.2344],
        [42.3413],
        [47.3124],
        [12.5695],
        [10.3067],
        [26.9052],
        [70.5474],
        [10.5940],
        [11.4365],
        [26.3465],
        [28.7430],
        [11.7235],
        [21.5138],
        [45.4709],
        [10.9353],
        [12.3914],
        [ 9.2371],
        [37.5691],
        [47.3204],
        [15.9742],
        [17.2528],
        [31.0715],
        [65.9497],
        [18.9387],
        [15.9518],
        [31.5728],
        [12.9327],
        [ 9.5353],
        [16.3081],
        [41.8755],
        [20.3373],
        [10.6035],
        [35.1676],
        [15.6250],
        [10.9292],
        [19.0671],
        [48.7518],
        [16.5910],
        [10.7314],
        [23.9573],
        [26.7195],
        [30.8686],
        [14.8029],
        [75.2526],
        [39.9549],
        [ 9.3640],
        [11.5521],
        [57.0292]], device='cuda:0', dtype=torch.float64)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64), tensor([[ 708.0655],
        [2031.4019],
        [2915.7359],
        [1585.8275],
        [ 647.0661],
        [ 883.4503],
        [2959.8029],
        [ 957.5514],
        [1012.1716],
        [5363.2380],
        [1733.4562],
        [1114.0342],
        [ 972.2719],
        [2811.7752],
        [3242.9229],
        [ 668.3336],
        [3283.3609],
        [ 650.7103],
        [ 634.4424],
        [2894.3986],
        [5118.3414],
        [ 775.4529],
        [1618.4367],
        [1356.6144],
        [1027.1797],
        [ 686.3990],
        [ 856.1055],
        [3105.1109],
        [1285.8402],
        [ 767.4203],
        [1057.2506],
        [1620.7397],
        [4020.9401],
        [ 622.5807],
        [1166.1465],
        [2065.1232],
        [4448.6041],
        [ 749.1892],
        [ 751.8039],
        [1813.8747],
        [1645.8845],
        [ 726.6516],
        [ 673.7424],
        [ 902.4678],
        [ 788.9320],
        [ 688.4275],
        [1212.4894],
        [4488.5844],
        [ 660.9054],
        [ 767.9148],
        [4554.5143],
        [1363.4143],
        [ 701.8773],
        [2763.7875],
        [1850.0250],
        [1063.6069],
        [ 765.2583],
        [3865.8456],
        [2225.2882],
        [ 882.0873],
        [ 702.3124],
        [4257.2211],
        [2451.8363],
        [ 918.3025],
        [ 727.1627],
        [3831.3851],
        [2625.6788],
        [1265.7433],
        [ 708.6436],
        [5302.0111],
        [1748.5566],
        [ 670.9112],
        [ 821.3871],
        [1499.4303],
        [1168.4045],
        [ 640.3162],
        [ 724.0030],
        [ 998.5122],
        [4090.6895],
        [1655.6224],
        [ 847.9758],
        [ 766.0677],
        [1551.9579],
        [3524.5875],
        [2041.9342],
        [ 724.2890],
        [ 812.3924],
        [2155.7848],
        [3957.3355],
        [ 873.6093],
        [ 867.9827],
        [1760.4172],
        [3534.9293],
        [ 730.5734],
        [1090.8339],
        [2586.8320],
        [1558.6479],
        [ 684.2619],
        [1219.1772],
        [3219.7315],
        [ 946.5611],
        [ 639.5795],
        [1021.7096],
        [2259.1464],
        [4324.2896],
        [1114.5531],
        [1448.1223],
        [1896.8557],
        [3022.1099],
        [1246.3499],
        [ 644.8563],
        [2550.5560],
        [ 674.6806],
        [4118.3637],
        [2658.7553],
        [ 682.2521],
        [1064.6567],
        [4783.7650],
        [1877.5245],
        [1802.6775],
        [ 677.3773],
        [1304.4498],
        [2924.9520],
        [1089.2295],
        [ 733.6874],
        [1203.1464],
        [2057.4076],
        [ 994.9936],
        [ 872.2641],
        [ 645.7052],
        [ 917.4017],
        [2905.7603],
        [1840.6578],
        [ 755.4286],
        [1412.0328],
        [2711.7898],
        [2390.7195],
        [1193.1971],
        [ 765.9485],
        [2870.4914],
        [5198.6652],
        [ 941.0297],
        [1233.7580],
        [1615.9908],
        [ 925.7558],
        [5627.1290],
        [1642.2272],
        [1293.2367],
        [ 646.3938],
        [3436.3289],
        [2972.0917],
        [ 640.0082],
        [ 755.0289],
        [1300.0064],
        [1612.9885],
        [1078.7345],
        [ 713.3283],
        [1118.1143],
        [3387.8641],
        [ 977.9293],
        [ 815.7947],
        [4867.4515],
        [2132.5891],
        [ 689.4622],
        [ 626.9148],
        [4140.1082],
        [2092.2212],
        [1177.1525],
        [ 687.4571],
        [ 832.3273],
        [4700.9883],
        [1243.3752],
        [ 760.3269],
        [2004.1576],
        [1093.7835],
        [ 778.0757],
        [2584.0050],
        [ 702.5588],
        [1000.2461],
        [1704.3218],
        [ 716.2670],
        [ 687.1467],
        [1207.0030],
        [3985.9369],
        [3827.7864],
        [ 663.8015],
        [ 957.0802],
        [2232.6704],
        [3786.5503],
        [ 761.8087],
        [ 905.3534],
        [2130.8954],
        [5083.5696],
        [ 680.8066],
        [ 676.4734],
        [1684.9204],
        [3444.6372],
        [ 646.4265],
        [1553.2567],
        [2243.8210],
        [ 930.0009],
        [ 784.1575],
        [1426.0829],
        [3787.2932],
        [1459.1041],
        [ 800.9905],
        [ 635.6337],
        [1175.6453],
        [ 805.7763],
        [2270.7483],
        [2340.6978],
        [ 883.3693],
        [ 746.6593],
        [ 850.4259],
        [3570.0208],
        [1622.9349],
        [ 771.9403],
        [3634.1403],
        [2724.5108],
        [1004.7033],
        [ 761.3029],
        [4540.3632],
        [2035.1544],
        [ 726.2817],
        [ 635.6503],
        [1152.5474],
        [2691.9955],
        [1164.2300],
        [ 674.1085],
        [1656.2020],
        [3426.0804],
        [1284.0179],
        [1256.2465],
        [3064.6533],
        [2624.3751],
        [ 646.7067],
        [1247.4290],
        [4849.4607],
        [2124.9857],
        [1338.5581],
        [4606.9524],
        [1036.5241],
        [1823.5577],
        [1821.6547],
        [3779.8628],
        [ 686.6350],
        [ 662.7770],
        [2318.9746],
        [ 998.2448],
        [ 736.7611],
        [ 835.5941],
        [1669.4224],
        [1186.5111],
        [ 665.0936],
        [1047.2330],
        [2743.4763],
        [ 978.6121],
        [1699.7394],
        [4752.1137],
        [1049.8234],
        [ 636.0765],
        [3012.3595],
        [2915.6867],
        [ 855.9663],
        [1367.1386],
        [2277.4864],
        [1718.0094],
        [ 756.8693],
        [ 854.8384],
        [2374.8687],
        [ 739.6287],
        [ 612.6947],
        [3681.7500],
        [ 862.5568],
        [ 777.2723],
        [1324.5916],
        [2189.2094],
        [1359.5483],
        [ 742.1916],
        [1665.8614],
        [3207.9614],
        [ 611.8345],
        [ 706.6336],
        [3320.6798],
        [1342.3447],
        [1875.2872],
        [ 759.0634],
        [5431.6238],
        [1286.3702],
        [ 799.3560],
        [ 764.1036],
        [2059.6953],
        [5009.2629],
        [1268.8187],
        [ 708.7846],
        [ 995.5688],
        [1927.2074],
        [1333.1210],
        [ 621.0265],
        [4353.1556],
        [2222.3598],
        [ 733.0112],
        [ 748.1840],
        [4423.4932],
        [ 882.2105],
        [2123.1532],
        [3795.4074],
        [ 710.2952],
        [ 764.5678],
        [2392.4967],
        [3961.2823],
        [ 722.3207],
        [1297.5015],
        [3715.5421],
        [ 725.5634],
        [ 689.4048],
        [ 865.9873],
        [1468.0298],
        [2211.7193],
        [ 726.1421],
        [ 675.4848],
        [1301.7884],
        [1612.1952],
        [ 780.8007],
        [1361.9652],
        [4269.3705],
        [1053.7400],
        [ 754.8662],
        [1880.1715],
        [2216.3266],
        [3424.7452],
        [ 646.9441],
        [ 675.6681],
        [1644.2829],
        [4876.6589],
        [ 663.0191],
        [1887.9690],
        [ 676.1374],
        [ 715.7019],
        [4784.1688],
        [3090.1657],
        [ 843.1198],
        [ 917.3561],
        [3556.5855],
        [3509.0323],
        [1640.5341],
        [ 722.7457],
        [ 779.3504],
        [1898.0279],
        [ 811.6367],
        [ 801.4048],
        [2060.3242],
        [2185.2106],
        [1040.2105],
        [1356.5650],
        [4488.1035],
        [2795.2680],
        [ 608.0845],
        [ 875.6210],
        [3606.2905],
        [2974.1450],
        [1201.6144],
        [ 710.6251],
        [1494.7701],
        [2136.5777],
        [1105.4418],
        [ 630.3633],
        [ 871.2625],
        [ 941.8266],
        [2932.0899],
        [1446.7776],
        [ 708.6042],
        [1022.4334],
        [2327.3865],
        [1247.9371],
        [ 730.1267],
        [ 616.2972],
        [2571.7520],
        [3609.2075],
        [ 826.7756],
        [2535.2188],
        [1462.3726],
        [4485.3251],
        [ 818.8516],
        [3117.7853],
        [ 632.9695],
        [ 864.2048],
        [2972.7513],
        [1928.1324],
        [ 906.2431],
        [1171.9783],
        [5346.8981],
        [2824.1755],
        [ 971.6388],
        [ 623.7461],
        [ 805.2072],
        [2443.8739],
        [1453.7836],
        [ 740.2702],
        [1824.2146],
        [1135.4149],
        [1803.0505],
        [1392.1816],
        [ 785.8709],
        [ 838.7840],
        [3488.8111],
        [1211.0791],
        [ 744.1307],
        [1887.4130],
        [1301.3453],
        [5248.9445],
        [ 744.6543],
        [ 628.8833],
        [2838.1490],
        [3040.0112],
        [ 715.5727],
        [1078.8042],
        [4636.7701],
        [ 914.5676],
        [ 729.1606],
        [ 785.0714],
        [1278.4808],
        [1997.6903],
        [ 750.2331],
        [ 772.9843],
        [2140.2483],
        [4215.1169],
        [ 716.2540],
        [1642.8824],
        [1613.3308],
        [3913.9169],
        [ 636.8466],
        [2502.8116],
        [ 719.4238],
        [ 759.3342],
        [4041.6969],
        [2409.6859],
        [ 745.2732],
        [ 718.2469],
        [4328.6849],
        [1595.1748],
        [ 949.0623],
        [ 768.5658],
        [2449.7193],
        [3761.0840],
        [1342.6430],
        [ 678.6712],
        [ 728.6904],
        [4450.1508],
        [1395.2505],
        [ 744.1676],
        [1129.3472],
        [1607.1674],
        [ 769.0443],
        [ 849.0752],
        [1951.4720],
        [1923.6701],
        [ 636.5671],
        [ 681.5505],
        [5300.9286],
        [2245.0528],
        [1905.4531],
        [ 653.5231],
        [3524.6702],
        [ 883.9244],
        [2808.0270],
        [3136.6384],
        [ 839.9685],
        [ 690.3895],
        [1787.6276],
        [4672.5817],
        [ 709.3822],
        [ 765.0713],
        [1750.6937],
        [1909.1161],
        [ 784.0455],
        [1431.2301],
        [3014.9079],
        [ 731.9453],
        [ 828.1950],
        [ 619.6844],
        [2492.5609],
        [3137.1660],
        [1065.0404],
        [1149.5582],
        [2063.0376],
        [4368.6517],
        [1261.0064],
        [1063.5600],
        [2096.1767],
        [ 863.9773],
        [ 639.3953],
        [1087.1081],
        [2777.2357],
        [1353.4618],
        [ 710.0076],
        [2333.8093],
        [1041.9567],
        [ 731.5389],
        [1269.4959],
        [3231.7918],
        [1105.8107],
        [ 718.4656],
        [1592.7569],
        [1775.3535],
        [2049.6255],
        [ 987.6104],
        [4983.6183],
        [2650.2769],
        [ 628.0734],
        [ 772.7127],
        [3778.9646]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.5828],
        [15.6250],
        [67.7567],
        [10.6877],
        [10.2499],
        [15.0615],
        [14.9678],
        [10.7314],
        [10.2918],
        [ 9.8927]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 708.6436],
        [1041.9567],
        [4488.1035],
        [ 715.5727],
        [ 686.6350],
        [1004.7033],
        [ 998.5122],
        [ 718.4656],
        [ 689.4048],
        [ 663.0191]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.5753],
        [15.6178],
        [67.7518],
        [10.6800],
        [10.2494],
        [15.0337],
        [14.9468],
        [10.7320],
        [10.2885],
        [ 9.8924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 708.1471],
        [1041.4806],
        [4487.7791],
        [ 715.0666],
        [ 686.5986],
        [1002.8651],
        [ 997.1193],
        [ 718.5057],
        [ 689.1887],
        [ 663.0038]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[17.8961],
        [ 9.9777],
        [61.3879],
        [13.4547],
        [11.7462],
        [14.2683],
        [32.2885],
        [11.3564],
        [11.7997],
        [ 9.7131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[1192.0837],
        [ 668.6388],
        [4067.0984],
        [ 898.4851],
        [ 785.5464],
        [ 952.2680],
        [2143.4924],
        [ 759.7822],
        [ 789.0846],
        [ 651.1478]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0611],
        [12.5004],
        [65.2682],
        [ 9.8463],
        [ 9.7823],
        [ 9.3005],
        [10.7033],
        [11.0310],
        [ 9.7058],
        [ 9.8201]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 674.1507],
        [ 835.4034],
        [4323.6057],
        [ 659.9549],
        [ 655.7253],
        [ 623.8775],
        [ 716.6085],
        [ 738.2667],
        [ 650.6645],
        [ 658.2230]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0270],
        [11.3326],
        [63.8524],
        [ 9.8628],
        [ 9.8786],
        [ 9.5438],
        [10.2650],
        [11.2017],
        [ 9.9307],
        [ 9.8020]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 671.9003],
        [ 758.2048],
        [4230.0152],
        [ 661.0482],
        [ 662.0890],
        [ 639.9598],
        [ 687.6320],
        [ 749.5549],
        [ 665.5347],
        [ 657.0237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.7291],
        [ 9.9829],
        [58.4284],
        [ 9.7434],
        [10.0477],
        [11.6068],
        [ 9.3057],
        [11.6627],
        [11.3883],
        [ 9.7878]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 652.2042],
        [ 668.9847],
        [3871.4632],
        [ 653.1491],
        [ 673.2647],
        [ 776.3288],
        [ 624.2180],
        [ 780.0268],
        [ 761.8896],
        [ 656.0881]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8648],
        [10.2749],
        [61.4768],
        [ 9.7950],
        [ 9.9500],
        [ 9.9410],
        [ 9.7937],
        [11.4689],
        [10.4588],
        [ 9.7958]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 661.1760],
        [ 688.2869],
        [4072.9720],
        [ 656.5644],
        [ 666.8125],
        [ 666.2162],
        [ 656.4773],
        [ 767.2166],
        [ 700.4462],
        [ 656.6163]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.7680],
        [10.1679],
        [59.1899],
        [ 9.7902],
        [ 9.9001],
        [ 9.9207],
        [ 9.7962],
        [11.7311],
        [10.6762],
        [ 9.8172]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 654.7807],
        [ 681.2135],
        [3921.7988],
        [ 656.2457],
        [ 663.5094],
        [ 664.8726],
        [ 656.6448],
        [ 784.5471],
        [ 714.8176],
        [ 658.0324]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8540],
        [10.3294],
        [53.9108],
        [ 9.9106],
        [ 9.7855],
        [10.1101],
        [ 9.7199],
        [11.7422],
        [11.2659],
        [ 9.8372]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 660.4602],
        [ 691.8914],
        [3572.8239],
        [ 664.2032],
        [ 655.9323],
        [ 677.3898],
        [ 651.6004],
        [ 785.2834],
        [ 753.7992],
        [ 659.3554]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[12.8892],
        [12.2050],
        [14.2082],
        [13.5349],
        [ 9.2296],
        [19.0720],
        [ 9.6733],
        [12.4569],
        [14.4106],
        [10.0315]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 861.1071],
        [ 815.8772],
        [ 948.2941],
        [ 903.7887],
        [ 619.1895],
        [1269.8174],
        [ 648.5188],
        [ 832.5274],
        [ 961.6767],
        [ 672.1994]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.4618],
        [11.0115],
        [36.2126],
        [10.6243],
        [ 9.4584],
        [11.6055],
        [ 9.5472],
        [10.3652],
        [10.7144],
        [ 9.9026]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 700.6397],
        [ 736.9815],
        [2402.8942],
        [ 711.3849],
        [ 634.3135],
        [ 776.2435],
        [ 640.1823],
        [ 694.2566],
        [ 717.3408],
        [ 663.6779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.9816],
        [13.0977],
        [19.9259],
        [11.2189],
        [ 9.5119],
        [13.8268],
        [10.2686],
        [14.6569],
        [ 9.3521],
        [ 9.9605]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 735.0003],
        [ 874.8902],
        [1326.2636],
        [ 750.6867],
        [ 637.8490],
        [ 923.0845],
        [ 687.8736],
        [ 977.9592],
        [ 627.2867],
        [ 667.5012]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.5761],
        [10.9469],
        [31.8882],
        [10.7501],
        [ 9.4250],
        [12.0244],
        [ 9.6023],
        [11.0954],
        [10.0410],
        [ 9.9159]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 708.2009],
        [ 732.7075],
        [2117.0292],
        [ 719.7024],
        [ 632.1074],
        [ 803.9363],
        [ 643.8235],
        [ 742.5247],
        [ 672.8250],
        [ 664.5529]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.2471],
        [17.5645],
        [22.8152],
        [10.2376],
        [ 9.9057],
        [11.3930],
        [10.8251],
        [14.9048],
        [ 9.6273],
        [ 9.9055]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 686.4503],
        [1170.1619],
        [1517.2620],
        [ 685.8207],
        [ 663.8796],
        [ 762.2010],
        [ 724.6582],
        [ 994.3471],
        [ 645.4788],
        [ 663.8685]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.3821],
        [12.6292],
        [27.4961],
        [10.4751],
        [ 9.5737],
        [11.7276],
        [ 9.9969],
        [12.8533],
        [ 9.8329],
        [ 9.9110]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 695.3712],
        [ 843.9172],
        [1826.6862],
        [ 701.5240],
        [ 641.9374],
        [ 784.3171],
        [ 669.9119],
        [ 858.7286],
        [ 659.0717],
        [ 664.2339]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0559],
        [11.4641],
        [22.8837],
        [ 9.9496],
        [10.0886],
        [10.0291],
        [10.3675],
        [12.8460],
        [10.8109],
        [ 9.8563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 673.8127],
        [ 766.8997],
        [1521.7907],
        [ 666.7844],
        [ 675.9693],
        [ 672.0371],
        [ 694.4050],
        [ 858.2497],
        [ 723.7203],
        [ 660.6171]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.4045],
        [ 9.9979],
        [10.9858],
        [10.0947],
        [10.8589],
        [ 9.9725],
        [11.1821],
        [11.0707],
        [10.6095],
        [ 9.8177]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[696.8519],
        [669.9772],
        [735.2801],
        [676.3780],
        [726.8949],
        [668.2979],
        [748.2569],
        [740.8951],
        [710.4081],
        [658.0619]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8878],
        [ 9.2115],
        [10.2354],
        [ 9.8526],
        [ 9.9557],
        [ 9.8302],
        [ 9.8674],
        [11.8832],
        [ 9.7783],
        [ 9.8027]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[662.6993],
        [617.9887],
        [685.6740],
        [660.3716],
        [667.1869],
        [658.8892],
        [661.3497],
        [794.6039],
        [655.4601],
        [657.0723]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.5843],
        [11.5068],
        [ 9.7150],
        [ 9.6979],
        [10.7668],
        [ 9.7105],
        [ 9.9014],
        [12.2379],
        [10.1378],
        [ 9.8013]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[642.6319],
        [769.7210],
        [651.2716],
        [650.1438],
        [720.8033],
        [650.9749],
        [663.5959],
        [818.0491],
        [679.2261],
        [656.9768]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.7311],
        [ 9.9435],
        [ 9.9186],
        [ 9.7607],
        [10.1664],
        [ 9.7498],
        [ 9.7290],
        [12.0385],
        [ 9.7957],
        [ 9.8020]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[652.3418],
        [666.3790],
        [664.7337],
        [654.2938],
        [681.1123],
        [653.5760],
        [652.2008],
        [804.8683],
        [656.6119],
        [657.0264]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8049],
        [ 9.8024],
        [ 9.7589],
        [ 9.8449],
        [ 9.7486],
        [ 9.8180],
        [ 9.7994],
        [10.5805],
        [ 9.9592],
        [ 9.8262]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[657.2165],
        [657.0556],
        [654.1792],
        [659.8628],
        [653.4964],
        [658.0813],
        [656.8521],
        [708.4917],
        [667.4146],
        [658.6290]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8104],
        [ 9.8403],
        [ 9.8189],
        [ 9.8232],
        [ 9.7945],
        [ 9.7873],
        [ 9.8340],
        [10.8348],
        [ 9.7916],
        [ 9.8205]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[657.5796],
        [659.5578],
        [658.1447],
        [658.4276],
        [656.5328],
        [656.0573],
        [659.1386],
        [725.2960],
        [656.3364],
        [658.2509]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8140],
        [ 9.8128],
        [ 9.8243],
        [ 9.8159],
        [ 9.8344],
        [ 9.8098],
        [ 9.8238],
        [10.7042],
        [ 9.8511],
        [ 9.8194]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[657.8185],
        [657.7399],
        [658.5031],
        [657.9429],
        [659.1685],
        [657.5422],
        [658.4680],
        [716.6663],
        [660.2694],
        [658.1744]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8171],
        [ 9.8143],
        [ 9.8203],
        [ 9.8195],
        [ 9.8181],
        [ 9.8238],
        [ 9.8252],
        [10.6410],
        [ 9.8307],
        [ 9.8217]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[658.0220],
        [657.8421],
        [658.2383],
        [658.1827],
        [658.0889],
        [658.4668],
        [658.5569],
        [712.4885],
        [658.9246],
        [658.3285]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64), tensor([[ 9.8171],
        [ 9.8143],
        [ 9.8203],
        [ 9.8195],
        [ 9.8181],
        [ 9.8238],
        [ 9.8252],
        [10.6410],
        [ 9.8307],
        [ 9.8217]], device='cuda:0', dtype=torch.float64)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64), tensor([[658.0220],
        [657.8421],
        [658.2383],
        [658.1827],
        [658.0889],
        [658.4668],
        [658.5569],
        [712.4885],
        [658.9246],
        [658.3285]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64), tensor([[10.5741],
        [30.5929],
        [43.9707],
        [23.8525],
        [ 9.6513],
        [13.2272],
        [44.6373],
        [14.3482],
        [15.1745],
        [80.9953],
        [26.0857],
        [16.7154],
        [14.5709],
        [42.3980],
        [48.9202],
        [ 9.9731],
        [49.5319],
        [ 9.7065],
        [ 9.4604],
        [43.6479],
        [77.2906],
        [11.5935],
        [24.3458],
        [20.3850],
        [15.4015],
        [10.2463],
        [12.8136],
        [46.8354],
        [19.3144],
        [11.4720],
        [15.8564],
        [24.3806],
        [60.6897],
        [ 9.2809],
        [17.5037],
        [31.1030],
        [67.1592],
        [11.1962],
        [11.2358],
        [27.3022],
        [24.7610],
        [10.8553],
        [10.0549],
        [13.5149],
        [11.7974],
        [10.2770],
        [18.2048],
        [67.7640],
        [ 9.8607],
        [11.4795],
        [68.7613],
        [20.4879],
        [10.4805],
        [41.6721],
        [27.8491],
        [15.9526],
        [11.4393],
        [58.3435],
        [33.5259],
        [13.2066],
        [10.4871],
        [64.2640],
        [36.9530],
        [13.7545],
        [10.8630],
        [57.8222],
        [39.5828],
        [19.0104],
        [10.5828],
        [80.0691],
        [26.3141],
        [10.0120],
        [12.2884],
        [22.5455],
        [17.5379],
        [ 9.5492],
        [10.8152],
        [14.9678],
        [61.7448],
        [24.9083],
        [12.6906],
        [11.4515],
        [23.3401],
        [53.1811],
        [30.7522],
        [10.8195],
        [12.1523],
        [32.4745],
        [59.7275],
        [13.0784],
        [12.9933],
        [26.4936],
        [53.3375],
        [10.9146],
        [16.3644],
        [38.9952],
        [23.4413],
        [10.2140],
        [18.3060],
        [48.5694],
        [14.1819],
        [ 9.5381],
        [15.3188],
        [34.0381],
        [65.2786],
        [16.7232],
        [21.7693],
        [28.5575],
        [45.5798],
        [18.7170],
        [ 9.6179],
        [38.4464],
        [10.0691],
        [62.1634],
        [40.0832],
        [10.1836],
        [15.9684],
        [72.2293],
        [28.2651],
        [27.1329],
        [10.1099],
        [19.5959],
        [44.1101],
        [16.3402],
        [10.9617],
        [18.0634],
        [30.9863],
        [14.9146],
        [13.0580],
        [ 9.6307],
        [13.7408],
        [43.8198],
        [27.7074],
        [11.2906],
        [21.2234],
        [40.8855],
        [36.0285],
        [17.9129],
        [11.4497],
        [43.2862],
        [78.5057],
        [14.0983],
        [18.5265],
        [24.3088],
        [13.8672],
        [84.9873],
        [24.7056],
        [19.4263],
        [ 9.6412],
        [51.8459],
        [44.8232],
        [ 9.5446],
        [11.2845],
        [19.5287],
        [24.2633],
        [16.1814],
        [10.6537],
        [16.7771],
        [51.1128],
        [14.6565],
        [12.2038],
        [73.4953],
        [32.1236],
        [10.2927],
        [ 9.3465],
        [62.4924],
        [31.5129],
        [17.6702],
        [10.2623],
        [12.4539],
        [70.9771],
        [18.6720],
        [11.3647],
        [30.1808],
        [16.4091],
        [11.6332],
        [38.9524],
        [10.4908],
        [14.9941],
        [25.6450],
        [10.6982],
        [10.2577],
        [18.1218],
        [60.1601],
        [57.7677],
        [ 9.9045],
        [14.3411],
        [33.6376],
        [57.1439],
        [11.3871],
        [13.5586],
        [32.0980],
        [76.7646],
        [10.1617],
        [10.0962],
        [25.3515],
        [51.9716],
        [ 9.6417],
        [23.3597],
        [33.8063],
        [13.9314],
        [11.7252],
        [21.4359],
        [57.1552],
        [21.9354],
        [11.9798],
        [ 9.4784],
        [17.6474],
        [12.0522],
        [34.2136],
        [35.2718],
        [13.2260],
        [11.1579],
        [12.7277],
        [53.8684],
        [24.4138],
        [11.5404],
        [54.8383],
        [41.0779],
        [15.0615],
        [11.3795],
        [68.5472],
        [30.6497],
        [10.8497],
        [ 9.4786],
        [17.2980],
        [40.5860],
        [17.4747],
        [10.0604],
        [24.9170],
        [51.6909],
        [19.2868],
        [18.8667],
        [46.2234],
        [39.5631],
        [ 9.6459],
        [18.7333],
        [73.2231],
        [32.0086],
        [20.1119],
        [69.5546],
        [15.5429],
        [27.4487],
        [27.4199],
        [57.0428],
        [10.2499],
        [ 9.8890],
        [34.9432],
        [14.9638],
        [11.0082],
        [12.5033],
        [25.1170],
        [17.8118],
        [ 9.9240],
        [15.7049],
        [41.3648],
        [14.6668],
        [25.5757],
        [71.7505],
        [15.7440],
        [ 9.4851],
        [45.4323],
        [43.9699],
        [12.8115],
        [20.5442],
        [34.3155],
        [25.8520],
        [11.3124],
        [12.7944],
        [35.7887],
        [11.0516],
        [ 9.1314],
        [55.5586],
        [12.9112],
        [11.6210],
        [19.9006],
        [32.9801],
        [20.4294],
        [11.0903],
        [25.0632],
        [48.3913],
        [ 9.1184],
        [10.5524],
        [50.0965],
        [20.1692],
        [28.2313],
        [11.3456],
        [82.0298],
        [19.3224],
        [11.9551],
        [11.4218],
        [31.0209],
        [75.6405],
        [19.0569],
        [10.5850],
        [14.9233],
        [29.0167],
        [20.0296],
        [ 9.2574],
        [65.7153],
        [33.4816],
        [10.9515],
        [11.1810],
        [66.7793],
        [13.2085],
        [31.9809],
        [57.2779],
        [10.6078],
        [11.4288],
        [36.0554],
        [59.7872],
        [10.7897],
        [19.4908],
        [56.0697],
        [10.8388],
        [10.2918],
        [12.9631],
        [22.0705],
        [33.3206],
        [10.8476],
        [10.0812],
        [19.5557],
        [24.2513],
        [11.6744],
        [20.4660],
        [64.4478],
        [15.8033],
        [11.2821],
        [28.3052],
        [33.3903],
        [51.6707],
        [ 9.6495],
        [10.0840],
        [24.7367],
        [73.6346],
        [ 9.8927],
        [28.4231],
        [10.0911],
        [10.6896],
        [72.2354],
        [46.6094],
        [12.6171],
        [13.7401],
        [53.6651],
        [52.9458],
        [24.6800],
        [10.7962],
        [11.6525],
        [28.5753],
        [12.1409],
        [11.9861],
        [31.0304],
        [32.9196],
        [15.5986],
        [20.3843],
        [67.7567],
        [42.1483],
        [ 9.0616],
        [13.1088],
        [54.4170],
        [44.8543],
        [18.0403],
        [10.6128],
        [22.4750],
        [32.1839],
        [16.5854],
        [ 9.3987],
        [13.0429],
        [14.1103],
        [44.2181],
        [21.7490],
        [10.5823],
        [15.3297],
        [35.0704],
        [18.7410],
        [10.9078],
        [ 9.1859],
        [38.7670],
        [54.4612],
        [12.3699],
        [38.2144],
        [21.9849],
        [67.7147],
        [12.2500],
        [47.0272],
        [ 9.4381],
        [12.9361],
        [44.8332],
        [29.0307],
        [13.5720],
        [17.5919],
        [80.7481],
        [42.5856],
        [14.5613],
        [ 9.2986],
        [12.0436],
        [36.8326],
        [21.8550],
        [11.0613],
        [27.4587],
        [17.0388],
        [27.1385],
        [20.9231],
        [11.7511],
        [12.5515],
        [52.6399],
        [18.1834],
        [11.1197],
        [28.4147],
        [19.5490],
        [79.2663],
        [11.1276],
        [ 9.3763],
        [42.7970],
        [45.8506],
        [10.6877],
        [16.1825],
        [70.0056],
        [13.6980],
        [10.8932],
        [11.7390],
        [19.2031],
        [30.0829],
        [11.2120],
        [11.5562],
        [32.2395],
        [63.6271],
        [10.6980],
        [24.7156],
        [24.2685],
        [59.0707],
        [ 9.4967],
        [37.7241],
        [10.7459],
        [11.3497],
        [61.0037],
        [36.3154],
        [11.1370],
        [10.7281],
        [65.3451],
        [23.9939],
        [14.2198],
        [11.4893],
        [36.9210],
        [56.7587],
        [20.1737],
        [10.1294],
        [10.8861],
        [67.1826],
        [20.9695],
        [11.1202],
        [16.9470],
        [24.1753],
        [11.4966],
        [12.7072],
        [29.3838],
        [28.9632],
        [ 9.4925],
        [10.1730],
        [80.0527],
        [33.8249],
        [28.6876],
        [ 9.7490],
        [53.1823],
        [13.2344],
        [42.3413],
        [47.3124],
        [12.5695],
        [10.3067],
        [26.9052],
        [70.5474],
        [10.5940],
        [11.4365],
        [26.3465],
        [28.7430],
        [11.7235],
        [21.5138],
        [45.4709],
        [10.9353],
        [12.3914],
        [ 9.2371],
        [37.5691],
        [47.3204],
        [15.9742],
        [17.2528],
        [31.0715],
        [65.9497],
        [18.9387],
        [15.9518],
        [31.5728],
        [12.9327],
        [ 9.5353],
        [16.3081],
        [41.8755],
        [20.3373],
        [10.6035],
        [35.1676],
        [15.6250],
        [10.9292],
        [19.0671],
        [48.7518],
        [16.5910],
        [10.7314],
        [23.9573],
        [26.7195],
        [30.8686],
        [14.8029],
        [75.2526],
        [39.9549],
        [ 9.3640],
        [11.5521],
        [57.0292]], device='cuda:0', dtype=torch.float64)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64), tensor([[ 708.0655],
        [2031.4019],
        [2915.7359],
        [1585.8275],
        [ 647.0661],
        [ 883.4503],
        [2959.8029],
        [ 957.5514],
        [1012.1716],
        [5363.2380],
        [1733.4562],
        [1114.0342],
        [ 972.2719],
        [2811.7752],
        [3242.9229],
        [ 668.3336],
        [3283.3609],
        [ 650.7103],
        [ 634.4424],
        [2894.3986],
        [5118.3414],
        [ 775.4529],
        [1618.4367],
        [1356.6144],
        [1027.1797],
        [ 686.3990],
        [ 856.1055],
        [3105.1109],
        [1285.8402],
        [ 767.4203],
        [1057.2506],
        [1620.7397],
        [4020.9401],
        [ 622.5807],
        [1166.1465],
        [2065.1232],
        [4448.6041],
        [ 749.1892],
        [ 751.8039],
        [1813.8747],
        [1645.8845],
        [ 726.6516],
        [ 673.7424],
        [ 902.4678],
        [ 788.9320],
        [ 688.4275],
        [1212.4894],
        [4488.5844],
        [ 660.9054],
        [ 767.9148],
        [4554.5143],
        [1363.4143],
        [ 701.8773],
        [2763.7875],
        [1850.0250],
        [1063.6069],
        [ 765.2583],
        [3865.8456],
        [2225.2882],
        [ 882.0873],
        [ 702.3124],
        [4257.2211],
        [2451.8363],
        [ 918.3025],
        [ 727.1627],
        [3831.3851],
        [2625.6788],
        [1265.7433],
        [ 708.6436],
        [5302.0111],
        [1748.5566],
        [ 670.9112],
        [ 821.3871],
        [1499.4303],
        [1168.4045],
        [ 640.3162],
        [ 724.0030],
        [ 998.5122],
        [4090.6895],
        [1655.6224],
        [ 847.9758],
        [ 766.0677],
        [1551.9579],
        [3524.5875],
        [2041.9342],
        [ 724.2890],
        [ 812.3924],
        [2155.7848],
        [3957.3355],
        [ 873.6093],
        [ 867.9827],
        [1760.4172],
        [3534.9293],
        [ 730.5734],
        [1090.8339],
        [2586.8320],
        [1558.6479],
        [ 684.2619],
        [1219.1772],
        [3219.7315],
        [ 946.5611],
        [ 639.5795],
        [1021.7096],
        [2259.1464],
        [4324.2896],
        [1114.5531],
        [1448.1223],
        [1896.8557],
        [3022.1099],
        [1246.3499],
        [ 644.8563],
        [2550.5560],
        [ 674.6806],
        [4118.3637],
        [2658.7553],
        [ 682.2521],
        [1064.6567],
        [4783.7650],
        [1877.5245],
        [1802.6775],
        [ 677.3773],
        [1304.4498],
        [2924.9520],
        [1089.2295],
        [ 733.6874],
        [1203.1464],
        [2057.4076],
        [ 994.9936],
        [ 872.2641],
        [ 645.7052],
        [ 917.4017],
        [2905.7603],
        [1840.6578],
        [ 755.4286],
        [1412.0328],
        [2711.7898],
        [2390.7195],
        [1193.1971],
        [ 765.9485],
        [2870.4914],
        [5198.6652],
        [ 941.0297],
        [1233.7580],
        [1615.9908],
        [ 925.7558],
        [5627.1290],
        [1642.2272],
        [1293.2367],
        [ 646.3938],
        [3436.3289],
        [2972.0917],
        [ 640.0082],
        [ 755.0289],
        [1300.0064],
        [1612.9885],
        [1078.7345],
        [ 713.3283],
        [1118.1143],
        [3387.8641],
        [ 977.9293],
        [ 815.7947],
        [4867.4515],
        [2132.5891],
        [ 689.4622],
        [ 626.9148],
        [4140.1082],
        [2092.2212],
        [1177.1525],
        [ 687.4571],
        [ 832.3273],
        [4700.9883],
        [1243.3752],
        [ 760.3269],
        [2004.1576],
        [1093.7835],
        [ 778.0757],
        [2584.0050],
        [ 702.5588],
        [1000.2461],
        [1704.3218],
        [ 716.2670],
        [ 687.1467],
        [1207.0030],
        [3985.9369],
        [3827.7864],
        [ 663.8015],
        [ 957.0802],
        [2232.6704],
        [3786.5503],
        [ 761.8087],
        [ 905.3534],
        [2130.8954],
        [5083.5696],
        [ 680.8066],
        [ 676.4734],
        [1684.9204],
        [3444.6372],
        [ 646.4265],
        [1553.2567],
        [2243.8210],
        [ 930.0009],
        [ 784.1575],
        [1426.0829],
        [3787.2932],
        [1459.1041],
        [ 800.9905],
        [ 635.6337],
        [1175.6453],
        [ 805.7763],
        [2270.7483],
        [2340.6978],
        [ 883.3693],
        [ 746.6593],
        [ 850.4259],
        [3570.0208],
        [1622.9349],
        [ 771.9403],
        [3634.1403],
        [2724.5108],
        [1004.7033],
        [ 761.3029],
        [4540.3632],
        [2035.1544],
        [ 726.2817],
        [ 635.6503],
        [1152.5474],
        [2691.9955],
        [1164.2300],
        [ 674.1085],
        [1656.2020],
        [3426.0804],
        [1284.0179],
        [1256.2465],
        [3064.6533],
        [2624.3751],
        [ 646.7067],
        [1247.4290],
        [4849.4607],
        [2124.9857],
        [1338.5581],
        [4606.9524],
        [1036.5241],
        [1823.5577],
        [1821.6547],
        [3779.8628],
        [ 686.6350],
        [ 662.7770],
        [2318.9746],
        [ 998.2448],
        [ 736.7611],
        [ 835.5941],
        [1669.4224],
        [1186.5111],
        [ 665.0936],
        [1047.2330],
        [2743.4763],
        [ 978.6121],
        [1699.7394],
        [4752.1137],
        [1049.8234],
        [ 636.0765],
        [3012.3595],
        [2915.6867],
        [ 855.9663],
        [1367.1386],
        [2277.4864],
        [1718.0094],
        [ 756.8693],
        [ 854.8384],
        [2374.8687],
        [ 739.6287],
        [ 612.6947],
        [3681.7500],
        [ 862.5568],
        [ 777.2723],
        [1324.5916],
        [2189.2094],
        [1359.5483],
        [ 742.1916],
        [1665.8614],
        [3207.9614],
        [ 611.8345],
        [ 706.6336],
        [3320.6798],
        [1342.3447],
        [1875.2872],
        [ 759.0634],
        [5431.6238],
        [1286.3702],
        [ 799.3560],
        [ 764.1036],
        [2059.6953],
        [5009.2629],
        [1268.8187],
        [ 708.7846],
        [ 995.5688],
        [1927.2074],
        [1333.1210],
        [ 621.0265],
        [4353.1556],
        [2222.3598],
        [ 733.0112],
        [ 748.1840],
        [4423.4932],
        [ 882.2105],
        [2123.1532],
        [3795.4074],
        [ 710.2952],
        [ 764.5678],
        [2392.4967],
        [3961.2823],
        [ 722.3207],
        [1297.5015],
        [3715.5421],
        [ 725.5634],
        [ 689.4048],
        [ 865.9873],
        [1468.0298],
        [2211.7193],
        [ 726.1421],
        [ 675.4848],
        [1301.7884],
        [1612.1952],
        [ 780.8007],
        [1361.9652],
        [4269.3705],
        [1053.7400],
        [ 754.8662],
        [1880.1715],
        [2216.3266],
        [3424.7452],
        [ 646.9441],
        [ 675.6681],
        [1644.2829],
        [4876.6589],
        [ 663.0191],
        [1887.9690],
        [ 676.1374],
        [ 715.7019],
        [4784.1688],
        [3090.1657],
        [ 843.1198],
        [ 917.3561],
        [3556.5855],
        [3509.0323],
        [1640.5341],
        [ 722.7457],
        [ 779.3504],
        [1898.0279],
        [ 811.6367],
        [ 801.4048],
        [2060.3242],
        [2185.2106],
        [1040.2105],
        [1356.5650],
        [4488.1035],
        [2795.2680],
        [ 608.0845],
        [ 875.6210],
        [3606.2905],
        [2974.1450],
        [1201.6144],
        [ 710.6251],
        [1494.7701],
        [2136.5777],
        [1105.4418],
        [ 630.3633],
        [ 871.2625],
        [ 941.8266],
        [2932.0899],
        [1446.7776],
        [ 708.6042],
        [1022.4334],
        [2327.3865],
        [1247.9371],
        [ 730.1267],
        [ 616.2972],
        [2571.7520],
        [3609.2075],
        [ 826.7756],
        [2535.2188],
        [1462.3726],
        [4485.3251],
        [ 818.8516],
        [3117.7853],
        [ 632.9695],
        [ 864.2048],
        [2972.7513],
        [1928.1324],
        [ 906.2431],
        [1171.9783],
        [5346.8981],
        [2824.1755],
        [ 971.6388],
        [ 623.7461],
        [ 805.2072],
        [2443.8739],
        [1453.7836],
        [ 740.2702],
        [1824.2146],
        [1135.4149],
        [1803.0505],
        [1392.1816],
        [ 785.8709],
        [ 838.7840],
        [3488.8111],
        [1211.0791],
        [ 744.1307],
        [1887.4130],
        [1301.3453],
        [5248.9445],
        [ 744.6543],
        [ 628.8833],
        [2838.1490],
        [3040.0112],
        [ 715.5727],
        [1078.8042],
        [4636.7701],
        [ 914.5676],
        [ 729.1606],
        [ 785.0714],
        [1278.4808],
        [1997.6903],
        [ 750.2331],
        [ 772.9843],
        [2140.2483],
        [4215.1169],
        [ 716.2540],
        [1642.8824],
        [1613.3308],
        [3913.9169],
        [ 636.8466],
        [2502.8116],
        [ 719.4238],
        [ 759.3342],
        [4041.6969],
        [2409.6859],
        [ 745.2732],
        [ 718.2469],
        [4328.6849],
        [1595.1748],
        [ 949.0623],
        [ 768.5658],
        [2449.7193],
        [3761.0840],
        [1342.6430],
        [ 678.6712],
        [ 728.6904],
        [4450.1508],
        [1395.2505],
        [ 744.1676],
        [1129.3472],
        [1607.1674],
        [ 769.0443],
        [ 849.0752],
        [1951.4720],
        [1923.6701],
        [ 636.5671],
        [ 681.5505],
        [5300.9286],
        [2245.0528],
        [1905.4531],
        [ 653.5231],
        [3524.6702],
        [ 883.9244],
        [2808.0270],
        [3136.6384],
        [ 839.9685],
        [ 690.3895],
        [1787.6276],
        [4672.5817],
        [ 709.3822],
        [ 765.0713],
        [1750.6937],
        [1909.1161],
        [ 784.0455],
        [1431.2301],
        [3014.9079],
        [ 731.9453],
        [ 828.1950],
        [ 619.6844],
        [2492.5609],
        [3137.1660],
        [1065.0404],
        [1149.5582],
        [2063.0376],
        [4368.6517],
        [1261.0064],
        [1063.5600],
        [2096.1767],
        [ 863.9773],
        [ 639.3953],
        [1087.1081],
        [2777.2357],
        [1353.4618],
        [ 710.0076],
        [2333.8093],
        [1041.9567],
        [ 731.5389],
        [1269.4959],
        [3231.7918],
        [1105.8107],
        [ 718.4656],
        [1592.7569],
        [1775.3535],
        [2049.6255],
        [ 987.6104],
        [4983.6183],
        [2650.2769],
        [ 628.0734],
        [ 772.7127],
        [3778.9646]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.3465],
        [24.7056],
        [34.2136],
        [12.6906],
        [12.7277],
        [30.6497],
        [13.5586],
        [ 9.7490],
        [13.9314],
        [ 9.8927]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 626.9148],
        [1642.2272],
        [2270.7483],
        [ 847.9758],
        [ 850.4259],
        [2035.1544],
        [ 905.3534],
        [ 653.5231],
        [ 930.0009],
        [ 663.0191]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.3488],
        [24.7017],
        [34.2016],
        [12.6846],
        [12.7219],
        [30.6426],
        [13.5555],
        [ 9.7493],
        [13.9222],
        [ 9.8927]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 627.0692],
        [1641.9638],
        [2269.9564],
        [ 847.5821],
        [ 850.0469],
        [2034.6893],
        [ 905.1505],
        [ 653.5447],
        [ 929.3922],
        [ 663.0227]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[25.0163],
        [15.1583],
        [ 9.8721],
        [23.3832],
        [22.6598],
        [13.3983],
        [10.8050],
        [12.2711],
        [34.3082],
        [10.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[1662.7633],
        [1011.1037],
        [ 661.6580],
        [1554.8045],
        [1506.9897],
        [ 894.7567],
        [ 723.3318],
        [ 820.2435],
        [2277.0025],
        [ 672.0605]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[18.9903],
        [13.7460],
        [10.6143],
        [11.2690],
        [11.0378],
        [11.0674],
        [12.1383],
        [10.3604],
        [17.1765],
        [ 9.9329]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[1264.4139],
        [ 917.7455],
        [ 710.7216],
        [ 754.0047],
        [ 738.7199],
        [ 740.6726],
        [ 811.4648],
        [ 693.9417],
        [1144.5157],
        [ 665.6795]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[11.9580],
        [13.1944],
        [10.6992],
        [10.0859],
        [ 9.8940],
        [11.7422],
        [10.4722],
        [10.3151],
        [ 9.2086],
        [ 9.9038]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[799.5502],
        [881.2785],
        [716.3368],
        [675.7934],
        [663.1059],
        [785.2798],
        [701.3262],
        [690.9468],
        [617.7993],
        [663.7545]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[17.2616],
        [12.8847],
        [11.3013],
        [10.9459],
        [12.2227],
        [16.1964],
        [ 9.7257],
        [ 9.8356],
        [28.4887],
        [ 9.8742]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[1150.1414],
        [ 860.8082],
        [ 756.1367],
        [ 732.6406],
        [ 817.0456],
        [1079.7235],
        [ 651.9799],
        [ 659.2471],
        [1892.3049],
        [ 661.7976]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0983],
        [13.1600],
        [10.8494],
        [ 9.8826],
        [ 9.8542],
        [12.6498],
        [ 9.9437],
        [10.1718],
        [10.2086],
        [ 9.8954]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[676.6149],
        [879.0050],
        [726.2634],
        [662.3534],
        [660.4785],
        [845.2769],
        [666.3905],
        [681.4728],
        [683.9072],
        [663.2029]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[12.2542],
        [11.7527],
        [10.2826],
        [ 9.9939],
        [10.2947],
        [10.4297],
        [10.1110],
        [ 9.9675],
        [17.7752],
        [ 9.8976]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[ 819.1260],
        [ 785.9769],
        [ 688.7931],
        [ 669.7143],
        [ 689.5940],
        [ 698.5220],
        [ 677.4550],
        [ 667.9645],
        [1184.0892],
        [ 663.3461]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.0779],
        [12.6317],
        [10.2859],
        [ 9.8384],
        [ 9.9210],
        [11.7875],
        [ 9.8661],
        [10.0985],
        [12.0701],
        [ 9.8962]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[675.2619],
        [844.0817],
        [689.0135],
        [659.4352],
        [664.8957],
        [788.2746],
        [661.2648],
        [676.6228],
        [806.9551],
        [663.2531]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[10.1963],
        [11.8256],
        [10.4264],
        [10.0815],
        [ 9.9280],
        [10.2572],
        [10.0563],
        [ 9.8357],
        [10.2103],
        [ 9.9247]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[683.0898],
        [790.7946],
        [698.2996],
        [675.5043],
        [665.3580],
        [687.1156],
        [673.8385],
        [659.2552],
        [684.0148],
        [665.1403]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9568],
        [12.1018],
        [10.1487],
        [10.0288],
        [10.0103],
        [11.5156],
        [ 9.9684],
        [ 9.8329],
        [10.6426],
        [ 9.9421]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[667.2585],
        [809.0554],
        [679.9423],
        [672.0158],
        [670.7960],
        [770.3059],
        [668.0287],
        [659.0690],
        [712.5945],
        [666.2896]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8339],
        [11.9717],
        [ 9.9681],
        [10.0018],
        [10.0371],
        [11.9253],
        [ 9.9170],
        [10.1267],
        [10.9850],
        [ 9.9540]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[659.1367],
        [800.4532],
        [668.0046],
        [670.2367],
        [672.5651],
        [797.3847],
        [664.6255],
        [678.4929],
        [735.2279],
        [667.0715]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.6419],
        [ 9.2931],
        [ 9.6262],
        [10.4561],
        [10.0457],
        [12.7288],
        [ 9.8748],
        [12.7773],
        [11.5561],
        [ 9.9754]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[646.4413],
        [623.3823],
        [645.4076],
        [700.2624],
        [673.1348],
        [850.4987],
        [661.8417],
        [853.7099],
        [772.9810],
        [668.4889]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.7954],
        [11.6059],
        [ 9.8994],
        [10.0151],
        [10.0335],
        [12.0554],
        [ 9.9027],
        [10.3412],
        [11.0662],
        [ 9.9570]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[656.5922],
        [776.2717],
        [663.4649],
        [671.1118],
        [672.3274],
        [805.9868],
        [663.6796],
        [692.6675],
        [740.5937],
        [667.2752]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.7825],
        [10.3417],
        [ 9.7908],
        [10.0013],
        [ 9.9925],
        [12.1325],
        [ 9.8811],
        [10.3885],
        [11.0795],
        [ 9.9436]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[655.7369],
        [692.7006],
        [656.2888],
        [670.1974],
        [669.6202],
        [811.0860],
        [662.2542],
        [695.7982],
        [741.4777],
        [666.3835]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8545],
        [12.5068],
        [ 9.9081],
        [ 9.9242],
        [ 9.9506],
        [11.7215],
        [ 9.9124],
        [10.1281],
        [10.6028],
        [ 9.9300]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[660.4975],
        [835.8282],
        [664.0427],
        [665.1070],
        [666.8483],
        [783.9126],
        [664.3251],
        [678.5848],
        [709.9644],
        [665.4874]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.8866],
        [11.8673],
        [ 9.8684],
        [ 9.9283],
        [ 9.9579],
        [11.4160],
        [ 9.9380],
        [10.0886],
        [10.2320],
        [ 9.9368]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[662.6188],
        [793.5549],
        [661.4183],
        [665.3745],
        [667.3336],
        [763.7162],
        [666.0192],
        [675.9702],
        [685.4504],
        [665.9360]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9261],
        [11.2667],
        [ 9.9460],
        [ 9.8831],
        [ 9.9182],
        [11.2533],
        [ 9.9289],
        [ 9.9442],
        [ 9.9504],
        [ 9.9327]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[665.2277],
        [753.8503],
        [666.5425],
        [662.3878],
        [664.7106],
        [752.9621],
        [665.4151],
        [666.4267],
        [666.8385],
        [665.6656]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9544],
        [10.8779],
        [ 9.9728],
        [ 9.8365],
        [ 9.8677],
        [11.1329],
        [ 9.9605],
        [ 9.8791],
        [ 9.8255],
        [ 9.9298]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[667.0997],
        [728.1486],
        [668.3173],
        [659.3053],
        [661.3670],
        [745.0037],
        [667.5027],
        [662.1229],
        [658.5793],
        [665.4751]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9626],
        [11.1925],
        [ 9.9701],
        [ 9.9222],
        [ 9.9225],
        [11.2688],
        [ 9.9341],
        [ 9.8726],
        [ 9.9621],
        [ 9.9307]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[667.6418],
        [748.9450],
        [668.1364],
        [664.9734],
        [664.9903],
        [753.9904],
        [665.7610],
        [661.6902],
        [667.6124],
        [665.5306]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 9.9435],
        [11.3452],
        [ 9.9385],
        [ 9.9479],
        [ 9.9414],
        [11.3279],
        [ 9.9288],
        [ 9.9163],
        [ 9.8892],
        [ 9.9328]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>), tensor([[666.3769],
        [759.0385],
        [666.0477],
        [666.6723],
        [666.2416],
        [757.8972],
        [665.4107],
        [664.5806],
        [662.7922],
        [665.6749]], device='cuda:0', dtype=torch.float64,
       grad_fn=<AddBackward0>)]
BEFORE NORMALIZATION:
[tensor([[9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237],
        [9.5237]], device='cuda:0', dtype=torch.float64), tensor([[9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779],
        [9.9779]], device='cuda:0', dtype=torch.float64), tensor([[ 9.9435],
        [11.3452],
        [ 9.9385],
        [ 9.9479],
        [ 9.9414],
        [11.3279],
        [ 9.9288],
        [ 9.9163],
        [ 9.8892],
        [ 9.9328]], device='cuda:0', dtype=torch.float64)]
AFTER NORMALIZATION:
[tensor([[217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679],
        [217.6679]], device='cuda:0', dtype=torch.float64), tensor([[557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963],
        [557.6963]], device='cuda:0', dtype=torch.float64), tensor([[666.3769],
        [759.0385],
        [666.0477],
        [666.6723],
        [666.2416],
        [757.8972],
        [665.4107],
        [664.5806],
        [662.7922],
        [665.6749]], device='cuda:0', dtype=torch.float64)]
