BEFORE NORMALIZATION: [tensor([[142.3885],
        [145.5871],
        [174.8970],
        [170.9017],
        [179.5178],
        [150.0107],
        [141.9908],
        [165.6734],
        [159.1328],
        [140.4244],
        [164.2126],
        [179.9829],
        [179.0162],
        [170.2043],
        [142.2457],
        [152.8613],
        [150.0684],
        [141.1142],
        [165.5602],
        [176.9768],
        [179.6611],
        [161.1531],
        [140.0129],
        [154.1409],
        [168.5755],
        [140.9390],
        [154.6948],
        [177.9087],
        [173.1661],
        [176.7816],
        [149.3217],
        [145.3439],
        [146.5491],
        [147.5825],
        [175.7529],
        [174.8303],
        [178.5755],
        [156.8386],
        [140.4644],
        [166.4709],
        [156.3322],
        [140.1607],
        [158.9441],
        [179.8963],
        [175.6392],
        [167.2242],
        [141.9286],
        [148.6211],
        [151.3021],
        [143.3250],
        [171.6905],
        [178.1670],
        [179.9836],
        [162.0490],
        [140.1306],
        [161.3997],
        [163.4817],
        [141.2735],
        [151.9798],
        [179.8114],
        [172.7651],
        [173.6653],
        [144.1855],
        [143.2645],
        [144.1985],
        [145.0543],
        [172.6357],
        [171.4813],
        [179.5795],
        [153.4769],
        [141.9017],
        [162.1272],
        [160.7851],
        [140.0921],
        [162.4231],
        [179.9487],
        [178.0097],
        [171.1848],
        [143.6772],
        [151.6417],
        [147.5300],
        [141.2989],
        [168.7063],
        [176.4548],
        [179.6686],
        [157.5889],
        [140.0342],
        [157.9305],
        [166.8186],
        [140.3416],
        [156.2247],
        [178.7114],
        [175.2362],
        [175.9768],
        [147.2896],
        [146.0937],
        [144.9270],
        [149.0061],
        [176.9793],
        [173.6239],
        [178.0731],
        [154.0955],
        [140.7617],
        [168.9062],
        [155.7039],
        [140.0106],
        [159.7942],
        [179.3034],
        [177.6594],
        [167.0922],
        [140.6464],
        [148.9113],
        [153.2141],
        [142.5417],
        [169.6700],
        [178.8991],
        [179.9990],
        [164.5789],
        [140.3522],
        [158.5174],
        [164.3500],
        [142.7514],
        [151.4351],
        [179.1759],
        [169.5125],
        [173.9498],
        [146.5623],
        [143.2064],
        [142.7459],
        [146.1699],
        [174.3780],
        [170.3347],
        [179.1797],
        [151.0603],
        [142.5104],
        [164.4314],
        [158.4339],
        [140.2672],
        [164.9836],
        [179.9991],
        [178.5681],
        [169.1346],
        [142.8097],
        [154.0462],
        [149.4438],
        [140.8603],
        [166.2835],
        [177.3183],
        [179.3693],
        [159.9586],
        [140.0043],
        [155.3849],
        [169.1979],
        [140.6988],
        [153.9386],
        [178.1821],
        [174.1303],
        [177.4170],
        [148.3560],
        [144.5183],
        [146.0423],
        [146.9266],
        [176.2259],
        [175.2477],
        [179.0237],
        [155.6350],
        [140.2481],
        [167.6474],
        [157.0485],
        [140.0738],
        [158.1878],
        [179.8178],
        [176.4448],
        [168.3260],
        [141.4726],
        [147.5861],
        [151.9369],
        [143.8114],
        [171.0379],
        [177.8911],
        [179.8872],
        [163.2613],
        [140.0318],
        [160.1475],
        [162.7600],
        [141.5787],
        [152.6823],
        [179.7088],
        [171.7006],
        [172.7721],
        [144.9022],
        [144.0021],
        [143.7790],
        [144.5002],
        [173.2397],
        [171.9967],
        [179.8053],
        [152.3344],
        [141.4383],
        [163.3694],
        [161.5136],
        [140.1879],
        [161.6655],
        [179.9854],
        [178.5543],
        [172.1523],
        [143.0510],
        [150.4933],
        [148.0808],
        [141.6172],
        [167.9895],
        [176.0861],
        [179.8649],
        [158.8104],
        [140.1361],
        [156.6855],
        [166.1305],
        [140.5090],
        [156.9709],
        [178.4667],
        [174.3279],
        [175.2297],
        [148.1848],
        [147.0485],
        [145.4142],
        [149.6992],
        [176.5665],
        [173.1297],
        [177.4539],
        [155.2483],
        [141.1020],
        [167.7351],
        [155.0270],
        [140.0010],
        [160.5819],
        [179.4594],
        [177.0022],
        [165.9336],
        [140.9728],
        [149.9792],
        [152.5314],
        [142.1546],
        [170.3288],
        [179.1071],
        [179.9399],
        [163.4123],
        [140.5946],
        [159.8008],
        [165.0297],
        [142.3351],
        [150.7251],
        [179.3473],
        [170.6485],
        [174.7998],
        [145.7263],
        [142.5592],
        [142.6308],
        [145.9272],
        [174.5642],
        [170.4725],
        [179.4062],
        [150.4470],
        [142.2174],
        [165.1998],
        [159.6404],
        [140.5311],
        [163.7379],
        [179.9559],
        [179.1629],
        [170.6375],
        [142.0210],
        [152.4111],
        [149.6376],
        [140.9603],
        [166.0314],
        [177.2396],
        [179.5667],
        [160.6539],
        [140.0011],
        [154.6131],
        [168.1143],
        [141.0938],
        [155.1632],
        [177.6806],
        [172.7917],
        [176.5001],
        [149.7475],
        [145.6779],
        [146.9233],
        [147.9656],
        [175.4449],
        [174.4850],
        [178.3906],
        [157.3330],
        [140.5794],
        [166.0035],
        [156.8323],
        [140.1045],
        [158.4609],
        [179.8393],
        [175.9411],
        [167.6954],
        [141.7201],
        [148.2261],
        [150.8548],
        [143.0624],
        [172.0861],
        [178.3734],
        [179.9974],
        [161.5512],
        [140.1951],
        [161.8904],
        [162.9807],
        [141.4520],
        [152.4260],
        [179.7368],
        [172.3824],
        [173.2904],
        [144.4964],
        [143.5346],
        [143.8968],
        [144.7369],
        [173.0134],
        [171.8931],
        [179.6726],
        [153.0065],
        [141.6914],
        [162.6156],
        [160.2777],
        [140.0510],
        [162.9029],
        [179.9066],
        [177.7903],
        [170.7602],
        [143.9710],
        [152.0842],
        [147.9247],
        [141.4762],
        [168.2607],
        [176.1610],
        [179.7507],
        [158.0859],
        [140.0703],
        [157.4416],
        [167.2937],
        [140.2570],
        [155.7500],
        [178.8820],
        [175.5505],
        [176.2768],
        [146.9075],
        [145.7497],
        [144.6032],
        [148.6047],
        [177.2339],
        [173.9913],
        [178.2752],
        [153.6197],
        [140.6291],
        [169.3441],
        [155.2094],
        [140.0006],
        [160.2786],
        [179.4281],
        [177.4231],
        [166.6154],
        [140.7785],
        [149.3175],
        [153.6865],
        [142.7831],
        [169.2363],
        [178.7270],
        [179.9980],
        [165.0639],
        [140.2637],
        [158.0271],
        [164.8438],
        [142.5075],
        [151.0000],
        [179.3119],
        [169.9423],
        [174.3091],
        [146.1964],
        [142.9482],
        [143.0041],
        [146.5239],
        [174.0318],
        [169.8967],
        [179.0368],
        [151.5104],
        [142.7623],
        [163.9502],
        [158.9407],
        [140.3533],
        [164.5130],
        [179.9881],
        [178.7452],
        [169.5832],
        [142.5595],
        [153.5857],
        [149.0225],
        [140.7254],
        [166.7489],
        [177.5665],
        [179.2429],
        [159.4589],
        [140.0213],
        [155.8650],
        [168.7444],
        [140.8337],
        [154.4018],
        [177.9681],
        [173.7780],
        [177.1618],
        [148.7658],
        [144.8296],
        [146.4049],
        [147.2968],
        [175.9333],
        [174.9144],
        [178.8686],
        [156.1240],
        [140.3342],
        [167.1905],
        [157.5514],
        [140.0376],
        [157.7061],
        [179.7442],
        [176.7198],
        [168.7850],
        [141.2899],
        [147.2099],
        [151.4821],
        [143.5316],
        [171.4449],
        [178.1122],
        [179.9328],
        [162.7671],
        [140.0669],
        [160.6397],
        [162.2564],
        [141.7759],
        [153.1354],
        [179.6178],
        [171.2978],
        [172.3775],
        [145.2349],
        [144.2974],
        [143.4916],
        [144.1987],
        [173.6046],
        [172.3989],
        [179.8669],
        [151.8751],
        [141.2553],
        [163.8532],
        [161.0068],
        [140.1266],
        [162.1474],
        [179.9601],
        [178.3651],
        [171.7451],
        [143.3216],
        [150.9223],
        [148.4858],
        [141.8134],
        [167.5361],
        [175.7793],
        [179.9153],
        [159.3098],
        [140.2015],
        [156.2011],
        [166.6118],
        [140.4046],
        [156.4929],
        [178.6528],
        [174.6670],
        [175.5537],
        [147.7852],
        [146.6832],
        [145.0768],
        [149.2870],
        [176.8371],
        [173.5085],
        [177.6852],
        [154.7641],
        [140.9419],
        [168.1866],
        [154.5369],
        [140.0120],
        [161.0658],
        [179.5687],
        [176.7379],
        [165.4470],
        [141.1328],
        [150.4011],
        [152.9975],
        [142.3784],
        [169.9042],
        [178.9510],
        [179.9715],
        [163.9035],
        [140.4780],
        [159.3088],
        [165.5191],
        [142.1096],
        [150.2989],
        [179.4679],
        [171.0617],
        [175.1365],
        [145.3808],
        [142.3272]], device='cuda:0', dtype=torch.float64), tensor([[75.0703],
        [41.4119],
        [64.2435],
        [51.6881],
        [61.0223],
        [72.4932],
        [35.2420],
        [74.0302],
        [36.0483],
        [75.8277],
        [70.3055],
        [65.7143],
        [61.5228],
        [53.1337],
        [86.3652],
        [39.6187],
        [87.5631],
        [35.1431],
        [68.1909],
        [51.5884],
        [49.4679],
        [57.5461],
        [37.9250],
        [89.6168],
        [44.9967],
        [89.0338],
        [37.8727],
        [66.4291],
        [69.8908],
        [61.7676],
        [87.3461],
        [35.0081],
        [62.7331],
        [67.4877],
        [36.5570],
        [88.7283],
        [89.5605],
        [38.3740],
        [62.8284],
        [39.6119],
        [65.7181],
        [49.8731],
        [89.3853],
        [40.7054],
        [35.0429],
        [83.8818],
        [48.7136],
        [72.9867],
        [50.9960],
        [67.4900],
        [43.2462],
        [81.9585],
        [71.7223],
        [35.1135],
        [71.2610],
        [64.1276],
        [68.8389],
        [68.0444],
        [85.7808],
        [35.4364],
        [37.4554],
        [78.4790],
        [55.4370],
        [59.2046],
        [37.6739],
        [67.1101],
        [55.0538],
        [74.9960],
        [74.5571],
        [50.4239],
        [65.1239],
        [54.5078],
        [83.8262],
        [45.2385],
        [70.1317],
        [50.3548],
        [56.8404],
        [74.8412],
        [36.5610],
        [64.5917],
        [49.0484],
        [85.3220],
        [42.7768],
        [71.9072],
        [73.9636],
        [45.0424],
        [81.4255],
        [35.6111],
        [73.2214],
        [40.3622],
        [74.7804],
        [50.7755],
        [38.5482],
        [73.1290],
        [51.8904],
        [83.4547],
        [69.4951],
        [35.3384],
        [87.3302],
        [46.8926],
        [36.9202],
        [79.9593],
        [45.8800],
        [74.5475],
        [40.3251],
        [74.9842],
        [38.8324],
        [76.9365],
        [81.7957],
        [55.8512],
        [73.9707],
        [46.6882],
        [74.9622],
        [51.2223],
        [60.3975],
        [41.0986],
        [53.7129],
        [78.5064],
        [50.6233],
        [72.6630],
        [49.8954],
        [70.6030],
        [50.4146],
        [73.8638],
        [81.8224],
        [36.2471],
        [73.4333],
        [57.5338],
        [66.6395],
        [50.6986],
        [80.8598],
        [43.9614],
        [35.0523],
        [71.8345],
        [63.2318],
        [70.6182],
        [67.3488],
        [68.3419],
        [35.3422],
        [85.3246],
        [76.0693],
        [37.6835],
        [58.5415],
        [54.9849],
        [65.3247],
        [61.4505],
        [89.4242],
        [35.7521],
        [39.8506],
        [89.4867],
        [38.5884],
        [60.3704],
        [49.5026],
        [63.7596],
        [42.2131],
        [89.7879],
        [85.2608],
        [35.2816],
        [71.8991],
        [48.6633],
        [35.5427],
        [87.2069],
        [53.5136],
        [69.5819],
        [59.5803],
        [46.4181],
        [89.9261],
        [36.8534],
        [88.2094],
        [42.7889],
        [68.3536],
        [37.8625],
        [61.4788],
        [71.4224],
        [35.1088],
        [85.8876],
        [40.9948],
        [75.0774],
        [51.3910],
        [64.6914],
        [72.7333],
        [61.4493],
        [77.9682],
        [35.1477],
        [76.1143],
        [36.4437],
        [66.4569],
        [71.0575],
        [53.6170],
        [62.3582],
        [38.9415],
        [88.6160],
        [52.9417],
        [74.6977],
        [39.6435],
        [58.1567],
        [71.8248],
        [51.6828],
        [73.6044],
        [50.1864],
        [72.1115],
        [49.9782],
        [71.4530],
        [48.0589],
        [35.5390],
        [77.1302],
        [59.7216],
        [74.2926],
        [35.5899],
        [70.0382],
        [46.4524],
        [86.3368],
        [79.5107],
        [36.7191],
        [74.6789],
        [51.6436],
        [75.0155],
        [42.0761],
        [75.9787],
        [38.3371],
        [54.9857],
        [81.0600],
        [49.4619],
        [74.2827],
        [86.0063],
        [50.0991],
        [71.4075],
        [40.6436],
        [43.7063],
        [73.6301],
        [35.9073],
        [82.4765],
        [40.8493],
        [73.8924],
        [49.5568],
        [74.8481],
        [72.9074],
        [36.2611],
        [83.9984],
        [52.5839],
        [71.7846],
        [39.1569],
        [74.8932],
        [53.5281],
        [50.9966],
        [73.8942],
        [57.1937],
        [67.8157],
        [47.2789],
        [86.0516],
        [50.0690],
        [68.6946],
        [74.4740],
        [55.3177],
        [69.3404],
        [37.5571],
        [49.9560],
        [85.5052],
        [35.1952],
        [71.5420],
        [73.6731],
        [50.4486],
        [82.6152],
        [35.8356],
        [73.9794],
        [40.9537],
        [74.8722],
        [38.3809],
        [47.2670],
        [72.7863],
        [52.8283],
        [84.2399],
        [39.0744],
        [63.6632],
        [53.2007],
        [74.9171],
        [73.9417],
        [51.5966],
        [74.0659],
        [56.9672],
        [76.0468],
        [47.5197],
        [68.5151],
        [49.9520],
        [55.3124],
        [74.4399],
        [37.6189],
        [78.6395],
        [74.6717],
        [53.2148],
        [62.9990],
        [39.5224],
        [51.4730],
        [67.9001],
        [49.8723],
        [73.6934],
        [50.0117],
        [72.0345],
        [48.1917],
        [81.0151],
        [68.1776],
        [35.6012],
        [74.2265],
        [59.4714],
        [70.0794],
        [44.1654],
        [87.1945],
        [46.2316],
        [36.6599],
        [78.6137],
        [42.2899],
        [74.8190],
        [53.0470],
        [75.0002],
        [38.4742],
        [76.3551],
        [81.0189],
        [55.1324],
        [74.2679],
        [38.0057],
        [87.3551],
        [35.6008],
        [69.7182],
        [57.7014],
        [41.7567],
        [59.7534],
        [36.7920],
        [89.7379],
        [42.9844],
        [88.3439],
        [47.1207],
        [68.1654],
        [71.3442],
        [52.0243],
        [85.9334],
        [35.0941],
        [84.6954],
        [40.7829],
        [64.8198],
        [52.1746],
        [60.6092],
        [72.8458],
        [35.2460],
        [69.4640],
        [36.3672],
        [87.8100],
        [71.0711],
        [66.3354],
        [62.1296],
        [53.3297],
        [77.6403],
        [39.1065],
        [50.4663],
        [66.8385],
        [43.8024],
        [74.1558],
        [77.0967],
        [35.0015],
        [70.7093],
        [63.8331],
        [68.1585],
        [67.0398],
        [74.2439],
        [35.3078],
        [37.7505],
        [86.9511],
        [54.9498],
        [58.3963],
        [54.8683],
        [65.5246],
        [35.7928],
        [88.7417],
        [89.9667],
        [39.6915],
        [60.5334],
        [46.2734],
        [63.6372],
        [40.0066],
        [89.7202],
        [42.3265],
        [35.3243],
        [85.5209],
        [58.3050],
        [71.7510],
        [39.6276],
        [69.3595],
        [47.0262],
        [87.6393],
        [79.9454],
        [37.0270],
        [74.5200],
        [41.3547],
        [74.9857],
        [50.2411],
        [76.8304],
        [38.7455],
        [55.6073],
        [81.5473],
        [37.7796],
        [74.0519],
        [51.9123],
        [74.9757],
        [41.1777],
        [69.8670],
        [69.8212],
        [54.0034],
        [72.5928],
        [49.7122],
        [70.7562],
        [50.0549],
        [85.0251],
        [50.1550],
        [36.2164],
        [70.3620],
        [57.5184],
        [73.4896],
        [61.0437],
        [37.7886],
        [74.9985],
        [54.6240],
        [50.9055],
        [74.5044],
        [54.6941],
        [71.1045],
        [45.1196],
        [72.9530],
        [50.3099],
        [70.2267],
        [74.8707],
        [57.0812],
        [75.6281],
        [36.4592],
        [84.9002],
        [49.2845],
        [71.8567],
        [35.5869],
        [51.9559],
        [73.8506],
        [35.6475],
        [82.0742],
        [40.1967],
        [72.9002],
        [40.9606],
        [74.7542],
        [73.1783],
        [47.9099],
        [83.4640],
        [51.7436],
        [67.3502],
        [56.6507],
        [88.4430],
        [36.4631],
        [38.4557],
        [89.9415],
        [45.6103],
        [62.6523],
        [38.5172],
        [65.9311],
        [40.5355],
        [89.2714],
        [83.8528],
        [35.0337],
        [73.0424],
        [59.4342],
        [67.3740],
        [50.4265],
        [74.5935],
        [43.4252],
        [35.0133],
        [78.7323],
        [64.4750],
        [71.1177],
        [68.0809],
        [68.9439],
        [35.4799],
        [76.0943],
        [88.1575],
        [37.3268],
        [59.4452],
        [55.6908],
        [41.5676],
        [79.6979],
        [51.8008],
        [64.0260],
        [72.4208],
        [60.6423],
        [70.0172],
        [35.3025],
        [84.7287],
        [36.1231],
        [65.9219],
        [70.5954],
        [53.1788],
        [61.6610],
        [39.5304],
        [76.7273],
        [35.1261],
        [88.5015],
        [60.4070],
        [67.9449],
        [57.4029],
        [40.2976],
        [88.7088],
        [38.0546],
        [89.1195],
        [44.8686],
        [66.5327],
        [49.3942],
        [50.8442],
        [70.0747],
        [35.0027],
        [87.0391]], device='cuda:0', dtype=torch.float64), tensor([[109.6853],
        [163.1213],
        [110.1927],
        [125.3351],
        [ 95.1258],
        [154.9402],
        [120.2891],
        [155.9777],
        [ 97.0723],
        [139.6182],
        [120.4123],
        [148.6575],
        [113.1622],
        [159.6941],
        [114.6645],
        [114.7146],
        [163.8523],
        [111.5581],
        [121.8632],
        [115.1507],
        [149.8895],
        [ 93.8678],
        [153.4095],
        [117.5145],
        [150.6926],
        [ 92.5144],
        [155.4174],
        [111.9711],
        [160.2034],
        [103.6415],
        [118.7265],
        [102.9348],
        [139.3690],
        [100.7871],
        [143.6486],
        [135.9993],
        [159.3367],
        [105.9897],
        [134.2207],
        [112.7493],
        [165.6301],
        [ 98.4753],
        [134.9682],
        [112.3786],
        [139.0253],
        [ 95.7358],
        [136.5642],
        [120.2195],
        [ 91.3997],
        [145.7531],
        [123.8396],
        [146.6787],
        [100.7920],
        [170.6888],
        [108.0619],
        [139.8706],
        [ 98.1338],
        [159.1827],
        [112.8883],
        [129.6132],
        [ 97.0819],
        [135.8906],
        [124.1178],
        [141.6740],
        [157.2296],
        [117.1579],
        [154.4287],
        [ 89.5718],
        [123.3089],
        [108.0110],
        [165.7572],
        [113.2656],
        [120.2463],
        [112.8839],
        [156.3851],
        [111.3654],
        [148.2135],
        [113.5836],
        [144.3345],
        [ 90.9270],
        [122.5820],
        [147.7196],
        [ 95.1863],
        [145.0244],
        [115.7150],
        [125.9735],
        [118.4464],
        [162.1410],
        [108.0633],
        [119.0295],
        [108.6338],
        [159.1888],
        [118.6245],
        [147.8384],
        [ 95.7172],
        [148.5835],
        [113.8649],
        [137.0297],
        [ 99.2728],
        [164.8039],
        [124.4379],
        [144.9254],
        [ 96.7005],
        [144.1974],
        [112.1823],
        [143.9982],
        [ 91.5408],
        [135.7789],
        [113.8244],
        [131.6935],
        [ 97.4011],
        [170.6645],
        [140.2049],
        [113.6289],
        [171.7835],
        [102.9138],
        [144.1265],
        [125.6516],
        [139.1790],
        [ 96.7353],
        [139.3881],
        [127.6273],
        [132.5084],
        [ 99.4896],
        [129.0562],
        [114.6426],
        [163.2512],
        [ 99.0750],
        [141.9147],
        [ 93.6718],
        [146.1255],
        [119.8816],
        [168.6309],
        [ 94.8482],
        [133.4038],
        [103.2993],
        [171.9270],
        [104.5272],
        [134.2593],
        [113.1232],
        [136.1417],
        [ 94.5135],
        [148.4576],
        [130.3477],
        [ 96.3945],
        [127.3777],
        [127.4564],
        [138.7287],
        [101.0591],
        [165.3281],
        [116.1446],
        [126.6196],
        [100.6559],
        [170.6065],
        [105.3656],
        [133.8484],
        [ 97.3069],
        [139.6983],
        [130.2318],
        [148.9530],
        [108.9590],
        [155.2003],
        [110.7861],
        [117.2482],
        [ 97.3017],
        [148.8483],
        [118.4062],
        [151.7636],
        [ 90.2558],
        [158.7955],
        [113.5818],
        [152.8305],
        [110.7066],
        [163.8409],
        [111.8385],
        [132.4279],
        [157.2536],
        [106.2157],
        [120.2524],
        [111.0851],
        [148.1106],
        [ 95.1662],
        [145.6325],
        [113.0232],
        [151.4651],
        [100.8664],
        [147.1486],
        [123.5448],
        [152.3247],
        [113.7357],
        [122.6062],
        [114.7308],
        [108.2183],
        [128.8399],
        [100.2441],
        [168.0173],
        [126.8866],
        [139.5479],
        [ 94.4982],
        [132.5973],
        [130.9848],
        [139.0302],
        [ 98.1403],
        [132.0112],
        [113.6169],
        [137.0487],
        [106.0537],
        [166.7550],
        [132.8694],
        [111.7189],
        [167.6661],
        [104.5785],
        [141.5184],
        [124.1205],
        [132.2041],
        [ 90.1083],
        [150.9055],
        [128.3313],
        [144.9370],
        [ 92.2995],
        [137.6738],
        [106.7473],
        [170.9543],
        [102.5912],
        [144.8792],
        [117.2631],
        [143.6599],
        [ 99.3227],
        [118.0352],
        [115.2229],
        [153.8468],
        [104.8558],
        [126.4690],
        [114.1316],
        [166.0919],
        [112.7584],
        [150.6313],
        [115.8700],
        [148.3515],
        [ 95.2095],
        [104.1310],
        [152.1774],
        [ 93.4958],
        [150.1726],
        [113.0122],
        [123.3742],
        [105.7603],
        [163.0223],
        [115.8389],
        [125.1153],
        [110.9771],
        [160.3729],
        [117.8296],
        [153.2269],
        [ 93.9281],
        [156.1017],
        [ 91.5511],
        [141.1268],
        [120.2602],
        [141.6659],
        [ 96.3083],
        [169.6316],
        [106.6602],
        [136.5604],
        [102.6516],
        [163.5068],
        [109.1642],
        [136.1675],
        [ 98.7209],
        [142.6044],
        [133.7644],
        [146.8626],
        [133.9634],
        [100.7436],
        [140.1624],
        [128.5827],
        [157.4642],
        [100.1565],
        [124.7454],
        [114.9070],
        [166.5653],
        [102.5075],
        [138.2366],
        [111.0239],
        [143.4409],
        [ 95.5426],
        [142.6376],
        [127.0814],
        [161.7142],
        [107.9527],
        [117.8115],
        [111.9326],
        [143.5148],
        [ 95.8479],
        [151.4440],
        [117.0040],
        [157.1454],
        [ 92.9448],
        [159.0758],
        [118.5536],
        [165.6014],
        [107.3945],
        [127.6229],
        [105.0270],
        [105.8003],
        [156.2717],
        [103.8599],
        [114.9676],
        [ 95.7429],
        [148.4970],
        [115.9105],
        [152.8470],
        [ 96.2918],
        [144.3724],
        [122.3060],
        [152.0785],
        [115.9057],
        [162.6358],
        [116.3184],
        [117.2437],
        [129.0213],
        [115.6391],
        [167.3262],
        [100.2016],
        [142.1284],
        [116.8609],
        [132.5908],
        [ 94.8224],
        [143.9979],
        [129.9601],
        [139.5701],
        [ 99.2698],
        [131.4737],
        [114.8014],
        [163.8539],
        [103.1368],
        [111.6864],
        [133.1916],
        [ 94.7156],
        [166.0470],
        [123.5995],
        [141.3709],
        [ 98.6077],
        [135.9259],
        [125.1636],
        [148.5377],
        [ 94.5194],
        [142.1783],
        [109.3489],
        [142.9043],
        [ 99.8804],
        [173.5507],
        [117.6051],
        [145.9628],
        [ 93.5681],
        [141.0294],
        [114.8695],
        [116.4741],
        [112.8088],
        [154.2135],
        [110.9097],
        [120.8410],
        [114.3923],
        [161.1749],
        [120.6475],
        [153.0391],
        [ 93.8916],
        [153.1997],
        [152.4866],
        [117.6236],
        [149.8038],
        [ 91.5980],
        [120.9425],
        [101.8994],
        [163.7890],
        [107.2388],
        [127.1416],
        [111.9337],
        [164.9248],
        [113.6235],
        [151.3768],
        [121.2296],
        [147.8975],
        [ 92.7047],
        [160.8521],
        [112.1438],
        [127.2119],
        [114.2918],
        [157.0564],
        [ 92.7620],
        [151.2318],
        [117.4500],
        [147.3313],
        [100.9248],
        [147.9686],
        [120.5686],
        [150.0432],
        [111.1030],
        [115.1308],
        [114.4169],
        [111.9041],
        [155.5921],
        [109.4521],
        [123.2595],
        [ 95.6722],
        [153.7338],
        [122.5786],
        [152.5716],
        [ 92.4255],
        [151.1225],
        [110.2785],
        [149.4946],
        [102.9519],
        [160.2240],
        [108.0243],
        [121.8648],
        [ 97.8191],
        [134.9092],
        [134.3379],
        [147.0213],
        [107.5886],
        [167.9496],
        [115.0182],
        [130.1060],
        [ 99.1977],
        [166.9952],
        [105.6217],
        [128.4757],
        [ 95.3587],
        [136.9053],
        [124.6529],
        [145.3723],
        [144.3497],
        [ 95.8518],
        [152.8625],
        [126.6154],
        [171.6913],
        [ 96.0465],
        [137.3130],
        [103.7879],
        [167.0406],
        [ 99.1620],
        [128.8370],
        [111.9212],
        [130.7166],
        [ 93.9823],
        [142.4910],
        [125.1064],
        [110.8437],
        [153.3858],
        [ 93.7377],
        [152.2022],
        [111.9429],
        [129.4514],
        [109.0192],
        [167.8720],
        [110.9734],
        [119.3218],
        [102.2009],
        [155.2588],
        [115.5158],
        [149.2385],
        [ 96.5073],
        [147.2641],
        [151.1190],
        [121.0716],
        [153.6307],
        [ 96.9390],
        [121.9142],
        [117.6064],
        [156.0782],
        [114.2535],
        [117.0475],
        [114.3555],
        [160.7784],
        [109.7691],
        [151.4169],
        [108.6107],
        [146.3225],
        [ 95.2635],
        [138.5957],
        [108.2946],
        [171.0639],
        [105.2205],
        [143.7381],
        [129.2302],
        [134.8622],
        [ 93.6984],
        [143.9034],
        [125.0419],
        [136.6129],
        [ 91.6671],
        [130.0353],
        [105.7875],
        [170.3106],
        [ 96.4635],
        [109.8124],
        [133.4700],
        [104.9304],
        [168.4477],
        [131.7772],
        [149.5126],
        [ 94.6591],
        [142.3940],
        [126.8434],
        [138.1397],
        [ 94.4925],
        [131.8562],
        [115.1716],
        [129.8424],
        [107.0376],
        [162.9190]], device='cuda:0', dtype=torch.float64)] SHAPE IS = torch.Size([512, 1]) SHAPE IS = torch.Size([512, 1]) SHAPE IS = torch.Size([512, 1]) AFTER NORMALIZATION: [tensor([[ 5.2985],
        [ 5.6983],
        [ 9.3622],
        [ 8.8628],
        [ 9.9398],
        [ 6.2513],
        [ 5.2488],
        [ 8.2092],
        [ 7.3916],
        [ 5.0530],
        [ 8.0266],
        [ 9.9980],
        [ 9.8771],
        [ 8.7756],
        [ 5.2806],
        [ 6.6076],
        [ 6.2585],
        [ 5.1392],
        [ 8.1951],
        [ 9.6222],
        [ 9.9577],
        [ 7.6442],
        [ 5.0015],
        [ 6.7676],
        [ 8.5720],
        [ 5.1173],
        [ 6.8368],
        [ 9.7387],
        [ 9.1458],
        [ 9.5978],
        [ 6.1652],
        [ 5.6679],
        [ 5.8186],
        [ 5.9478],
        [ 9.4692],
        [ 9.3539],
        [ 9.8221],
        [ 7.1048],
        [ 5.0580],
        [ 8.3089],
        [ 7.0415],
        [ 5.0200],
        [ 7.3680],
        [ 9.9872],
        [ 9.4550],
        [ 8.4031],
        [ 5.2410],
        [ 6.0776],
        [ 6.4127],
        [ 5.4156],
        [ 8.9614],
        [ 9.7710],
        [ 9.9981],
        [ 7.7562],
        [ 5.0162],
        [ 7.6750],
        [ 7.9352],
        [ 5.1591],
        [ 6.4975],
        [ 9.9765],
        [ 9.0957],
        [ 9.2082],
        [ 5.5231],
        [ 5.4080],
        [ 5.5248],
        [ 5.6317],
        [ 9.0795],
        [ 8.9352],
        [ 9.9476],
        [ 6.6846],
        [ 5.2376],
        [ 7.7659],
        [ 7.5982],
        [ 5.0114],
        [ 7.8029],
        [ 9.9937],
        [ 9.7513],
        [ 8.8982],
        [ 5.4596],
        [ 6.4552],
        [ 5.9412],
        [ 5.1623],
        [ 8.5883],
        [ 9.5570],
        [ 9.9587],
        [ 7.1986],
        [ 5.0042],
        [ 7.2413],
        [ 8.3524],
        [ 5.0426],
        [ 7.0281],
        [ 9.8390],
        [ 9.4046],
        [ 9.4972],
        [ 5.9112],
        [ 5.7617],
        [ 5.6158],
        [ 6.1257],
        [ 9.6225],
        [ 9.2031],
        [ 9.7592],
        [ 6.7619],
        [ 5.0951],
        [ 8.6133],
        [ 6.9630],
        [ 5.0012],
        [ 7.4743],
        [ 9.9130],
        [ 9.7075],
        [ 8.3866],
        [ 5.0807],
        [ 6.1139],
        [ 6.6517],
        [ 5.3177],
        [ 8.7088],
        [ 9.8625],
        [10.0000],
        [ 8.0724],
        [ 5.0439],
        [ 7.3147],
        [ 8.0438],
        [ 5.3439],
        [ 6.4294],
        [ 9.8971],
        [ 8.6891],
        [ 9.2438],
        [ 5.8202],
        [ 5.4007],
        [ 5.3432],
        [ 5.7712],
        [ 9.2973],
        [ 8.7919],
        [ 9.8976],
        [ 6.3825],
        [ 5.3137],
        [ 8.0540],
        [ 7.3043],
        [ 5.0333],
        [ 8.1230],
        [10.0000],
        [ 9.8211],
        [ 8.6419],
        [ 5.3512],
        [ 6.7558],
        [ 6.1804],
        [ 5.1075],
        [ 8.2855],
        [ 9.6649],
        [ 9.9213],
        [ 7.4948],
        [ 5.0005],
        [ 6.9231],
        [ 8.6498],
        [ 5.0873],
        [ 6.7423],
        [ 9.7729],
        [ 9.2664],
        [ 9.6772],
        [ 6.0445],
        [ 5.5647],
        [ 5.7552],
        [ 5.8658],
        [ 9.5283],
        [ 9.4061],
        [ 9.8781],
        [ 6.9544],
        [ 5.0309],
        [ 8.4560],
        [ 7.1311],
        [ 5.0091],
        [ 7.2735],
        [ 9.9773],
        [ 9.5557],
        [ 8.5408],
        [ 5.1840],
        [ 5.9482],
        [ 6.4921],
        [ 5.4764],
        [ 8.8798],
        [ 9.7365],
        [ 9.9860],
        [ 7.9077],
        [ 5.0039],
        [ 7.5185],
        [ 7.8450],
        [ 5.1973],
        [ 6.5853],
        [ 9.9637],
        [ 8.9626],
        [ 9.0966],
        [ 5.6127],
        [ 5.5002],
        [ 5.4723],
        [ 5.5625],
        [ 9.1550],
        [ 8.9997],
        [ 9.9758],
        [ 6.5418],
        [ 5.1797],
        [ 7.9212],
        [ 7.6892],
        [ 5.0234],
        [ 7.7082],
        [ 9.9983],
        [ 9.8194],
        [ 9.0191],
        [ 5.3813],
        [ 6.3116],
        [ 6.0101],
        [ 5.2021],
        [ 8.4987],
        [ 9.5109],
        [ 9.9832],
        [ 7.3513],
        [ 5.0169],
        [ 7.0857],
        [ 8.2664],
        [ 5.0635],
        [ 7.1214],
        [ 9.8084],
        [ 9.2911],
        [ 9.4038],
        [ 6.0231],
        [ 5.8810],
        [ 5.6767],
        [ 6.2124],
        [ 9.5709],
        [ 9.1413],
        [ 9.6818],
        [ 6.9060],
        [ 5.1377],
        [ 8.4669],
        [ 6.8784],
        [ 5.0000],
        [ 7.5728],
        [ 9.9325],
        [ 9.6254],
        [ 8.2417],
        [ 5.1215],
        [ 6.2474],
        [ 6.5664],
        [ 5.2693],
        [ 8.7912],
        [ 9.8885],
        [ 9.9926],
        [ 7.9266],
        [ 5.0743],
        [ 7.4751],
        [ 8.1288],
        [ 5.2918],
        [ 6.3406],
        [ 9.9185],
        [ 8.8311],
        [ 9.3501],
        [ 5.7157],
        [ 5.3198],
        [ 5.3288],
        [ 5.7409],
        [ 9.3206],
        [ 8.8091],
        [ 9.9259],
        [ 6.3058],
        [ 5.2771],
        [ 8.1500],
        [ 7.4551],
        [ 5.0663],
        [ 7.9673],
        [ 9.9946],
        [ 9.8955],
        [ 8.8298],
        [ 5.2526],
        [ 6.5514],
        [ 6.2047],
        [ 5.1200],
        [ 8.2540],
        [ 9.6550],
        [ 9.9459],
        [ 7.5818],
        [ 5.0001],
        [ 6.8266],
        [ 8.5143],
        [ 5.1367],
        [ 6.8954],
        [ 9.7102],
        [ 9.0990],
        [ 9.5626],
        [ 6.2184],
        [ 5.7097],
        [ 5.8654],
        [ 5.9957],
        [ 9.4307],
        [ 9.3107],
        [ 9.7989],
        [ 7.1666],
        [ 5.0724],
        [ 8.2505],
        [ 7.1040],
        [ 5.0130],
        [ 7.3076],
        [ 9.9800],
        [ 9.4927],
        [ 8.4620],
        [ 5.2149],
        [ 6.0282],
        [ 6.3568],
        [ 5.3827],
        [ 9.0108],
        [ 9.7968],
        [ 9.9998],
        [ 7.6939],
        [ 5.0243],
        [ 7.7363],
        [ 7.8726],
        [ 5.1814],
        [ 6.5532],
        [ 9.9672],
        [ 9.0479],
        [ 9.1614],
        [ 5.5620],
        [ 5.4418],
        [ 5.4870],
        [ 5.5921],
        [ 9.1268],
        [ 8.9867],
        [ 9.9592],
        [ 6.6258],
        [ 5.2114],
        [ 7.8270],
        [ 7.5347],
        [ 5.0063],
        [ 7.8629],
        [ 9.9884],
        [ 9.7239],
        [ 8.8451],
        [ 5.4963],
        [ 6.5105],
        [ 5.9905],
        [ 5.1845],
        [ 8.5326],
        [ 9.5202],
        [ 9.9689],
        [ 7.2607],
        [ 5.0087],
        [ 7.1802],
        [ 8.4118],
        [ 5.0321],
        [ 6.9687],
        [ 9.8604],
        [ 9.4439],
        [ 9.5347],
        [ 5.8634],
        [ 5.7187],
        [ 5.5753],
        [ 6.0756],
        [ 9.6543],
        [ 9.2490],
        [ 9.7845],
        [ 6.7024],
        [ 5.0786],
        [ 8.6681],
        [ 6.9012],
        [ 5.0000],
        [ 7.5348],
        [ 9.9286],
        [ 9.6780],
        [ 8.3270],
        [ 5.0972],
        [ 6.1646],
        [ 6.7108],
        [ 5.3478],
        [ 8.6546],
        [ 9.8410],
        [ 9.9999],
        [ 8.1330],
        [ 5.0329],
        [ 7.2534],
        [ 8.1055],
        [ 5.3134],
        [ 6.3750],
        [ 9.9141],
        [ 8.7429],
        [ 9.2887],
        [ 5.7745],
        [ 5.3685],
        [ 5.3754],
        [ 5.8154],
        [ 9.2541],
        [ 8.7372],
        [ 9.8797],
        [ 6.4388],
        [ 5.3452],
        [ 7.9938],
        [ 7.3676],
        [ 5.0441],
        [ 8.0642],
        [ 9.9986],
        [ 9.8433],
        [ 8.6980],
        [ 5.3199],
        [ 6.6982],
        [ 6.1278],
        [ 5.0906],
        [ 8.3437],
        [ 9.6959],
        [ 9.9055],
        [ 7.4324],
        [ 5.0026],
        [ 6.9831],
        [ 8.5931],
        [ 5.1041],
        [ 6.8002],
        [ 9.7461],
        [ 9.2223],
        [ 9.6453],
        [ 6.0957],
        [ 5.6036],
        [ 5.8006],
        [ 5.9121],
        [ 9.4918],
        [ 9.3644],
        [ 9.8587],
        [ 7.0155],
        [ 5.0417],
        [ 8.3989],
        [ 7.1939],
        [ 5.0046],
        [ 7.2133],
        [ 9.9681],
        [ 9.5901],
        [ 8.5982],
        [ 5.1612],
        [ 5.9012],
        [ 6.4352],
        [ 5.4414],
        [ 8.9307],
        [ 9.7641],
        [ 9.9917],
        [ 7.8459],
        [ 5.0083],
        [ 7.5800],
        [ 7.7821],
        [ 5.2219],
        [ 6.6419],
        [ 9.9523],
        [ 8.9123],
        [ 9.0473],
        [ 5.6543],
        [ 5.5371],
        [ 5.4364],
        [ 5.5248],
        [ 9.2007],
        [ 9.0499],
        [ 9.9835],
        [ 6.4844],
        [ 5.1568],
        [ 7.9817],
        [ 7.6259],
        [ 5.0157],
        [ 7.7685],
        [ 9.9951],
        [ 9.7957],
        [ 8.9682],
        [ 5.4151],
        [ 6.3653],
        [ 6.0607],
        [ 5.2266],
        [ 8.4421],
        [ 9.4725],
        [ 9.9895],
        [ 7.4137],
        [ 5.0251],
        [ 7.0251],
        [ 8.3265],
        [ 5.0505],
        [ 7.0616],
        [ 9.8317],
        [ 9.3335],
        [ 9.4443],
        [ 5.9731],
        [ 5.8354],
        [ 5.6345],
        [ 6.1608],
        [ 9.6047],
        [ 9.1887],
        [ 9.7108],
        [ 6.8455],
        [ 5.1177],
        [ 8.5234],
        [ 6.8171],
        [ 5.0014],
        [ 7.6333],
        [ 9.9462],
        [ 9.5923],
        [ 8.1809],
        [ 5.1415],
        [ 6.3001],
        [ 6.6247],
        [ 5.2972],
        [ 8.7381],
        [ 9.8690],
        [ 9.9966],
        [ 7.9880],
        [ 5.0597],
        [ 7.4136],
        [ 8.1899],
        [ 5.2636],
        [ 6.2873],
        [ 9.9336],
        [ 8.8828],
        [ 9.3922],
        [ 5.6725],
        [ 5.2908]], device='cuda:0', dtype=torch.float64), tensor([[ 8.6449],
        [ 5.5831],
        [ 7.6601],
        [ 6.5179],
        [ 7.3670],
        [ 8.4105],
        [ 5.0219],
        [ 8.5503],
        [ 5.0952],
        [ 8.7138],
        [ 8.2115],
        [ 7.7938],
        [ 7.4126],
        [ 6.6494],
        [ 9.6724],
        [ 5.4200],
        [ 9.7814],
        [ 5.0129],
        [ 8.0191],
        [ 6.5089],
        [ 6.3160],
        [ 7.0508],
        [ 5.2659],
        [ 9.9682],
        [ 5.9092],
        [ 9.9151],
        [ 5.2612],
        [ 7.8589],
        [ 8.1738],
        [ 7.4348],
        [ 9.7616],
        [ 5.0006],
        [ 7.5227],
        [ 7.9552],
        [ 5.1415],
        [ 9.8874],
        [ 9.9630],
        [ 5.3068],
        [ 7.5313],
        [ 5.4194],
        [ 7.7942],
        [ 6.3528],
        [ 9.9471],
        [ 5.5189],
        [ 5.0038],
        [ 9.4465],
        [ 6.2473],
        [ 8.4554],
        [ 6.4550],
        [ 7.9554],
        [ 5.7500],
        [ 9.2715],
        [ 8.3404],
        [ 5.0102],
        [ 8.2984],
        [ 7.6495],
        [ 8.0781],
        [ 8.0058],
        [ 9.6192],
        [ 5.0396],
        [ 5.2232],
        [ 8.9550],
        [ 6.8589],
        [ 7.2017],
        [ 5.2431],
        [ 7.9208],
        [ 6.8241],
        [ 8.6382],
        [ 8.5982],
        [ 6.4029],
        [ 7.7401],
        [ 6.7744],
        [ 9.4414],
        [ 5.9312],
        [ 8.1957],
        [ 6.3966],
        [ 6.9866],
        [ 8.6241],
        [ 5.1419],
        [ 7.6917],
        [ 6.2778],
        [ 9.5775],
        [ 5.7073],
        [ 8.3572],
        [ 8.5443],
        [ 5.9134],
        [ 9.2230],
        [ 5.0555],
        [ 8.4767],
        [ 5.4876],
        [ 8.6186],
        [ 6.4349],
        [ 5.3226],
        [ 8.4683],
        [ 6.5363],
        [ 9.4076],
        [ 8.1378],
        [ 5.0306],
        [ 9.7602],
        [ 6.0817],
        [ 5.1745],
        [ 9.0897],
        [ 5.9896],
        [ 8.5974],
        [ 5.4843],
        [ 8.6371],
        [ 5.3485],
        [ 8.8147],
        [ 9.2567],
        [ 6.8966],
        [ 8.5449],
        [ 6.0631],
        [ 8.6351],
        [ 6.4755],
        [ 7.3102],
        [ 5.5546],
        [ 6.7021],
        [ 8.9575],
        [ 6.4211],
        [ 8.4259],
        [ 6.3548],
        [ 8.2386],
        [ 6.4021],
        [ 8.5352],
        [ 9.2591],
        [ 5.1133],
        [ 8.4960],
        [ 7.0497],
        [ 7.8780],
        [ 6.4279],
        [ 9.1716],
        [ 5.8151],
        [ 5.0046],
        [ 8.3506],
        [ 7.5680],
        [ 8.2399],
        [ 7.9425],
        [ 8.0329],
        [ 5.0310],
        [ 9.5777],
        [ 8.7358],
        [ 5.2440],
        [ 7.1414],
        [ 6.8178],
        [ 7.7584],
        [ 7.4060],
        [ 9.9507],
        [ 5.0683],
        [ 5.4411],
        [ 9.9563],
        [ 5.3263],
        [ 7.3077],
        [ 6.3191],
        [ 7.6160],
        [ 5.6560],
        [ 9.9837],
        [ 9.5719],
        [ 5.0255],
        [ 8.3564],
        [ 6.2428],
        [ 5.0492],
        [ 9.7489],
        [ 6.6840],
        [ 8.1457],
        [ 7.2359],
        [ 6.0385],
        [ 9.9963],
        [ 5.1685],
        [ 9.8401],
        [ 5.7084],
        [ 8.0339],
        [ 5.2603],
        [ 7.4086],
        [ 8.3131],
        [ 5.0098],
        [ 9.6289],
        [ 5.5452],
        [ 8.6456],
        [ 6.4909],
        [ 7.7008],
        [ 8.4323],
        [ 7.4059],
        [ 8.9085],
        [ 5.0133],
        [ 8.7399],
        [ 5.1312],
        [ 7.8614],
        [ 8.2799],
        [ 6.6934],
        [ 7.4885],
        [ 5.3584],
        [ 9.8771],
        [ 6.6320],
        [ 8.6110],
        [ 5.4223],
        [ 7.1063],
        [ 8.3497],
        [ 6.5174],
        [ 8.5116],
        [ 6.3813],
        [ 8.3758],
        [ 6.3624],
        [ 8.3159],
        [ 6.1878],
        [ 5.0489],
        [ 8.8323],
        [ 7.2487],
        [ 8.5742],
        [ 5.0535],
        [ 8.1872],
        [ 6.0417],
        [ 9.6698],
        [ 9.0489],
        [ 5.1562],
        [ 8.6093],
        [ 6.5139],
        [ 8.6399],
        [ 5.6436],
        [ 8.7276],
        [ 5.3034],
        [ 6.8179],
        [ 9.1898],
        [ 6.3154],
        [ 8.5733],
        [ 9.6397],
        [ 6.3734],
        [ 8.3117],
        [ 5.5132],
        [ 5.7918],
        [ 8.5139],
        [ 5.0824],
        [ 9.3186],
        [ 5.5320],
        [ 8.5378],
        [ 6.3240],
        [ 8.6247],
        [ 8.4482],
        [ 5.1146],
        [ 9.4571],
        [ 6.5994],
        [ 8.3460],
        [ 5.3780],
        [ 8.6288],
        [ 6.6853],
        [ 6.4550],
        [ 8.5379],
        [ 7.0187],
        [ 7.9850],
        [ 6.1168],
        [ 9.6439],
        [ 6.3706],
        [ 8.0650],
        [ 8.5907],
        [ 6.8481],
        [ 8.1237],
        [ 5.2325],
        [ 6.3604],
        [ 9.5942],
        [ 5.0176],
        [ 8.3240],
        [ 8.5178],
        [ 6.4052],
        [ 9.3313],
        [ 5.0759],
        [ 8.5457],
        [ 5.5414],
        [ 8.6269],
        [ 5.3074],
        [ 6.1157],
        [ 8.4372],
        [ 6.6216],
        [ 9.4791],
        [ 5.3705],
        [ 7.6073],
        [ 6.6555],
        [ 8.6310],
        [ 8.5423],
        [ 6.5096],
        [ 8.5536],
        [ 6.9981],
        [ 8.7338],
        [ 6.1387],
        [ 8.0486],
        [ 6.3600],
        [ 6.8476],
        [ 8.5876],
        [ 5.2381],
        [ 8.9696],
        [ 8.6087],
        [ 6.6568],
        [ 7.5468],
        [ 5.4112],
        [ 6.4984],
        [ 7.9927],
        [ 6.3527],
        [ 8.5197],
        [ 6.3654],
        [ 8.3688],
        [ 6.1999],
        [ 9.1857],
        [ 8.0179],
        [ 5.0546],
        [ 8.5682],
        [ 7.2259],
        [ 8.1909],
        [ 5.8336],
        [ 9.7478],
        [ 6.0216],
        [ 5.1509],
        [ 8.9673],
        [ 5.6630],
        [ 8.6221],
        [ 6.6415],
        [ 8.6385],
        [ 5.3159],
        [ 8.7618],
        [ 9.1860],
        [ 6.8312],
        [ 8.5719],
        [ 5.2733],
        [ 9.7624],
        [ 5.0545],
        [ 8.1581],
        [ 7.0649],
        [ 5.6145],
        [ 7.2516],
        [ 5.1629],
        [ 9.9792],
        [ 5.7262],
        [ 9.8524],
        [ 6.1024],
        [ 8.0168],
        [ 8.3060],
        [ 6.5485],
        [ 9.6331],
        [ 5.0084],
        [ 9.5205],
        [ 5.5259],
        [ 7.7125],
        [ 6.5622],
        [ 7.3294],
        [ 8.4426],
        [ 5.0222],
        [ 8.1349],
        [ 5.1242],
        [ 9.8038],
        [ 8.2811],
        [ 7.8503],
        [ 7.4678],
        [ 6.6673],
        [ 8.8787],
        [ 5.3734],
        [ 6.4068],
        [ 7.8961],
        [ 5.8006],
        [ 8.5617],
        [ 8.8293],
        [ 5.0000],
        [ 8.2482],
        [ 7.6227],
        [ 8.0162],
        [ 7.9144],
        [ 8.5697],
        [ 5.0279],
        [ 5.2501],
        [ 9.7257],
        [ 6.8146],
        [ 7.1281],
        [ 6.8072],
        [ 7.7766],
        [ 5.0720],
        [ 9.8886],
        [10.0000],
        [ 5.4266],
        [ 7.3225],
        [ 6.0254],
        [ 7.6049],
        [ 5.4553],
        [ 9.9776],
        [ 5.6663],
        [ 5.0294],
        [ 9.5956],
        [ 7.1198],
        [ 8.3430],
        [ 5.4208],
        [ 8.1254],
        [ 6.0938],
        [ 9.7883],
        [ 9.0884],
        [ 5.1843],
        [ 8.5949],
        [ 5.5779],
        [ 8.6372],
        [ 6.3863],
        [ 8.8050],
        [ 5.3406],
        [ 6.8744],
        [ 9.2341],
        [ 5.2527],
        [ 8.5523],
        [ 6.5383],
        [ 8.6363],
        [ 5.5618],
        [ 8.1716],
        [ 8.1674],
        [ 6.7285],
        [ 8.4196],
        [ 6.3382],
        [ 8.2525],
        [ 6.3694],
        [ 9.5505],
        [ 6.3785],
        [ 5.1105],
        [ 8.2166],
        [ 7.0483],
        [ 8.5011],
        [ 7.3690],
        [ 5.2535],
        [ 8.6384],
        [ 6.7850],
        [ 6.4467],
        [ 8.5935],
        [ 6.7914],
        [ 8.2842],
        [ 5.9204],
        [ 8.4523],
        [ 6.3926],
        [ 8.2043],
        [ 8.6268],
        [ 7.0085],
        [ 8.6957],
        [ 5.1326],
        [ 9.5391],
        [ 6.2993],
        [ 8.3526],
        [ 5.0532],
        [ 6.5423],
        [ 8.5340],
        [ 5.0588],
        [ 9.2820],
        [ 5.4726],
        [ 8.4475],
        [ 5.5421],
        [ 8.6162],
        [ 8.4728],
        [ 6.1742],
        [ 9.4085],
        [ 6.5230],
        [ 7.9427],
        [ 6.9694],
        [ 9.8614],
        [ 5.1330],
        [ 5.3142],
        [ 9.9977],
        [ 5.9650],
        [ 7.5153],
        [ 5.3198],
        [ 7.8136],
        [ 5.5034],
        [ 9.9368],
        [ 9.4438],
        [ 5.0029],
        [ 8.4605],
        [ 7.2226],
        [ 7.9448],
        [ 6.4032],
        [ 8.6016],
        [ 5.7663],
        [ 5.0011],
        [ 8.9780],
        [ 7.6811],
        [ 8.2854],
        [ 8.0091],
        [ 8.0876],
        [ 5.0435],
        [ 8.7381],
        [ 9.8354],
        [ 5.2115],
        [ 7.2236],
        [ 6.8820],
        [ 5.5973],
        [ 9.0659],
        [ 6.5282],
        [ 7.6403],
        [ 8.4039],
        [ 7.3325],
        [ 8.1853],
        [ 5.0274],
        [ 9.5235],
        [ 5.1020],
        [ 7.8127],
        [ 8.2379],
        [ 6.6535],
        [ 7.4251],
        [ 5.4120],
        [ 8.7957],
        [ 5.0113],
        [ 9.8667],
        [ 7.3111],
        [ 7.9968],
        [ 7.0378],
        [ 5.4818],
        [ 9.8856],
        [ 5.2777],
        [ 9.9229],
        [ 5.8976],
        [ 7.8683],
        [ 6.3093],
        [ 6.4412],
        [ 8.1905],
        [ 5.0001],
        [ 9.7337]], device='cuda:0', dtype=torch.float64), tensor([[ 6.1975],
        [ 9.3790],
        [ 6.2277],
        [ 7.1293],
        [ 5.3307],
        [ 8.8920],
        [ 6.8289],
        [ 8.9537],
        [ 5.4466],
        [ 7.9797],
        [ 6.8362],
        [ 8.5179],
        [ 6.4045],
        [ 9.1750],
        [ 6.4940],
        [ 6.4970],
        [ 9.4226],
        [ 6.3090],
        [ 6.9226],
        [ 6.5229],
        [ 8.5912],
        [ 5.2558],
        [ 8.8008],
        [ 6.6637],
        [ 8.6391],
        [ 5.1752],
        [ 8.9204],
        [ 6.3336],
        [ 9.2053],
        [ 5.8377],
        [ 6.7358],
        [ 5.7956],
        [ 7.9649],
        [ 5.6677],
        [ 8.2197],
        [ 7.7642],
        [ 9.1537],
        [ 5.9775],
        [ 7.6583],
        [ 6.3800],
        [ 9.5284],
        [ 5.5301],
        [ 7.7028],
        [ 6.3579],
        [ 7.9444],
        [ 5.3670],
        [ 7.7979],
        [ 6.8247],
        [ 5.1088],
        [ 8.3450],
        [ 7.0403],
        [ 8.4001],
        [ 5.6680],
        [ 9.8296],
        [ 6.1009],
        [ 7.9947],
        [ 5.5098],
        [ 9.1445],
        [ 6.3882],
        [ 7.3840],
        [ 5.4471],
        [ 7.7578],
        [ 7.0568],
        [ 8.1021],
        [ 9.0283],
        [ 6.6424],
        [ 8.8615],
        [ 5.0000],
        [ 7.0087],
        [ 6.0978],
        [ 9.5360],
        [ 6.4107],
        [ 6.8263],
        [ 6.3880],
        [ 8.9780],
        [ 6.2976],
        [ 8.4915],
        [ 6.4296],
        [ 8.2605],
        [ 5.0807],
        [ 6.9654],
        [ 8.4620],
        [ 5.3343],
        [ 8.3016],
        [ 6.5565],
        [ 7.1673],
        [ 6.7192],
        [ 9.3207],
        [ 6.1010],
        [ 6.7539],
        [ 6.1349],
        [ 9.1449],
        [ 6.7298],
        [ 8.4691],
        [ 5.3659],
        [ 8.5135],
        [ 6.4464],
        [ 7.8256],
        [ 5.5776],
        [ 9.4792],
        [ 7.0759],
        [ 8.2957],
        [ 5.4244],
        [ 8.2523],
        [ 6.3462],
        [ 8.2405],
        [ 5.1172],
        [ 7.7511],
        [ 6.4440],
        [ 7.5079],
        [ 5.4661],
        [ 9.8282],
        [ 8.0146],
        [ 6.4323],
        [ 9.8948],
        [ 5.7944],
        [ 8.2481],
        [ 7.1481],
        [ 7.9535],
        [ 5.4265],
        [ 7.9660],
        [ 7.2658],
        [ 7.5564],
        [ 5.5905],
        [ 7.3509],
        [ 6.4927],
        [ 9.3868],
        [ 5.5658],
        [ 8.1164],
        [ 5.2441],
        [ 8.3671],
        [ 6.8046],
        [ 9.7071],
        [ 5.3142],
        [ 7.6097],
        [ 5.8173],
        [ 9.9033],
        [ 5.8904],
        [ 7.6606],
        [ 6.4022],
        [ 7.7727],
        [ 5.2942],
        [ 8.5060],
        [ 7.4277],
        [ 5.4062],
        [ 7.2509],
        [ 7.2556],
        [ 7.9267],
        [ 5.6839],
        [ 9.5104],
        [ 6.5821],
        [ 7.2058],
        [ 5.6599],
        [ 9.8247],
        [ 5.9403],
        [ 7.6362],
        [ 5.4605],
        [ 7.9845],
        [ 7.4208],
        [ 8.5355],
        [ 6.1543],
        [ 8.9074],
        [ 6.2631],
        [ 6.6478],
        [ 5.4602],
        [ 8.5292],
        [ 6.7168],
        [ 8.7028],
        [ 5.0407],
        [ 9.1215],
        [ 6.4295],
        [ 8.7663],
        [ 6.2583],
        [ 9.4219],
        [ 6.3257],
        [ 7.5516],
        [ 9.0297],
        [ 5.9910],
        [ 6.8267],
        [ 6.2809],
        [ 8.4853],
        [ 5.3331],
        [ 8.3378],
        [ 6.3963],
        [ 8.6850],
        [ 5.6725],
        [ 8.4281],
        [ 7.0227],
        [ 8.7362],
        [ 6.4387],
        [ 6.9668],
        [ 6.4979],
        [ 6.1102],
        [ 7.3380],
        [ 5.6354],
        [ 9.6705],
        [ 7.2217],
        [ 7.9755],
        [ 5.2933],
        [ 7.5617],
        [ 7.4657],
        [ 7.9447],
        [ 5.5102],
        [ 7.5268],
        [ 6.4316],
        [ 7.8267],
        [ 5.9813],
        [ 9.5954],
        [ 7.5779],
        [ 6.3186],
        [ 9.6496],
        [ 5.8935],
        [ 8.0928],
        [ 7.0570],
        [ 7.5383],
        [ 5.0319],
        [ 8.6517],
        [ 7.3077],
        [ 8.2964],
        [ 5.1624],
        [ 7.8639],
        [ 6.0226],
        [ 9.8454],
        [ 5.7752],
        [ 8.2929],
        [ 6.6487],
        [ 8.2203],
        [ 5.5806],
        [ 6.6947],
        [ 6.5272],
        [ 8.8269],
        [ 5.9100],
        [ 7.1968],
        [ 6.4623],
        [ 9.5559],
        [ 6.3805],
        [ 8.6354],
        [ 6.5658],
        [ 8.4997],
        [ 5.3357],
        [ 5.8668],
        [ 8.7275],
        [ 5.2336],
        [ 8.6081],
        [ 6.3956],
        [ 7.0126],
        [ 5.9638],
        [ 9.3732],
        [ 6.5639],
        [ 7.1162],
        [ 6.2744],
        [ 9.2154],
        [ 6.6824],
        [ 8.7899],
        [ 5.2594],
        [ 8.9611],
        [ 5.1178],
        [ 8.0695],
        [ 6.8271],
        [ 8.1016],
        [ 5.4011],
        [ 9.7667],
        [ 6.0174],
        [ 7.7976],
        [ 5.7788],
        [ 9.4020],
        [ 6.1665],
        [ 7.7742],
        [ 5.5447],
        [ 8.1575],
        [ 7.6312],
        [ 8.4110],
        [ 7.6430],
        [ 5.6652],
        [ 8.0121],
        [ 7.3227],
        [ 9.0422],
        [ 5.6302],
        [ 7.0942],
        [ 6.5084],
        [ 9.5841],
        [ 5.7702],
        [ 7.8974],
        [ 6.2772],
        [ 8.2073],
        [ 5.3555],
        [ 8.1595],
        [ 7.2333],
        [ 9.2953],
        [ 6.0944],
        [ 6.6814],
        [ 6.3313],
        [ 8.2117],
        [ 5.3737],
        [ 8.6838],
        [ 6.6333],
        [ 9.0232],
        [ 5.2008],
        [ 9.1382],
        [ 6.7255],
        [ 9.5267],
        [ 6.0611],
        [ 7.2655],
        [ 5.9202],
        [ 5.9662],
        [ 8.9712],
        [ 5.8507],
        [ 6.5120],
        [ 5.3674],
        [ 8.5083],
        [ 6.5682],
        [ 8.7673],
        [ 5.4001],
        [ 8.2628],
        [ 6.9490],
        [ 8.7216],
        [ 6.5679],
        [ 9.3501],
        [ 6.5925],
        [ 6.6476],
        [ 7.3488],
        [ 6.5520],
        [ 9.6294],
        [ 5.6329],
        [ 8.1292],
        [ 6.6248],
        [ 7.5613],
        [ 5.3126],
        [ 8.2405],
        [ 7.4047],
        [ 7.9768],
        [ 5.5774],
        [ 7.4948],
        [ 6.5021],
        [ 9.4227],
        [ 5.8076],
        [ 6.3167],
        [ 7.5971],
        [ 5.3063],
        [ 9.5532],
        [ 7.0260],
        [ 8.0841],
        [ 5.5380],
        [ 7.7599],
        [ 7.1191],
        [ 8.5108],
        [ 5.2946],
        [ 8.1321],
        [ 6.1775],
        [ 8.1754],
        [ 5.6138],
        [10.0000],
        [ 6.6691],
        [ 8.3574],
        [ 5.2379],
        [ 8.0637],
        [ 6.5062],
        [ 6.6017],
        [ 6.3835],
        [ 8.8487],
        [ 6.2704],
        [ 6.8617],
        [ 6.4778],
        [ 9.2632],
        [ 6.8502],
        [ 8.7788],
        [ 5.2572],
        [ 8.7883],
        [ 8.7459],
        [ 6.6702],
        [ 8.5861],
        [ 5.1206],
        [ 6.8678],
        [ 5.7340],
        [ 9.4188],
        [ 6.0519],
        [ 7.2369],
        [ 6.3314],
        [ 9.4864],
        [ 6.4320],
        [ 8.6798],
        [ 6.8849],
        [ 8.4726],
        [ 5.1865],
        [ 9.2439],
        [ 6.3439],
        [ 7.2410],
        [ 6.4718],
        [ 9.0180],
        [ 5.1899],
        [ 8.6712],
        [ 6.6598],
        [ 8.4389],
        [ 5.6759],
        [ 8.4769],
        [ 6.8455],
        [ 8.6004],
        [ 6.2819],
        [ 6.5218],
        [ 6.4792],
        [ 6.3296],
        [ 8.9308],
        [ 6.1836],
        [ 7.0057],
        [ 5.3632],
        [ 8.8201],
        [ 6.9652],
        [ 8.7509],
        [ 5.1699],
        [ 8.6647],
        [ 6.2328],
        [ 8.5677],
        [ 5.7966],
        [ 9.2065],
        [ 6.0986],
        [ 6.9227],
        [ 5.4910],
        [ 7.6993],
        [ 7.6653],
        [ 8.4205],
        [ 6.0727],
        [ 9.6665],
        [ 6.5150],
        [ 7.4134],
        [ 5.5731],
        [ 9.6097],
        [ 5.9556],
        [ 7.3163],
        [ 5.3445],
        [ 7.8182],
        [ 7.0887],
        [ 8.3223],
        [ 8.2614],
        [ 5.3739],
        [ 8.7682],
        [ 7.2055],
        [ 9.8893],
        [ 5.3855],
        [ 7.8424],
        [ 5.8464],
        [ 9.6124],
        [ 5.5710],
        [ 7.3378],
        [ 6.3307],
        [ 7.4497],
        [ 5.2626],
        [ 8.1507],
        [ 7.1157],
        [ 6.2665],
        [ 8.7994],
        [ 5.2480],
        [ 8.7289],
        [ 6.3319],
        [ 7.3744],
        [ 6.1579],
        [ 9.6619],
        [ 6.2742],
        [ 6.7713],
        [ 5.7519],
        [ 8.9109],
        [ 6.5447],
        [ 8.5525],
        [ 5.4129],
        [ 8.4349],
        [ 8.6644],
        [ 6.8755],
        [ 8.8140],
        [ 5.4386],
        [ 6.9256],
        [ 6.6691],
        [ 8.9597],
        [ 6.4695],
        [ 6.6359],
        [ 6.4756],
        [ 9.2396],
        [ 6.2025],
        [ 8.6822],
        [ 6.1336],
        [ 8.3789],
        [ 5.3389],
        [ 7.9188],
        [ 6.1147],
        [ 9.8519],
        [ 5.9317],
        [ 8.2250],
        [ 7.3612],
        [ 7.6965],
        [ 5.2457],
        [ 8.2348],
        [ 7.1118],
        [ 7.8008],
        [ 5.1247],
        [ 7.4091],
        [ 5.9655],
        [ 9.8071],
        [ 5.4103],
        [ 6.2051],
        [ 7.6136],
        [ 5.9144],
        [ 9.6962],
        [ 7.5129],
        [ 8.5688],
        [ 5.3029],
        [ 8.1450],
        [ 7.2191],
        [ 7.8917],
        [ 5.2930],
        [ 7.5176],
        [ 6.5242],
        [ 7.3977],
        [ 6.0399],
        [ 9.3670]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION: [tensor([[178.8686],
        [142.3885],
        [140.0669],
        [166.2835],
        [165.0639],
        [140.1879],
        [150.7251],
        [157.7061],
        [143.7790],
        [148.1848]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.9055],
        [75.0703],
        [35.6475],
        [89.4242],
        [39.6915],
        [49.9782],
        [50.0690],
        [50.3099],
        [52.9417],
        [49.4619]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[107.5886],
        [109.6853],
        [137.3130],
        [127.4564],
        [101.8994],
        [139.0302],
        [110.9771],
        [105.6217],
        [108.2183],
        [170.9543]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.2992],
        [ 5.0000],
        [ 8.3783],
        [ 8.2211],
        [ 5.0156],
        [ 6.3734],
        [ 7.2730],
        [ 5.4784],
        [ 6.0461]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.4186],
        [ 8.6654],
        [ 5.0000],
        [10.0000],
        [ 5.3760],
        [ 6.3324],
        [ 6.3409],
        [ 6.3633],
        [ 6.6080],
        [ 6.2844]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4119],
        [ 5.5637],
        [ 7.5642],
        [ 6.8505],
        [ 5.0000],
        [ 7.6885],
        [ 5.6573],
        [ 5.2695],
        [ 5.4575],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[178.5778],
        [142.3274],
        [140.0598],
        [166.1628],
        [164.8384],
        [140.1801],
        [150.3466],
        [157.3714],
        [143.6862],
        [148.0105]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.7592],
        [75.0670],
        [35.6520],
        [89.4082],
        [39.6297],
        [49.9804],
        [50.0997],
        [50.3242],
        [52.8533],
        [49.4442]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[107.4844],
        [109.6059],
        [137.2229],
        [127.3985],
        [101.8467],
        [138.9623],
        [110.7504],
        [105.5411],
        [108.2171],
        [170.9163]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.2943],
        [ 5.0000],
        [ 8.3884],
        [ 8.2165],
        [ 5.0156],
        [ 6.3353],
        [ 7.2472],
        [ 5.4707],
        [ 6.0321]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.4052],
        [ 8.6661],
        [ 5.0000],
        [10.0000],
        [ 5.3700],
        [ 6.3327],
        [ 6.3438],
        [ 6.3647],
        [ 6.5999],
        [ 6.2828]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4081],
        [ 5.5617],
        [ 7.5609],
        [ 6.8497],
        [ 5.0000],
        [ 7.6868],
        [ 5.6445],
        [ 5.2674],
        [ 5.4612],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[178.2472],
        [142.2672],
        [140.0533],
        [166.0407],
        [164.6088],
        [140.1726],
        [149.9765],
        [157.0338],
        [143.5951],
        [147.8376]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.6261],
        [75.0637],
        [35.6565],
        [89.3919],
        [39.5683],
        [49.9826],
        [50.1354],
        [50.3386],
        [52.7669],
        [49.4270]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[107.3828],
        [109.5268],
        [137.1322],
        [127.3408],
        [101.7944],
        [138.8938],
        [110.5267],
        [105.4592],
        [108.2168],
        [170.8772]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.2898],
        [ 5.0000],
        [ 8.4020],
        [ 8.2146],
        [ 5.0156],
        [ 6.2991],
        [ 7.2229],
        [ 5.4637],
        [ 6.0191]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3929],
        [ 8.6668],
        [ 5.0000],
        [10.0000],
        [ 5.3640],
        [ 6.3330],
        [ 6.3472],
        [ 6.3662],
        [ 6.5921],
        [ 6.2813]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4045],
        [ 5.5596],
        [ 7.5576],
        [ 6.8490],
        [ 5.0000],
        [ 7.6851],
        [ 5.6320],
        [ 5.2653],
        [ 5.4648],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[178.0915],
        [142.2411],
        [140.0505],
        [165.9870],
        [164.5077],
        [140.1693],
        [149.8154],
        [156.8857],
        [143.5554],
        [147.7621]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.5716],
        [75.0622],
        [35.6584],
        [89.3846],
        [39.5415],
        [49.9836],
        [50.1526],
        [50.3450],
        [52.7293],
        [49.4196]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[107.3382],
        [109.4920],
        [137.0923],
        [127.3154],
        [101.7715],
        [138.8637],
        [110.4288],
        [105.4234],
        [108.2166],
        [170.8598]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.2879],
        [ 5.0000],
        [ 8.4090],
        [ 8.2146],
        [ 5.0156],
        [ 6.2835],
        [ 7.2128],
        [ 5.4607],
        [ 6.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3879],
        [ 8.6671],
        [ 5.0000],
        [10.0000],
        [ 5.3614],
        [ 6.3332],
        [ 6.3489],
        [ 6.3668],
        [ 6.5887],
        [ 6.2807]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4029],
        [ 5.5587],
        [ 7.5562],
        [ 6.8486],
        [ 5.0000],
        [ 7.6844],
        [ 5.6265],
        [ 5.2643],
        [ 5.4664],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[177.7027],
        [142.2411],
        [140.0447],
        [165.8626],
        [164.2719],
        [140.1622],
        [149.4578],
        [156.5438],
        [143.4664],
        [147.5913]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.4580],
        [75.0588],
        [35.6627],
        [89.3678],
        [39.4807],
        [49.9858],
        [50.1949],
        [50.3598],
        [52.6457],
        [49.4031]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[107.2402],
        [109.4131],
        [137.0006],
        [127.2581],
        [101.7196],
        [138.7945],
        [110.2099],
        [105.3398],
        [108.2177],
        [170.8190]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.2916],
        [ 5.0000],
        [ 8.4279],
        [ 8.2167],
        [ 5.0156],
        [ 6.2498],
        [ 7.1906],
        [ 5.4543],
        [ 6.0020]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3775],
        [ 8.6678],
        [ 5.0000],
        [10.0000],
        [ 5.3555],
        [ 6.3335],
        [ 6.3530],
        [ 6.3683],
        [ 6.5811],
        [ 6.2792]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3995],
        [ 5.5567],
        [ 7.5529],
        [ 6.8480],
        [ 5.0000],
        [ 7.6827],
        [ 5.6144],
        [ 5.2620],
        [ 5.4702],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[175.8194],
        [142.2411],
        [140.0250],
        [165.3628],
        [163.3227],
        [140.1352],
        [148.0754],
        [155.1875],
        [143.1207],
        [146.9229]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1277],
        [75.0448],
        [35.6801],
        [89.2979],
        [39.2412],
        [49.9953],
        [50.4128],
        [50.4200],
        [52.3227],
        [49.3406]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[106.8518],
        [109.0984],
        [136.6324],
        [127.0296],
        [101.5153],
        [138.5161],
        [109.3479],
        [105.0109],
        [108.2210],
        [170.6488]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.3096],
        [ 5.0000],
        [ 8.5394],
        [ 8.2544],
        [ 5.0154],
        [ 6.1245],
        [ 7.1180],
        [ 5.4324],
        [ 5.9635]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3473],
        [ 8.6709],
        [ 5.0000],
        [10.0000],
        [ 5.3321],
        [ 6.3349],
        [ 6.3739],
        [ 6.3745],
        [ 6.5520],
        [ 6.2739]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3860],
        [ 5.5484],
        [ 7.5398],
        [ 6.8453],
        [ 5.0000],
        [ 7.6760],
        [ 5.5665],
        [ 5.2528],
        [ 5.4850],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[168.2131],
        [142.2411],
        [140.0001],
        [163.9423],
        [160.6257],
        [140.0724],
        [144.6704],
        [151.5266],
        [142.2411],
        [145.1828]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.2743],
        [75.0035],
        [35.7301],
        [89.0808],
        [38.6006],
        [50.0258],
        [51.4357],
        [50.5977],
        [51.5173],
        [49.1945]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[105.7933],
        [108.2243],
        [135.5888],
        [126.3958],
        [100.9702],
        [137.7205],
        [107.0507],
        [104.1403],
        [108.2202],
        [170.1094]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.3972],
        [ 5.0000],
        [ 9.2431],
        [ 8.6553],
        [ 5.0128],
        [ 5.8277],
        [ 7.0428],
        [ 5.3972],
        [ 5.9185]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3631],
        [ 8.6807],
        [ 5.0000],
        [10.0000],
        [ 5.2690],
        [ 6.3398],
        [ 6.4719],
        [ 6.3934],
        [ 6.4796],
        [ 6.2619]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3488],
        [ 5.5246],
        [ 7.5035],
        [ 6.8387],
        [ 5.0000],
        [ 7.6577],
        [ 5.4397],
        [ 5.2293],
        [ 5.5243],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[141.0418],
        [142.2410],
        [140.3895],
        [153.4711],
        [143.5402],
        [140.0514],
        [142.8824],
        [140.4985],
        [142.2411],
        [140.0024]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7479],
        [74.6889],
        [35.9581],
        [87.1298],
        [35.9906],
        [50.2941],
        [55.7516],
        [52.1965],
        [50.0435],
        [49.2997]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 99.5257],
        [103.5812],
        [128.9265],
        [123.1854],
        [ 99.7143],
        [132.4603],
        [ 99.2207],
        [100.9959],
        [108.3285],
        [164.5923]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.3859],
        [ 5.8310],
        [ 5.1437],
        [10.0000],
        [ 6.3134],
        [ 5.0182],
        [ 6.0691],
        [ 5.1842],
        [ 5.8311],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.6405],
        [ 8.7844],
        [ 5.0000],
        [10.0000],
        [ 5.0032],
        [ 6.4008],
        [ 6.9340],
        [ 6.5867],
        [ 6.3763],
        [ 6.3036]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0233],
        [ 5.3335],
        [ 7.2721],
        [ 6.8330],
        [ 5.0378],
        [ 7.5424],
        [ 5.0000],
        [ 5.1358],
        [ 5.6966],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.5219],
        [142.2410],
        [140.1249],
        [150.8002],
        [141.4395],
        [140.0101],
        [141.3160],
        [141.3086],
        [142.2411],
        [140.0335]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.3168],
        [74.6347],
        [35.9225],
        [86.7142],
        [35.8437],
        [50.3090],
        [54.3009],
        [52.2886],
        [50.0096],
        [49.4388]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.8083],
        [103.2050],
        [127.9436],
        [122.9984],
        [ 99.3584],
        [131.6119],
        [100.5764],
        [101.2761],
        [108.4114],
        [163.1014]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.1639],
        [ 6.0338],
        [ 5.0532],
        [10.0000],
        [ 5.6623],
        [ 5.0000],
        [ 5.6051],
        [ 5.6017],
        [ 6.0338],
        [ 5.0108]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.6191],
        [ 8.8127],
        [ 5.0077],
        [10.0000],
        [ 5.0000],
        [ 6.4218],
        [ 6.8141],
        [ 6.6163],
        [ 6.3923],
        [ 6.3362]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1137],
        [ 5.3017],
        [ 7.2422],
        [ 6.8543],
        [ 5.0000],
        [ 7.5300],
        [ 5.0955],
        [ 5.1504],
        [ 5.7101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.0121],
        [142.2410],
        [140.0858],
        [143.8179],
        [141.4408],
        [140.0275],
        [142.2729],
        [140.4737],
        [142.2411],
        [140.3903]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8811],
        [74.3541],
        [35.9850],
        [84.6594],
        [35.1475],
        [50.5238],
        [54.5049],
        [53.4543],
        [50.5286],
        [50.2623]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 99.1655],
        [100.7882],
        [123.3442],
        [121.4165],
        [ 98.6043],
        [127.6442],
        [ 99.0828],
        [103.8624],
        [108.1570],
        [156.4932]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.0000],
        [ 7.9284],
        [ 5.0969],
        [10.0000],
        [ 6.8771],
        [ 5.0203],
        [ 7.9702],
        [ 5.6065],
        [ 7.9284],
        [ 5.4969]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7908],
        [ 8.9593],
        [ 5.0846],
        [10.0000],
        [ 5.0000],
        [ 6.5528],
        [ 6.9548],
        [ 6.8487],
        [ 6.5533],
        [ 6.5264]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0485],
        [ 5.1886],
        [ 7.1368],
        [ 6.9703],
        [ 5.0000],
        [ 7.5082],
        [ 5.0413],
        [ 5.4542],
        [ 5.8251],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[141.3258],
        [142.2410],
        [140.1140],
        [148.7223],
        [140.3329],
        [140.0138],
        [141.5414],
        [141.0521],
        [142.2411],
        [140.0008]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.4583],
        [74.5662],
        [35.9386],
        [86.2216],
        [35.6080],
        [50.3602],
        [54.3537],
        [52.5712],
        [50.0813],
        [49.6131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.3524],
        [102.5553],
        [126.7481],
        [122.5747],
        [ 99.1397],
        [130.6000],
        [100.1492],
        [101.6595],
        [108.3691],
        [161.5201]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.7597],
        [ 6.2843],
        [ 5.0649],
        [10.0000],
        [ 5.1904],
        [ 5.0075],
        [ 5.8832],
        [ 5.6027],
        [ 6.2843],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.6646],
        [ 8.8486],
        [ 5.0327],
        [10.0000],
        [ 5.0000],
        [ 6.4573],
        [ 6.8518],
        [ 6.6758],
        [ 6.4298],
        [ 6.3835]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0972],
        [ 5.2738],
        [ 7.2129],
        [ 6.8784],
        [ 5.0000],
        [ 7.5216],
        [ 5.0809],
        [ 5.2020],
        [ 5.7398],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.6159],
        [142.2410],
        [140.0089],
        [140.0558],
        [142.8827],
        [140.0009],
        [140.1700],
        [142.6565],
        [142.2411],
        [140.4154]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[54.1176],
        [73.9881],
        [36.0041],
        [81.7095],
        [35.0217],
        [50.7728],
        [54.3059],
        [53.2965],
        [51.2827],
        [51.5627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 99.6053],
        [ 98.5700],
        [118.1579],
        [120.0046],
        [ 97.4332],
        [122.8116],
        [ 98.8848],
        [105.4678],
        [107.7393],
        [146.5709]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 9.5371],
        [ 8.8867],
        [ 5.0138],
        [ 5.0953],
        [10.0000],
        [ 5.0000],
        [ 5.2934],
        [ 9.6075],
        [ 8.8868],
        [ 5.7192]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.0451],
        [ 9.1731],
        [ 5.1052],
        [10.0000],
        [ 5.0000],
        [ 6.6869],
        [ 7.0652],
        [ 6.9571],
        [ 6.7415],
        [ 6.7714]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.2210],
        [ 5.1157],
        [ 7.1088],
        [ 7.2968],
        [ 5.0000],
        [ 7.5824],
        [ 5.1477],
        [ 5.8176],
        [ 6.0487],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8824],
        [142.2410],
        [140.3901],
        [142.8827],
        [142.8827],
        [140.0472],
        [142.8824],
        [142.8824],
        [142.2411],
        [140.0106]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[54.0342],
        [73.6397],
        [35.9947],
        [78.6583],
        [35.2972],
        [50.9894],
        [53.4037],
        [53.0082],
        [51.8143],
        [52.9037]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.2099],
        [ 97.0151],
        [113.7432],
        [119.0148],
        [ 96.3534],
        [118.3713],
        [ 99.8082],
        [107.0833],
        [107.4320],
        [136.1753]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 9.9996],
        [ 8.8830],
        [ 5.6608],
        [10.0000],
        [10.0000],
        [ 5.0638],
        [ 9.9996],
        [ 9.9996],
        [ 8.8830],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.1606],
        [ 9.4213],
        [ 5.0804],
        [10.0000],
        [ 5.0000],
        [ 6.8095],
        [ 7.0879],
        [ 7.0423],
        [ 6.9046],
        [ 7.0302]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4842],
        [ 5.0831],
        [ 7.1834],
        [ 7.8453],
        [ 5.0000],
        [ 7.7645],
        [ 5.4338],
        [ 6.3472],
        [ 6.3910],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.0202],
        [142.2410],
        [140.0091],
        [142.6433],
        [140.0602],
        [140.0021],
        [140.1932],
        [140.0034],
        [142.2411],
        [140.0257]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.9963],
        [74.3315],
        [35.9603],
        [84.3771],
        [35.1469],
        [50.5193],
        [54.1820],
        [52.7770],
        [50.4008],
        [50.3270]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1667],
        [100.7512],
        [122.8997],
        [121.4296],
        [ 98.2293],
        [127.1868],
        [ 99.8766],
        [102.6472],
        [108.1190],
        [155.2373]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.0343],
        [ 9.2385],
        [ 5.0132],
        [10.0000],
        [ 5.1099],
        [ 5.0000],
        [ 5.3618],
        [ 5.0024],
        [ 9.2386],
        [ 5.0447]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.8128],
        [ 8.9797],
        [ 5.0826],
        [10.0000],
        [ 5.0000],
        [ 6.5613],
        [ 6.9333],
        [ 6.7906],
        [ 6.5492],
        [ 6.5417]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1699],
        [ 5.2212],
        [ 7.1638],
        [ 7.0348],
        [ 5.0000],
        [ 7.5398],
        [ 5.1445],
        [ 5.3875],
        [ 5.8674],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2022],
        [142.2410],
        [140.0460],
        [144.6445],
        [140.0000],
        [140.0080],
        [140.6307],
        [140.1237],
        [142.2411],
        [140.0288]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8386],
        [74.4285],
        [35.9547],
        [85.1644],
        [35.2876],
        [50.4552],
        [54.3172],
        [52.7397],
        [50.2626],
        [50.0172]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1683],
        [101.4377],
        [124.4497],
        [121.8630],
        [ 98.6115],
        [128.5877],
        [ 99.8602],
        [102.2251],
        [108.2277],
        [157.9661]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2177],
        [ 7.4126],
        [ 5.0496],
        [10.0000],
        [ 5.0000],
        [ 5.0086],
        [ 5.6789],
        [ 5.1331],
        [ 7.4126],
        [ 5.0310]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7594],
        [ 8.9238],
        [ 5.0669],
        [10.0000],
        [ 5.0000],
        [ 6.5205],
        [ 6.9077],
        [ 6.7495],
        [ 6.5012],
        [ 6.4766]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1311],
        [ 5.2381],
        [ 7.1766],
        [ 6.9587],
        [ 5.0000],
        [ 7.5252],
        [ 5.1052],
        [ 5.3044],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2462],
        [142.2410],
        [140.0541],
        [144.9905],
        [140.0012],
        [140.0092],
        [140.7186],
        [140.1569],
        [142.2411],
        [140.0293]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8151],
        [74.4427],
        [35.9538],
        [85.2792],
        [35.3129],
        [50.4458],
        [54.3379],
        [52.7340],
        [50.2441],
        [49.9726]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1687],
        [101.5434],
        [124.6847],
        [121.9295],
        [ 98.6707],
        [128.7979],
        [ 99.8570],
        [102.1702],
        [108.2438],
        [158.3639]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2455],
        [ 7.2446],
        [ 5.0530],
        [10.0000],
        [ 5.0000],
        [ 5.0080],
        [ 5.7189],
        [ 5.1560],
        [ 7.2447],
        [ 5.0282]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7514],
        [ 8.9156],
        [ 5.0641],
        [10.0000],
        [ 5.0000],
        [ 6.5143],
        [ 6.9038],
        [ 6.7433],
        [ 6.4941],
        [ 6.4670]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1255],
        [ 5.2406],
        [ 7.1790],
        [ 6.9482],
        [ 5.0000],
        [ 7.5235],
        [ 5.0994],
        [ 5.2931],
        [ 5.8019],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2547],
        [142.2410],
        [140.0557],
        [145.0552],
        [140.0017],
        [140.0094],
        [140.7353],
        [140.1634],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8108],
        [74.4453],
        [35.9537],
        [85.3001],
        [35.3177],
        [50.4441],
        [54.3417],
        [52.7330],
        [50.2407],
        [49.9645]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5628],
        [124.7278],
        [121.9417],
        [ 98.6816],
        [128.8363],
        [ 99.8564],
        [102.1604],
        [108.2468],
        [158.4364]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2503],
        [ 7.2156],
        [ 5.0534],
        [10.0000],
        [ 5.0000],
        [ 5.0076],
        [ 5.7258],
        [ 5.1600],
        [ 7.2157],
        [ 5.0274]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7499],
        [ 8.9141],
        [ 5.0636],
        [10.0000],
        [ 5.0000],
        [ 6.5132],
        [ 6.9031],
        [ 6.7421],
        [ 6.4928],
        [ 6.4652]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1244],
        [ 5.2411],
        [ 7.1794],
        [ 6.9463],
        [ 5.0000],
        [ 7.5232],
        [ 5.0983],
        [ 5.2911],
        [ 5.8004],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2563],
        [142.2410],
        [140.0560],
        [145.0671],
        [140.0018],
        [140.0095],
        [140.7384],
        [140.1646],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8100],
        [74.4458],
        [35.9536],
        [85.3039],
        [35.3186],
        [50.4438],
        [54.3424],
        [52.7328],
        [50.2401],
        [49.9630]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5664],
        [124.7357],
        [121.9440],
        [ 98.6836],
        [128.8434],
        [ 99.8563],
        [102.1586],
        [108.2473],
        [158.4497]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2512],
        [ 7.2104],
        [ 5.0534],
        [10.0000],
        [ 5.0000],
        [ 5.0076],
        [ 5.7271],
        [ 5.1607],
        [ 7.2104],
        [ 5.0273]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7497],
        [ 8.9139],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5130],
        [ 6.9029],
        [ 6.7419],
        [ 6.4926],
        [ 6.4649]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1243],
        [ 5.2412],
        [ 7.1795],
        [ 6.9460],
        [ 5.0000],
        [ 7.5232],
        [ 5.0981],
        [ 5.2907],
        [ 5.8001],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0693],
        [140.0018],
        [140.0095],
        [140.7389],
        [140.1648],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3047],
        [35.3187],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9628]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5670],
        [124.7372],
        [121.9444],
        [ 98.6840],
        [128.8447],
        [ 99.8563],
        [102.1583],
        [108.2474],
        [158.4521]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2513],
        [ 7.2094],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7273],
        [ 5.1608],
        [ 7.2094],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0697],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1648],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5671],
        [124.7374],
        [121.9445],
        [ 98.6841],
        [128.8449],
        [ 99.8563],
        [102.1582],
        [108.2474],
        [158.4526]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7273],
        [ 5.1608],
        [ 7.2093],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0697],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4526]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.2566],
        [142.2410],
        [140.0560],
        [145.0698],
        [140.0018],
        [140.0095],
        [140.7391],
        [140.1649],
        [142.2411],
        [140.0294]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8098],
        [74.4459],
        [35.9536],
        [85.3048],
        [35.3188],
        [50.4437],
        [54.3425],
        [52.7328],
        [50.2400],
        [49.9627]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1688],
        [101.5672],
        [124.7375],
        [121.9445],
        [ 98.6841],
        [128.8450],
        [ 99.8563],
        [102.1582],
        [108.2475],
        [158.4527]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2514],
        [ 7.2092],
        [ 5.0535],
        [10.0000],
        [ 5.0000],
        [ 5.0075],
        [ 5.7274],
        [ 5.1608],
        [ 7.2092],
        [ 5.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7496],
        [ 8.9138],
        [ 5.0635],
        [10.0000],
        [ 5.0000],
        [ 6.5129],
        [ 6.9029],
        [ 6.7419],
        [ 6.4925],
        [ 6.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1242],
        [ 5.2412],
        [ 7.1795],
        [ 6.9459],
        [ 5.0000],
        [ 7.5231],
        [ 5.0981],
        [ 5.2906],
        [ 5.8000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1447],
        [142.2410],
        [140.0498],
        [140.0687],
        [140.0117],
        [140.0205],
        [141.0896],
        [140.0632],
        [142.2411],
        [140.2489]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.1217],
        [74.3025],
        [35.9087],
        [83.8846],
        [35.1605],
        [50.5021],
        [52.9210],
        [52.1976],
        [50.1716],
        [50.4274]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.5298],
        [100.7967],
        [122.1470],
        [121.5273],
        [ 97.5711],
        [126.3914],
        [100.9687],
        [101.8840],
        [108.1143],
        [152.7024]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2982],
        [10.0000],
        [ 5.0856],
        [ 5.1280],
        [ 5.0000],
        [ 5.0198],
        [ 7.4176],
        [ 5.1155],
        [10.0000],
        [ 5.5320]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7405],
        [ 9.0167],
        [ 5.0768],
        [10.0000],
        [ 5.0000],
        [ 6.5743],
        [ 6.8226],
        [ 6.7483],
        [ 6.5404],
        [ 6.5667]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.2683],
        [ 5.2925],
        [ 7.2288],
        [ 7.1726],
        [ 5.0000],
        [ 7.6138],
        [ 5.3081],
        [ 5.3911],
        [ 5.9562],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.0407],
        [142.2410],
        [140.0096],
        [142.8435],
        [140.0000],
        [140.0006],
        [140.0564],
        [140.0379],
        [142.2411],
        [140.0011]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.5879],
        [74.4043],
        [35.9401],
        [84.9009],
        [35.2661],
        [50.4607],
        [53.8906],
        [52.5648],
        [50.2183],
        [50.1036]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.2575],
        [101.3349],
        [123.9697],
        [121.8196],
        [ 98.3533],
        [128.1266],
        [100.1496],
        [102.0699],
        [108.2073],
        [156.8339]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.0715],
        [ 8.9406],
        [ 5.0169],
        [10.0000],
        [ 5.0000],
        [ 5.0011],
        [ 5.0992],
        [ 5.0665],
        [ 8.9407],
        [ 5.0018]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7449],
        [ 8.9426],
        [ 5.0679],
        [10.0000],
        [ 5.0000],
        [ 6.5306],
        [ 6.8762],
        [ 6.7426],
        [ 6.5062],
        [ 6.4947]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1628],
        [ 5.2549],
        [ 7.1902],
        [ 7.0063],
        [ 5.0000],
        [ 7.5456],
        [ 5.1536],
        [ 5.3178],
        [ 5.8425],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1339],
        [142.2410],
        [140.0358],
        [144.3034],
        [140.0006],
        [140.0052],
        [140.3591],
        [140.1026],
        [142.2411],
        [140.0097]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7269],
        [74.4320],
        [35.9491],
        [85.1727],
        [35.3006],
        [50.4493],
        [54.1859],
        [52.6729],
        [50.2325],
        [50.0092]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1840],
        [101.4885],
        [124.4837],
        [121.9025],
        [ 98.5748],
        [128.6085],
        [ 99.9428],
        [102.1247],
        [108.2336],
        [157.9301]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1549],
        [ 7.6034],
        [ 5.0408],
        [10.0000],
        [ 5.0000],
        [ 5.0053],
        [ 5.4165],
        [ 5.1184],
        [ 7.6034],
        [ 5.0105]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7471],
        [ 8.9232],
        [ 5.0650],
        [10.0000],
        [ 5.0000],
        [ 6.5188],
        [ 6.8934],
        [ 6.7417],
        [ 6.4970],
        [ 6.4746]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1356],
        [ 5.2454],
        [ 7.1825],
        [ 6.9651],
        [ 5.0000],
        [ 7.5300],
        [ 5.1152],
        [ 5.2990],
        [ 5.8136],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1519],
        [142.2410],
        [140.0409],
        [144.5372],
        [140.0009],
        [140.0062],
        [140.4245],
        [140.1145],
        [142.2411],
        [140.0138]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7473],
        [74.4360],
        [35.9504],
        [85.2116],
        [35.3058],
        [50.4476],
        [54.2295],
        [52.6888],
        [50.2346],
        [49.9953]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1735],
        [101.5108],
        [124.5582],
        [121.9146],
        [ 98.6069],
        [128.6781],
        [ 99.9137],
        [102.1327],
        [108.2375],
        [158.0864]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1665],
        [ 7.4691],
        [ 5.0441],
        [10.0000],
        [ 5.0000],
        [ 5.0059],
        [ 5.4669],
        [ 5.1253],
        [ 7.4692],
        [ 5.0142]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7474],
        [ 8.9204],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5170],
        [ 6.8959],
        [ 6.7416],
        [ 6.4957],
        [ 6.4717]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1317],
        [ 5.2441],
        [ 7.1815],
        [ 6.9593],
        [ 5.0000],
        [ 7.5279],
        [ 5.1099],
        [ 5.2964],
        [ 5.8096],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1551],
        [142.2410],
        [140.0418],
        [144.5776],
        [140.0009],
        [140.0064],
        [140.4362],
        [140.1167],
        [142.2411],
        [140.0145]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7508],
        [74.4366],
        [35.9506],
        [85.2182],
        [35.3067],
        [50.4474],
        [54.2370],
        [52.6915],
        [50.2349],
        [49.9929]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1717],
        [101.5146],
        [124.5709],
        [121.9166],
        [ 98.6124],
        [128.6900],
        [ 99.9087],
        [102.1341],
        [108.2381],
        [158.1130]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1684],
        [ 7.4473],
        [ 5.0447],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4755],
        [ 5.1264],
        [ 7.4473],
        [ 5.0149]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9199],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5168],
        [ 6.8964],
        [ 6.7416],
        [ 6.4955],
        [ 6.4712]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1310],
        [ 5.2439],
        [ 7.1814],
        [ 6.9583],
        [ 5.0000],
        [ 7.5275],
        [ 5.1089],
        [ 5.2959],
        [ 5.8089],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1556],
        [142.2410],
        [140.0420],
        [144.5847],
        [140.0009],
        [140.0065],
        [140.4382],
        [140.1170],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7514],
        [74.4368],
        [35.9506],
        [85.2194],
        [35.3068],
        [50.4473],
        [54.2383],
        [52.6920],
        [50.2350],
        [49.9925]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1714],
        [101.5153],
        [124.5731],
        [121.9170],
        [ 98.6134],
        [128.6921],
        [ 99.9079],
        [102.1343],
        [108.2382],
        [158.1177]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4435],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4770],
        [ 5.1266],
        [ 7.4435],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1088],
        [ 5.2959],
        [ 5.8088],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1557],
        [142.2410],
        [140.0420],
        [144.5859],
        [140.0009],
        [140.0065],
        [140.4386],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7515],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2385],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5735],
        [121.9170],
        [ 98.6135],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1185]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4429],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4429],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4428],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1558],
        [142.2410],
        [140.0420],
        [144.5862],
        [140.0009],
        [140.0065],
        [140.4387],
        [140.1171],
        [142.2411],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7516],
        [74.4368],
        [35.9506],
        [85.2196],
        [35.3069],
        [50.4473],
        [54.2386],
        [52.6921],
        [50.2350],
        [49.9924]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1713],
        [101.5154],
        [124.5736],
        [121.9171],
        [ 98.6136],
        [128.6925],
        [ 99.9077],
        [102.1344],
        [108.2383],
        [158.1186]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1688],
        [ 7.4427],
        [ 5.0448],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4773],
        [ 5.1267],
        [ 7.4427],
        [ 5.0150]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9198],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5167],
        [ 6.8965],
        [ 6.7416],
        [ 6.4954],
        [ 6.4711]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1309],
        [ 5.2438],
        [ 7.1813],
        [ 6.9581],
        [ 5.0000],
        [ 7.5274],
        [ 5.1087],
        [ 5.2958],
        [ 5.8087],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.0981],
        [142.2410],
        [140.0305],
        [144.0962],
        [140.0004],
        [140.0041],
        [140.2567],
        [140.0844],
        [142.2411],
        [140.0056]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7002],
        [74.4277],
        [35.9477],
        [85.1333],
        [35.2953],
        [50.4509],
        [54.1388],
        [52.6543],
        [50.2302],
        [50.0226]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1847],
        [101.4648],
        [124.4086],
        [121.8900],
        [ 98.5425],
        [128.5386],
        [ 99.9665],
        [102.1137],
        [108.2294],
        [157.7755]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1193],
        [ 7.7353],
        [ 5.0367],
        [10.0000],
        [ 5.0000],
        [ 5.0046],
        [ 5.3129],
        [ 5.1025],
        [ 7.7353],
        [ 5.0064]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7462],
        [ 8.9260],
        [ 5.0655],
        [10.0000],
        [ 5.0000],
        [ 6.5205],
        [ 6.8905],
        [ 6.7415],
        [ 6.4983],
        [ 6.4775]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1386],
        [ 5.2467],
        [ 7.1834],
        [ 6.9708],
        [ 5.0000],
        [ 7.5320],
        [ 5.1202],
        [ 5.3015],
        [ 5.8177],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1429],
        [142.2410],
        [140.0395],
        [144.4837],
        [140.0008],
        [140.0059],
        [140.3974],
        [140.1100],
        [142.2411],
        [140.0125]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7410],
        [74.4349],
        [35.9500],
        [85.2020],
        [35.3045],
        [50.4480],
        [54.2180],
        [52.6843],
        [50.2340],
        [49.9986]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1740],
        [101.5050],
        [124.5397],
        [121.9115],
        [ 98.5990],
        [128.6610],
        [ 99.9197],
        [102.1301],
        [108.2364],
        [158.0485]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1584],
        [ 7.4987],
        [ 5.0431],
        [10.0000],
        [ 5.0000],
        [ 5.0057],
        [ 5.4423],
        [ 5.1217],
        [ 7.4987],
        [ 5.0130]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7472],
        [ 8.9211],
        [ 5.0647],
        [10.0000],
        [ 5.0000],
        [ 6.5175],
        [ 6.8952],
        [ 6.7416],
        [ 6.4960],
        [ 6.4724]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1325],
        [ 5.2444],
        [ 7.1817],
        [ 6.9607],
        [ 5.0000],
        [ 7.5284],
        [ 5.1111],
        [ 5.2970],
        [ 5.8106],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1530],
        [142.2410],
        [140.0415],
        [144.5643],
        [140.0009],
        [140.0063],
        [140.4297],
        [140.1156],
        [142.2411],
        [140.0142]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7493],
        [74.4364],
        [35.9505],
        [85.2159],
        [35.3064],
        [50.4475],
        [54.2342],
        [52.6904],
        [50.2348],
        [49.9937]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1719],
        [101.5132],
        [124.5664],
        [121.9159],
        [ 98.6105],
        [128.6858],
        [ 99.9102],
        [102.1335],
        [108.2379],
        [158.1037]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1666],
        [ 7.4544],
        [ 5.0444],
        [10.0000],
        [ 5.0000],
        [ 5.0060],
        [ 5.4698],
        [ 5.1256],
        [ 7.4545],
        [ 5.0146]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7475],
        [ 8.9201],
        [ 5.0645],
        [10.0000],
        [ 5.0000],
        [ 6.5169],
        [ 6.8962],
        [ 6.7416],
        [ 6.4955],
        [ 6.4714]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1312],
        [ 5.2440],
        [ 7.1814],
        [ 6.9587],
        [ 5.0000],
        [ 7.5276],
        [ 5.1092],
        [ 5.2961],
        [ 5.8091],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1440],
        [142.2410],
        [140.0397],
        [144.4929],
        [140.0008],
        [140.0060],
        [140.4011],
        [140.1106],
        [142.2411],
        [140.0127]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7420],
        [74.4351],
        [35.9501],
        [85.2036],
        [35.3047],
        [50.4480],
        [54.2199],
        [52.6850],
        [50.2341],
        [49.9980]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1738],
        [101.5060],
        [124.5428],
        [121.9120],
        [ 98.6003],
        [128.6638],
        [ 99.9186],
        [102.1305],
        [108.2366],
        [158.0549]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1594],
        [ 7.4935],
        [ 5.0433],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4455],
        [ 5.1222],
        [ 7.4935],
        [ 5.0132]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9210],
        [ 5.0647],
        [10.0000],
        [ 5.0000],
        [ 6.5174],
        [ 6.8954],
        [ 6.7416],
        [ 6.4960],
        [ 6.4723]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1323],
        [ 5.2444],
        [ 7.1817],
        [ 6.9605],
        [ 5.0000],
        [ 7.5283],
        [ 5.1109],
        [ 5.2969],
        [ 5.8104],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1458],
        [142.2410],
        [140.0401],
        [144.5072],
        [140.0008],
        [140.0061],
        [140.4067],
        [140.1116],
        [142.2411],
        [140.0130]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7434],
        [74.4354],
        [35.9502],
        [85.2061],
        [35.3050],
        [50.4479],
        [54.2228],
        [52.6861],
        [50.2342],
        [49.9972]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1734],
        [101.5074],
        [124.5475],
        [121.9128],
        [ 98.6023],
        [128.6682],
        [ 99.9169],
        [102.1311],
        [108.2369],
        [158.0647]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1608],
        [ 7.4856],
        [ 5.0435],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4504],
        [ 5.1229],
        [ 7.4856],
        [ 5.0135]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9208],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8955],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1321],
        [ 5.2443],
        [ 7.1816],
        [ 6.9601],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.5244],
        [142.2410],
        [140.1889],
        [140.7789],
        [140.0266],
        [140.0618],
        [142.7315],
        [140.2943],
        [142.2411],
        [140.5855]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[51.8538],
        [74.2322],
        [35.8877],
        [83.1231],
        [35.1034],
        [50.5325],
        [52.3603],
        [51.9758],
        [50.1445],
        [50.6579]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.7480],
        [100.4463],
        [120.8634],
        [121.3299],
        [ 97.0252],
        [125.1420],
        [101.6046],
        [101.7725],
        [108.0563],
        [149.5203]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.9200],
        [ 9.0933],
        [ 5.2999],
        [ 6.3906],
        [ 5.0000],
        [ 5.0650],
        [10.0000],
        [ 5.4947],
        [ 9.0934],
        [ 6.0331]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7441],
        [ 9.0742],
        [ 5.0817],
        [10.0000],
        [ 5.0000],
        [ 6.6065],
        [ 6.7969],
        [ 6.7568],
        [ 6.5661],
        [ 6.6196]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3546],
        [ 5.3259],
        [ 7.2705],
        [ 7.3149],
        [ 5.0000],
        [ 7.6780],
        [ 5.4362],
        [ 5.4522],
        [ 6.0507],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.0153],
        [142.2410],
        [140.0026],
        [142.0798],
        [140.0002],
        [140.0000],
        [140.0100],
        [140.0168],
        [142.2411],
        [140.0083]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.5219],
        [74.3899],
        [35.9354],
        [84.7495],
        [35.2486],
        [50.4670],
        [53.7459],
        [52.5117],
        [50.2115],
        [50.1563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.3008],
        [101.2564],
        [123.6877],
        [121.7757],
        [ 98.2315],
        [127.8600],
        [100.2630],
        [102.0429],
        [108.1946],
        [156.2063]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.0341],
        [10.0000],
        [ 5.0059],
        [ 9.6401],
        [ 5.0005],
        [ 5.0000],
        [ 5.0223],
        [ 5.0376],
        [10.0000],
        [ 5.0184]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7447],
        [ 8.9536],
        [ 5.0694],
        [10.0000],
        [ 5.0000],
        [ 6.5372],
        [ 6.8684],
        [ 6.7437],
        [ 6.5114],
        [ 6.5058]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1785],
        [ 5.2609],
        [ 7.1955],
        [ 7.0306],
        [ 5.0000],
        [ 7.5553],
        [ 5.1752],
        [ 5.3287],
        [ 5.8593],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1204],
        [142.2410],
        [140.0324],
        [144.1276],
        [140.0005],
        [140.0046],
        [140.3195],
        [140.0938],
        [142.2411],
        [140.0074]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7128],
        [74.4292],
        [35.9482],
        [85.1450],
        [35.2970],
        [50.4505],
        [54.1564],
        [52.6621],
        [50.2311],
        [50.0192]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1906],
        [101.4731],
        [124.4305],
        [121.8941],
        [ 98.5518],
        [128.5587],
        [ 99.9624],
        [102.1190],
        [108.2311],
        [157.8169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1452],
        [ 7.7144],
        [ 5.0386],
        [10.0000],
        [ 5.0000],
        [ 5.0049],
        [ 5.3864],
        [ 5.1131],
        [ 7.7144],
        [ 5.0084]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7469],
        [ 8.9252],
        [ 5.0653],
        [10.0000],
        [ 5.0000],
        [ 6.5200],
        [ 6.8917],
        [ 6.7418],
        [ 6.4980],
        [ 6.4767]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1383],
        [ 5.2465],
        [ 7.1833],
        [ 6.9693],
        [ 5.0000],
        [ 7.5316],
        [ 5.1190],
        [ 5.3009],
        [ 5.8166],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1421],
        [142.2410],
        [140.0389],
        [144.4508],
        [140.0008],
        [140.0058],
        [140.3938],
        [140.1090],
        [142.2411],
        [140.0121]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7390],
        [74.4345],
        [35.9499],
        [85.1972],
        [35.3038],
        [50.4482],
        [54.2131],
        [52.6826],
        [50.2338],
        [50.0004]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1760],
        [101.5025],
        [124.5305],
        [121.9101],
        [ 98.5950],
        [128.6523],
        [ 99.9235],
        [102.1294],
        [108.2360],
        [158.0287]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1588],
        [ 7.5171],
        [ 5.0428],
        [10.0000],
        [ 5.0000],
        [ 5.0057],
        [ 5.4416],
        [ 5.1215],
        [ 7.5172],
        [ 5.0127]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7472],
        [ 8.9214],
        [ 5.0647],
        [10.0000],
        [ 5.0000],
        [ 6.5177],
        [ 6.8950],
        [ 6.7416],
        [ 6.4962],
        [ 6.4728]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1330],
        [ 5.2446],
        [ 7.1819],
        [ 6.9614],
        [ 5.0000],
        [ 7.5286],
        [ 5.1118],
        [ 5.2973],
        [ 5.8111],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1456],
        [142.2410],
        [140.0400],
        [144.5014],
        [140.0008],
        [140.0060],
        [140.4059],
        [140.1114],
        [142.2411],
        [140.0129]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7431],
        [74.4353],
        [35.9502],
        [85.2052],
        [35.3049],
        [50.4479],
        [54.2219],
        [52.6858],
        [50.2342],
        [49.9975]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1737],
        [101.5070],
        [124.5459],
        [121.9125],
        [ 98.6016],
        [128.6667],
        [ 99.9176],
        [102.1310],
        [108.2368],
        [158.0612]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1608],
        [ 7.4888],
        [ 5.0435],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4501],
        [ 5.1228],
        [ 7.4888],
        [ 5.0134]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9209],
        [ 5.0647],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8955],
        [ 6.7416],
        [ 6.4959],
        [ 6.4722]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1322],
        [ 5.2443],
        [ 7.1817],
        [ 6.9602],
        [ 5.0000],
        [ 7.5282],
        [ 5.1107],
        [ 5.2968],
        [ 5.8102],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1462],
        [142.2410],
        [140.0401],
        [144.5095],
        [140.0008],
        [140.0061],
        [140.4079],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7437],
        [74.4354],
        [35.9502],
        [85.2065],
        [35.3051],
        [50.4479],
        [54.2233],
        [52.6863],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1734],
        [101.5077],
        [124.5483],
        [121.9129],
        [ 98.6027],
        [128.6690],
        [ 99.9167],
        [102.1312],
        [108.2369],
        [158.0663]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4843],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4514],
        [ 5.1230],
        [ 7.4844],
        [ 5.0135]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9208],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1321],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1462],
        [142.2410],
        [140.0402],
        [144.5108],
        [140.0008],
        [140.0061],
        [140.4082],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5487],
        [121.9130],
        [ 98.6028],
        [128.6693],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0671]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4836],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4516],
        [ 5.1231],
        [ 7.4837],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9208],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1321],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4082],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4082],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.0924],
        [142.2410],
        [140.0289],
        [144.0200],
        [140.0003],
        [140.0038],
        [140.2382],
        [140.0806],
        [142.2411],
        [140.0047]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.6933],
        [74.4264],
        [35.9473],
        [85.1203],
        [35.2936],
        [50.4515],
        [54.1244],
        [52.6490],
        [50.2295],
        [50.0272]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1878],
        [101.4574],
        [124.3837],
        [121.8859],
        [ 98.5318],
        [128.5152],
        [ 99.9760],
        [102.1109],
        [108.2282],
        [157.7228]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1145],
        [ 7.7872],
        [ 5.0356],
        [10.0000],
        [ 5.0000],
        [ 5.0044],
        [ 5.2959],
        [ 5.0998],
        [ 7.7872],
        [ 5.0055]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7460],
        [ 8.9269],
        [ 5.0656],
        [10.0000],
        [ 5.0000],
        [ 6.5211],
        [ 6.8896],
        [ 6.7416],
        [ 6.4988],
        [ 6.4785]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1399],
        [ 5.2471],
        [ 7.1838],
        [ 6.9728],
        [ 5.0000],
        [ 7.5328],
        [ 5.1220],
        [ 5.3023],
        [ 5.8191],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1348],
        [142.2410],
        [140.0378],
        [144.4131],
        [140.0007],
        [140.0056],
        [140.3715],
        [140.1053],
        [142.2411],
        [140.0111]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7339],
        [74.4337],
        [35.9496],
        [85.1899],
        [35.3028],
        [50.4486],
        [54.2041],
        [52.6791],
        [50.2333],
        [50.0029]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1761],
        [101.4979],
        [124.5165],
        [121.9077],
        [ 98.5890],
        [128.6393],
        [ 99.9280],
        [102.1273],
        [108.2352],
        [158.0002]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1519],
        [ 7.5387],
        [ 5.0420],
        [10.0000],
        [ 5.0000],
        [ 5.0055],
        [ 5.4201],
        [ 5.1185],
        [ 7.5387],
        [ 5.0118]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7471],
        [ 8.9219],
        [ 5.0648],
        [10.0000],
        [ 5.0000],
        [ 6.5180],
        [ 6.8944],
        [ 6.7416],
        [ 6.4964],
        [ 6.4733]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1336],
        [ 5.2448],
        [ 7.1820],
        [ 6.9625],
        [ 5.0000],
        [ 7.5290],
        [ 5.1127],
        [ 5.2978],
        [ 5.8118],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1439],
        [142.2410],
        [140.0397],
        [144.4911],
        [140.0008],
        [140.0060],
        [140.4007],
        [140.1105],
        [142.2411],
        [140.0127]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7418],
        [74.4351],
        [35.9501],
        [85.2033],
        [35.3046],
        [50.4480],
        [54.2196],
        [52.6849],
        [50.2341],
        [49.9982]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1739],
        [101.5058],
        [124.5423],
        [121.9119],
        [ 98.6001],
        [128.6633],
        [ 99.9188],
        [102.1305],
        [108.2366],
        [158.0537]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1593],
        [ 7.4945],
        [ 5.0433],
        [10.0000],
        [ 5.0000],
        [ 5.0057],
        [ 5.4452],
        [ 5.1221],
        [ 7.4945],
        [ 5.0132]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9210],
        [ 5.0647],
        [10.0000],
        [ 5.0000],
        [ 6.5174],
        [ 6.8953],
        [ 6.7416],
        [ 6.4960],
        [ 6.4723]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1324],
        [ 5.2444],
        [ 7.1817],
        [ 6.9605],
        [ 5.0000],
        [ 7.5283],
        [ 5.1109],
        [ 5.2969],
        [ 5.8104],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1458],
        [142.2410],
        [140.0401],
        [144.5069],
        [140.0008],
        [140.0061],
        [140.4067],
        [140.1116],
        [142.2411],
        [140.0130]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7434],
        [74.4353],
        [35.9502],
        [85.2060],
        [35.3050],
        [50.4479],
        [54.2227],
        [52.6861],
        [50.2342],
        [49.9972]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1734],
        [101.5074],
        [124.5475],
        [121.9128],
        [ 98.6023],
        [128.6682],
        [ 99.9170],
        [102.1311],
        [108.2369],
        [158.0645]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1608],
        [ 7.4857],
        [ 5.0435],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4503],
        [ 5.1229],
        [ 7.4858],
        [ 5.0135]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9208],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8955],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1321],
        [ 5.2443],
        [ 7.1817],
        [ 6.9601],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1462],
        [142.2410],
        [140.0401],
        [144.5102],
        [140.0008],
        [140.0061],
        [140.4079],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7437],
        [74.4354],
        [35.9502],
        [85.2066],
        [35.3051],
        [50.4479],
        [54.2234],
        [52.6863],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5077],
        [124.5485],
        [121.9129],
        [ 98.6028],
        [128.6692],
        [ 99.9166],
        [102.1312],
        [108.2369],
        [158.0667]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1611],
        [ 7.4840],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4514],
        [ 5.1230],
        [ 7.4840],
        [ 5.0135]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9208],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1321],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1462],
        [142.2410],
        [140.0402],
        [144.5108],
        [140.0008],
        [140.0061],
        [140.4082],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5487],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0672]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4836],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4516],
        [ 5.1231],
        [ 7.4836],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1321],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4082],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4516],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4082],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4082],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1463],
        [142.2410],
        [140.0402],
        [144.5110],
        [140.0008],
        [140.0061],
        [140.4083],
        [140.1118],
        [142.2411],
        [140.0131]], device='cuda:0', dtype=torch.float64), tensor([[52.7438],
        [74.4354],
        [35.9502],
        [85.2067],
        [35.3051],
        [50.4478],
        [54.2235],
        [52.6864],
        [50.2343],
        [49.9970]], device='cuda:0', dtype=torch.float64), tensor([[100.1733],
        [101.5078],
        [124.5488],
        [121.9130],
        [ 98.6029],
        [128.6694],
        [ 99.9165],
        [102.1313],
        [108.2369],
        [158.0673]], device='cuda:0', dtype=torch.float64)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1612],
        [ 7.4835],
        [ 5.0436],
        [10.0000],
        [ 5.0000],
        [ 5.0058],
        [ 5.4517],
        [ 5.1231],
        [ 7.4835],
        [ 5.0136]], device='cuda:0', dtype=torch.float64), tensor([[ 6.7473],
        [ 8.9207],
        [ 5.0646],
        [10.0000],
        [ 5.0000],
        [ 6.5173],
        [ 6.8956],
        [ 6.7416],
        [ 6.4959],
        [ 6.4721]], device='cuda:0', dtype=torch.float64), tensor([[ 5.1320],
        [ 5.2443],
        [ 7.1816],
        [ 6.9600],
        [ 5.0000],
        [ 7.5281],
        [ 5.1105],
        [ 5.2967],
        [ 5.8101],
        [10.0000]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION: [tensor([[142.3885],
        [145.5871],
        [174.8970],
        [170.9017],
        [179.5178],
        [150.0107],
        [141.9908],
        [165.6734],
        [159.1328],
        [140.4244],
        [164.2126],
        [179.9829],
        [179.0162],
        [170.2043],
        [142.2457],
        [152.8613],
        [150.0684],
        [141.1142],
        [165.5602],
        [176.9768],
        [179.6611],
        [161.1531],
        [140.0129],
        [154.1409],
        [168.5755],
        [140.9390],
        [154.6948],
        [177.9087],
        [173.1661],
        [176.7816],
        [149.3217],
        [145.3439],
        [146.5491],
        [147.5825],
        [175.7529],
        [174.8303],
        [178.5755],
        [156.8386],
        [140.4644],
        [166.4709],
        [156.3322],
        [140.1607],
        [158.9441],
        [179.8963],
        [175.6392],
        [167.2242],
        [141.9286],
        [148.6211],
        [151.3021],
        [143.3250],
        [171.6905],
        [178.1670],
        [179.9836],
        [162.0490],
        [140.1306],
        [161.3997],
        [163.4817],
        [141.2735],
        [151.9798],
        [179.8114],
        [172.7651],
        [173.6653],
        [144.1855],
        [143.2645],
        [144.1985],
        [145.0543],
        [172.6357],
        [171.4813],
        [179.5795],
        [153.4769],
        [141.9017],
        [162.1272],
        [160.7851],
        [140.0921],
        [162.4231],
        [179.9487],
        [178.0097],
        [171.1848],
        [143.6772],
        [151.6417],
        [147.5300],
        [141.2989],
        [168.7063],
        [176.4548],
        [179.6686],
        [157.5889],
        [140.0342],
        [157.9305],
        [166.8186],
        [140.3416],
        [156.2247],
        [178.7114],
        [175.2362],
        [175.9768],
        [147.2896],
        [146.0937],
        [144.9270],
        [149.0061],
        [176.9793],
        [173.6239],
        [178.0731],
        [154.0955],
        [140.7617],
        [168.9062],
        [155.7039],
        [140.0106],
        [159.7942],
        [179.3034],
        [177.6594],
        [167.0922],
        [140.6464],
        [148.9113],
        [153.2141],
        [142.5417],
        [169.6700],
        [178.8991],
        [179.9990],
        [164.5789],
        [140.3522],
        [158.5174],
        [164.3500],
        [142.7514],
        [151.4351],
        [179.1759],
        [169.5125],
        [173.9498],
        [146.5623],
        [143.2064],
        [142.7459],
        [146.1699],
        [174.3780],
        [170.3347],
        [179.1797],
        [151.0603],
        [142.5104],
        [164.4314],
        [158.4339],
        [140.2672],
        [164.9836],
        [179.9991],
        [178.5681],
        [169.1346],
        [142.8097],
        [154.0462],
        [149.4438],
        [140.8603],
        [166.2835],
        [177.3183],
        [179.3693],
        [159.9586],
        [140.0043],
        [155.3849],
        [169.1979],
        [140.6988],
        [153.9386],
        [178.1821],
        [174.1303],
        [177.4170],
        [148.3560],
        [144.5183],
        [146.0423],
        [146.9266],
        [176.2259],
        [175.2477],
        [179.0237],
        [155.6350],
        [140.2481],
        [167.6474],
        [157.0485],
        [140.0738],
        [158.1878],
        [179.8178],
        [176.4448],
        [168.3260],
        [141.4726],
        [147.5861],
        [151.9369],
        [143.8114],
        [171.0379],
        [177.8911],
        [179.8872],
        [163.2613],
        [140.0318],
        [160.1475],
        [162.7600],
        [141.5787],
        [152.6823],
        [179.7088],
        [171.7006],
        [172.7721],
        [144.9022],
        [144.0021],
        [143.7790],
        [144.5002],
        [173.2397],
        [171.9967],
        [179.8053],
        [152.3344],
        [141.4383],
        [163.3694],
        [161.5136],
        [140.1879],
        [161.6655],
        [179.9854],
        [178.5543],
        [172.1523],
        [143.0510],
        [150.4933],
        [148.0808],
        [141.6172],
        [167.9895],
        [176.0861],
        [179.8649],
        [158.8104],
        [140.1361],
        [156.6855],
        [166.1305],
        [140.5090],
        [156.9709],
        [178.4667],
        [174.3279],
        [175.2297],
        [148.1848],
        [147.0485],
        [145.4142],
        [149.6992],
        [176.5665],
        [173.1297],
        [177.4539],
        [155.2483],
        [141.1020],
        [167.7351],
        [155.0270],
        [140.0010],
        [160.5819],
        [179.4594],
        [177.0022],
        [165.9336],
        [140.9728],
        [149.9792],
        [152.5314],
        [142.1546],
        [170.3288],
        [179.1071],
        [179.9399],
        [163.4123],
        [140.5946],
        [159.8008],
        [165.0297],
        [142.3351],
        [150.7251],
        [179.3473],
        [170.6485],
        [174.7998],
        [145.7263],
        [142.5592],
        [142.6308],
        [145.9272],
        [174.5642],
        [170.4725],
        [179.4062],
        [150.4470],
        [142.2174],
        [165.1998],
        [159.6404],
        [140.5311],
        [163.7379],
        [179.9559],
        [179.1629],
        [170.6375],
        [142.0210],
        [152.4111],
        [149.6376],
        [140.9603],
        [166.0314],
        [177.2396],
        [179.5667],
        [160.6539],
        [140.0011],
        [154.6131],
        [168.1143],
        [141.0938],
        [155.1632],
        [177.6806],
        [172.7917],
        [176.5001],
        [149.7475],
        [145.6779],
        [146.9233],
        [147.9656],
        [175.4449],
        [174.4850],
        [178.3906],
        [157.3330],
        [140.5794],
        [166.0035],
        [156.8323],
        [140.1045],
        [158.4609],
        [179.8393],
        [175.9411],
        [167.6954],
        [141.7201],
        [148.2261],
        [150.8548],
        [143.0624],
        [172.0861],
        [178.3734],
        [179.9974],
        [161.5512],
        [140.1951],
        [161.8904],
        [162.9807],
        [141.4520],
        [152.4260],
        [179.7368],
        [172.3824],
        [173.2904],
        [144.4964],
        [143.5346],
        [143.8968],
        [144.7369],
        [173.0134],
        [171.8931],
        [179.6726],
        [153.0065],
        [141.6914],
        [162.6156],
        [160.2777],
        [140.0510],
        [162.9029],
        [179.9066],
        [177.7903],
        [170.7602],
        [143.9710],
        [152.0842],
        [147.9247],
        [141.4762],
        [168.2607],
        [176.1610],
        [179.7507],
        [158.0859],
        [140.0703],
        [157.4416],
        [167.2937],
        [140.2570],
        [155.7500],
        [178.8820],
        [175.5505],
        [176.2768],
        [146.9075],
        [145.7497],
        [144.6032],
        [148.6047],
        [177.2339],
        [173.9913],
        [178.2752],
        [153.6197],
        [140.6291],
        [169.3441],
        [155.2094],
        [140.0006],
        [160.2786],
        [179.4281],
        [177.4231],
        [166.6154],
        [140.7785],
        [149.3175],
        [153.6865],
        [142.7831],
        [169.2363],
        [178.7270],
        [179.9980],
        [165.0639],
        [140.2637],
        [158.0271],
        [164.8438],
        [142.5075],
        [151.0000],
        [179.3119],
        [169.9423],
        [174.3091],
        [146.1964],
        [142.9482],
        [143.0041],
        [146.5239],
        [174.0318],
        [169.8967],
        [179.0368],
        [151.5104],
        [142.7623],
        [163.9502],
        [158.9407],
        [140.3533],
        [164.5130],
        [179.9881],
        [178.7452],
        [169.5832],
        [142.5595],
        [153.5857],
        [149.0225],
        [140.7254],
        [166.7489],
        [177.5665],
        [179.2429],
        [159.4589],
        [140.0213],
        [155.8650],
        [168.7444],
        [140.8337],
        [154.4018],
        [177.9681],
        [173.7780],
        [177.1618],
        [148.7658],
        [144.8296],
        [146.4049],
        [147.2968],
        [175.9333],
        [174.9144],
        [178.8686],
        [156.1240],
        [140.3342],
        [167.1905],
        [157.5514],
        [140.0376],
        [157.7061],
        [179.7442],
        [176.7198],
        [168.7850],
        [141.2899],
        [147.2099],
        [151.4821],
        [143.5316],
        [171.4449],
        [178.1122],
        [179.9328],
        [162.7671],
        [140.0669],
        [160.6397],
        [162.2564],
        [141.7759],
        [153.1354],
        [179.6178],
        [171.2978],
        [172.3775],
        [145.2349],
        [144.2974],
        [143.4916],
        [144.1987],
        [173.6046],
        [172.3989],
        [179.8669],
        [151.8751],
        [141.2553],
        [163.8532],
        [161.0068],
        [140.1266],
        [162.1474],
        [179.9601],
        [178.3651],
        [171.7451],
        [143.3216],
        [150.9223],
        [148.4858],
        [141.8134],
        [167.5361],
        [175.7793],
        [179.9153],
        [159.3098],
        [140.2015],
        [156.2011],
        [166.6118],
        [140.4046],
        [156.4929],
        [178.6528],
        [174.6670],
        [175.5537],
        [147.7852],
        [146.6832],
        [145.0768],
        [149.2870],
        [176.8371],
        [173.5085],
        [177.6852],
        [154.7641],
        [140.9419],
        [168.1866],
        [154.5369],
        [140.0120],
        [161.0658],
        [179.5687],
        [176.7379],
        [165.4470],
        [141.1328],
        [150.4011],
        [152.9975],
        [142.3784],
        [169.9042],
        [178.9510],
        [179.9715],
        [163.9035],
        [140.4780],
        [159.3088],
        [165.5191],
        [142.1096],
        [150.2989],
        [179.4679],
        [171.0617],
        [175.1365],
        [145.3808],
        [142.3272]], device='cuda:0', dtype=torch.float64), tensor([[75.0703],
        [41.4119],
        [64.2435],
        [51.6881],
        [61.0223],
        [72.4932],
        [35.2420],
        [74.0302],
        [36.0483],
        [75.8277],
        [70.3055],
        [65.7143],
        [61.5228],
        [53.1337],
        [86.3652],
        [39.6187],
        [87.5631],
        [35.1431],
        [68.1909],
        [51.5884],
        [49.4679],
        [57.5461],
        [37.9250],
        [89.6168],
        [44.9967],
        [89.0338],
        [37.8727],
        [66.4291],
        [69.8908],
        [61.7676],
        [87.3461],
        [35.0081],
        [62.7331],
        [67.4877],
        [36.5570],
        [88.7283],
        [89.5605],
        [38.3740],
        [62.8284],
        [39.6119],
        [65.7181],
        [49.8731],
        [89.3853],
        [40.7054],
        [35.0429],
        [83.8818],
        [48.7136],
        [72.9867],
        [50.9960],
        [67.4900],
        [43.2462],
        [81.9585],
        [71.7223],
        [35.1135],
        [71.2610],
        [64.1276],
        [68.8389],
        [68.0444],
        [85.7808],
        [35.4364],
        [37.4554],
        [78.4790],
        [55.4370],
        [59.2046],
        [37.6739],
        [67.1101],
        [55.0538],
        [74.9960],
        [74.5571],
        [50.4239],
        [65.1239],
        [54.5078],
        [83.8262],
        [45.2385],
        [70.1317],
        [50.3548],
        [56.8404],
        [74.8412],
        [36.5610],
        [64.5917],
        [49.0484],
        [85.3220],
        [42.7768],
        [71.9072],
        [73.9636],
        [45.0424],
        [81.4255],
        [35.6111],
        [73.2214],
        [40.3622],
        [74.7804],
        [50.7755],
        [38.5482],
        [73.1290],
        [51.8904],
        [83.4547],
        [69.4951],
        [35.3384],
        [87.3302],
        [46.8926],
        [36.9202],
        [79.9593],
        [45.8800],
        [74.5475],
        [40.3251],
        [74.9842],
        [38.8324],
        [76.9365],
        [81.7957],
        [55.8512],
        [73.9707],
        [46.6882],
        [74.9622],
        [51.2223],
        [60.3975],
        [41.0986],
        [53.7129],
        [78.5064],
        [50.6233],
        [72.6630],
        [49.8954],
        [70.6030],
        [50.4146],
        [73.8638],
        [81.8224],
        [36.2471],
        [73.4333],
        [57.5338],
        [66.6395],
        [50.6986],
        [80.8598],
        [43.9614],
        [35.0523],
        [71.8345],
        [63.2318],
        [70.6182],
        [67.3488],
        [68.3419],
        [35.3422],
        [85.3246],
        [76.0693],
        [37.6835],
        [58.5415],
        [54.9849],
        [65.3247],
        [61.4505],
        [89.4242],
        [35.7521],
        [39.8506],
        [89.4867],
        [38.5884],
        [60.3704],
        [49.5026],
        [63.7596],
        [42.2131],
        [89.7879],
        [85.2608],
        [35.2816],
        [71.8991],
        [48.6633],
        [35.5427],
        [87.2069],
        [53.5136],
        [69.5819],
        [59.5803],
        [46.4181],
        [89.9261],
        [36.8534],
        [88.2094],
        [42.7889],
        [68.3536],
        [37.8625],
        [61.4788],
        [71.4224],
        [35.1088],
        [85.8876],
        [40.9948],
        [75.0774],
        [51.3910],
        [64.6914],
        [72.7333],
        [61.4493],
        [77.9682],
        [35.1477],
        [76.1143],
        [36.4437],
        [66.4569],
        [71.0575],
        [53.6170],
        [62.3582],
        [38.9415],
        [88.6160],
        [52.9417],
        [74.6977],
        [39.6435],
        [58.1567],
        [71.8248],
        [51.6828],
        [73.6044],
        [50.1864],
        [72.1115],
        [49.9782],
        [71.4530],
        [48.0589],
        [35.5390],
        [77.1302],
        [59.7216],
        [74.2926],
        [35.5899],
        [70.0382],
        [46.4524],
        [86.3368],
        [79.5107],
        [36.7191],
        [74.6789],
        [51.6436],
        [75.0155],
        [42.0761],
        [75.9787],
        [38.3371],
        [54.9857],
        [81.0600],
        [49.4619],
        [74.2827],
        [86.0063],
        [50.0991],
        [71.4075],
        [40.6436],
        [43.7063],
        [73.6301],
        [35.9073],
        [82.4765],
        [40.8493],
        [73.8924],
        [49.5568],
        [74.8481],
        [72.9074],
        [36.2611],
        [83.9984],
        [52.5839],
        [71.7846],
        [39.1569],
        [74.8932],
        [53.5281],
        [50.9966],
        [73.8942],
        [57.1937],
        [67.8157],
        [47.2789],
        [86.0516],
        [50.0690],
        [68.6946],
        [74.4740],
        [55.3177],
        [69.3404],
        [37.5571],
        [49.9560],
        [85.5052],
        [35.1952],
        [71.5420],
        [73.6731],
        [50.4486],
        [82.6152],
        [35.8356],
        [73.9794],
        [40.9537],
        [74.8722],
        [38.3809],
        [47.2670],
        [72.7863],
        [52.8283],
        [84.2399],
        [39.0744],
        [63.6632],
        [53.2007],
        [74.9171],
        [73.9417],
        [51.5966],
        [74.0659],
        [56.9672],
        [76.0468],
        [47.5197],
        [68.5151],
        [49.9520],
        [55.3124],
        [74.4399],
        [37.6189],
        [78.6395],
        [74.6717],
        [53.2148],
        [62.9990],
        [39.5224],
        [51.4730],
        [67.9001],
        [49.8723],
        [73.6934],
        [50.0117],
        [72.0345],
        [48.1917],
        [81.0151],
        [68.1776],
        [35.6012],
        [74.2265],
        [59.4714],
        [70.0794],
        [44.1654],
        [87.1945],
        [46.2316],
        [36.6599],
        [78.6137],
        [42.2899],
        [74.8190],
        [53.0470],
        [75.0002],
        [38.4742],
        [76.3551],
        [81.0189],
        [55.1324],
        [74.2679],
        [38.0057],
        [87.3551],
        [35.6008],
        [69.7182],
        [57.7014],
        [41.7567],
        [59.7534],
        [36.7920],
        [89.7379],
        [42.9844],
        [88.3439],
        [47.1207],
        [68.1654],
        [71.3442],
        [52.0243],
        [85.9334],
        [35.0941],
        [84.6954],
        [40.7829],
        [64.8198],
        [52.1746],
        [60.6092],
        [72.8458],
        [35.2460],
        [69.4640],
        [36.3672],
        [87.8100],
        [71.0711],
        [66.3354],
        [62.1296],
        [53.3297],
        [77.6403],
        [39.1065],
        [50.4663],
        [66.8385],
        [43.8024],
        [74.1558],
        [77.0967],
        [35.0015],
        [70.7093],
        [63.8331],
        [68.1585],
        [67.0398],
        [74.2439],
        [35.3078],
        [37.7505],
        [86.9511],
        [54.9498],
        [58.3963],
        [54.8683],
        [65.5246],
        [35.7928],
        [88.7417],
        [89.9667],
        [39.6915],
        [60.5334],
        [46.2734],
        [63.6372],
        [40.0066],
        [89.7202],
        [42.3265],
        [35.3243],
        [85.5209],
        [58.3050],
        [71.7510],
        [39.6276],
        [69.3595],
        [47.0262],
        [87.6393],
        [79.9454],
        [37.0270],
        [74.5200],
        [41.3547],
        [74.9857],
        [50.2411],
        [76.8304],
        [38.7455],
        [55.6073],
        [81.5473],
        [37.7796],
        [74.0519],
        [51.9123],
        [74.9757],
        [41.1777],
        [69.8670],
        [69.8212],
        [54.0034],
        [72.5928],
        [49.7122],
        [70.7562],
        [50.0549],
        [85.0251],
        [50.1550],
        [36.2164],
        [70.3620],
        [57.5184],
        [73.4896],
        [61.0437],
        [37.7886],
        [74.9985],
        [54.6240],
        [50.9055],
        [74.5044],
        [54.6941],
        [71.1045],
        [45.1196],
        [72.9530],
        [50.3099],
        [70.2267],
        [74.8707],
        [57.0812],
        [75.6281],
        [36.4592],
        [84.9002],
        [49.2845],
        [71.8567],
        [35.5869],
        [51.9559],
        [73.8506],
        [35.6475],
        [82.0742],
        [40.1967],
        [72.9002],
        [40.9606],
        [74.7542],
        [73.1783],
        [47.9099],
        [83.4640],
        [51.7436],
        [67.3502],
        [56.6507],
        [88.4430],
        [36.4631],
        [38.4557],
        [89.9415],
        [45.6103],
        [62.6523],
        [38.5172],
        [65.9311],
        [40.5355],
        [89.2714],
        [83.8528],
        [35.0337],
        [73.0424],
        [59.4342],
        [67.3740],
        [50.4265],
        [74.5935],
        [43.4252],
        [35.0133],
        [78.7323],
        [64.4750],
        [71.1177],
        [68.0809],
        [68.9439],
        [35.4799],
        [76.0943],
        [88.1575],
        [37.3268],
        [59.4452],
        [55.6908],
        [41.5676],
        [79.6979],
        [51.8008],
        [64.0260],
        [72.4208],
        [60.6423],
        [70.0172],
        [35.3025],
        [84.7287],
        [36.1231],
        [65.9219],
        [70.5954],
        [53.1788],
        [61.6610],
        [39.5304],
        [76.7273],
        [35.1261],
        [88.5015],
        [60.4070],
        [67.9449],
        [57.4029],
        [40.2976],
        [88.7088],
        [38.0546],
        [89.1195],
        [44.8686],
        [66.5327],
        [49.3942],
        [50.8442],
        [70.0747],
        [35.0027],
        [87.0391]], device='cuda:0', dtype=torch.float64), tensor([[109.6853],
        [163.1213],
        [110.1927],
        [125.3351],
        [ 95.1258],
        [154.9402],
        [120.2891],
        [155.9777],
        [ 97.0723],
        [139.6182],
        [120.4123],
        [148.6575],
        [113.1622],
        [159.6941],
        [114.6645],
        [114.7146],
        [163.8523],
        [111.5581],
        [121.8632],
        [115.1507],
        [149.8895],
        [ 93.8678],
        [153.4095],
        [117.5145],
        [150.6926],
        [ 92.5144],
        [155.4174],
        [111.9711],
        [160.2034],
        [103.6415],
        [118.7265],
        [102.9348],
        [139.3690],
        [100.7871],
        [143.6486],
        [135.9993],
        [159.3367],
        [105.9897],
        [134.2207],
        [112.7493],
        [165.6301],
        [ 98.4753],
        [134.9682],
        [112.3786],
        [139.0253],
        [ 95.7358],
        [136.5642],
        [120.2195],
        [ 91.3997],
        [145.7531],
        [123.8396],
        [146.6787],
        [100.7920],
        [170.6888],
        [108.0619],
        [139.8706],
        [ 98.1338],
        [159.1827],
        [112.8883],
        [129.6132],
        [ 97.0819],
        [135.8906],
        [124.1178],
        [141.6740],
        [157.2296],
        [117.1579],
        [154.4287],
        [ 89.5718],
        [123.3089],
        [108.0110],
        [165.7572],
        [113.2656],
        [120.2463],
        [112.8839],
        [156.3851],
        [111.3654],
        [148.2135],
        [113.5836],
        [144.3345],
        [ 90.9270],
        [122.5820],
        [147.7196],
        [ 95.1863],
        [145.0244],
        [115.7150],
        [125.9735],
        [118.4464],
        [162.1410],
        [108.0633],
        [119.0295],
        [108.6338],
        [159.1888],
        [118.6245],
        [147.8384],
        [ 95.7172],
        [148.5835],
        [113.8649],
        [137.0297],
        [ 99.2728],
        [164.8039],
        [124.4379],
        [144.9254],
        [ 96.7005],
        [144.1974],
        [112.1823],
        [143.9982],
        [ 91.5408],
        [135.7789],
        [113.8244],
        [131.6935],
        [ 97.4011],
        [170.6645],
        [140.2049],
        [113.6289],
        [171.7835],
        [102.9138],
        [144.1265],
        [125.6516],
        [139.1790],
        [ 96.7353],
        [139.3881],
        [127.6273],
        [132.5084],
        [ 99.4896],
        [129.0562],
        [114.6426],
        [163.2512],
        [ 99.0750],
        [141.9147],
        [ 93.6718],
        [146.1255],
        [119.8816],
        [168.6309],
        [ 94.8482],
        [133.4038],
        [103.2993],
        [171.9270],
        [104.5272],
        [134.2593],
        [113.1232],
        [136.1417],
        [ 94.5135],
        [148.4576],
        [130.3477],
        [ 96.3945],
        [127.3777],
        [127.4564],
        [138.7287],
        [101.0591],
        [165.3281],
        [116.1446],
        [126.6196],
        [100.6559],
        [170.6065],
        [105.3656],
        [133.8484],
        [ 97.3069],
        [139.6983],
        [130.2318],
        [148.9530],
        [108.9590],
        [155.2003],
        [110.7861],
        [117.2482],
        [ 97.3017],
        [148.8483],
        [118.4062],
        [151.7636],
        [ 90.2558],
        [158.7955],
        [113.5818],
        [152.8305],
        [110.7066],
        [163.8409],
        [111.8385],
        [132.4279],
        [157.2536],
        [106.2157],
        [120.2524],
        [111.0851],
        [148.1106],
        [ 95.1662],
        [145.6325],
        [113.0232],
        [151.4651],
        [100.8664],
        [147.1486],
        [123.5448],
        [152.3247],
        [113.7357],
        [122.6062],
        [114.7308],
        [108.2183],
        [128.8399],
        [100.2441],
        [168.0173],
        [126.8866],
        [139.5479],
        [ 94.4982],
        [132.5973],
        [130.9848],
        [139.0302],
        [ 98.1403],
        [132.0112],
        [113.6169],
        [137.0487],
        [106.0537],
        [166.7550],
        [132.8694],
        [111.7189],
        [167.6661],
        [104.5785],
        [141.5184],
        [124.1205],
        [132.2041],
        [ 90.1083],
        [150.9055],
        [128.3313],
        [144.9370],
        [ 92.2995],
        [137.6738],
        [106.7473],
        [170.9543],
        [102.5912],
        [144.8792],
        [117.2631],
        [143.6599],
        [ 99.3227],
        [118.0352],
        [115.2229],
        [153.8468],
        [104.8558],
        [126.4690],
        [114.1316],
        [166.0919],
        [112.7584],
        [150.6313],
        [115.8700],
        [148.3515],
        [ 95.2095],
        [104.1310],
        [152.1774],
        [ 93.4958],
        [150.1726],
        [113.0122],
        [123.3742],
        [105.7603],
        [163.0223],
        [115.8389],
        [125.1153],
        [110.9771],
        [160.3729],
        [117.8296],
        [153.2269],
        [ 93.9281],
        [156.1017],
        [ 91.5511],
        [141.1268],
        [120.2602],
        [141.6659],
        [ 96.3083],
        [169.6316],
        [106.6602],
        [136.5604],
        [102.6516],
        [163.5068],
        [109.1642],
        [136.1675],
        [ 98.7209],
        [142.6044],
        [133.7644],
        [146.8626],
        [133.9634],
        [100.7436],
        [140.1624],
        [128.5827],
        [157.4642],
        [100.1565],
        [124.7454],
        [114.9070],
        [166.5653],
        [102.5075],
        [138.2366],
        [111.0239],
        [143.4409],
        [ 95.5426],
        [142.6376],
        [127.0814],
        [161.7142],
        [107.9527],
        [117.8115],
        [111.9326],
        [143.5148],
        [ 95.8479],
        [151.4440],
        [117.0040],
        [157.1454],
        [ 92.9448],
        [159.0758],
        [118.5536],
        [165.6014],
        [107.3945],
        [127.6229],
        [105.0270],
        [105.8003],
        [156.2717],
        [103.8599],
        [114.9676],
        [ 95.7429],
        [148.4970],
        [115.9105],
        [152.8470],
        [ 96.2918],
        [144.3724],
        [122.3060],
        [152.0785],
        [115.9057],
        [162.6358],
        [116.3184],
        [117.2437],
        [129.0213],
        [115.6391],
        [167.3262],
        [100.2016],
        [142.1284],
        [116.8609],
        [132.5908],
        [ 94.8224],
        [143.9979],
        [129.9601],
        [139.5701],
        [ 99.2698],
        [131.4737],
        [114.8014],
        [163.8539],
        [103.1368],
        [111.6864],
        [133.1916],
        [ 94.7156],
        [166.0470],
        [123.5995],
        [141.3709],
        [ 98.6077],
        [135.9259],
        [125.1636],
        [148.5377],
        [ 94.5194],
        [142.1783],
        [109.3489],
        [142.9043],
        [ 99.8804],
        [173.5507],
        [117.6051],
        [145.9628],
        [ 93.5681],
        [141.0294],
        [114.8695],
        [116.4741],
        [112.8088],
        [154.2135],
        [110.9097],
        [120.8410],
        [114.3923],
        [161.1749],
        [120.6475],
        [153.0391],
        [ 93.8916],
        [153.1997],
        [152.4866],
        [117.6236],
        [149.8038],
        [ 91.5980],
        [120.9425],
        [101.8994],
        [163.7890],
        [107.2388],
        [127.1416],
        [111.9337],
        [164.9248],
        [113.6235],
        [151.3768],
        [121.2296],
        [147.8975],
        [ 92.7047],
        [160.8521],
        [112.1438],
        [127.2119],
        [114.2918],
        [157.0564],
        [ 92.7620],
        [151.2318],
        [117.4500],
        [147.3313],
        [100.9248],
        [147.9686],
        [120.5686],
        [150.0432],
        [111.1030],
        [115.1308],
        [114.4169],
        [111.9041],
        [155.5921],
        [109.4521],
        [123.2595],
        [ 95.6722],
        [153.7338],
        [122.5786],
        [152.5716],
        [ 92.4255],
        [151.1225],
        [110.2785],
        [149.4946],
        [102.9519],
        [160.2240],
        [108.0243],
        [121.8648],
        [ 97.8191],
        [134.9092],
        [134.3379],
        [147.0213],
        [107.5886],
        [167.9496],
        [115.0182],
        [130.1060],
        [ 99.1977],
        [166.9952],
        [105.6217],
        [128.4757],
        [ 95.3587],
        [136.9053],
        [124.6529],
        [145.3723],
        [144.3497],
        [ 95.8518],
        [152.8625],
        [126.6154],
        [171.6913],
        [ 96.0465],
        [137.3130],
        [103.7879],
        [167.0406],
        [ 99.1620],
        [128.8370],
        [111.9212],
        [130.7166],
        [ 93.9823],
        [142.4910],
        [125.1064],
        [110.8437],
        [153.3858],
        [ 93.7377],
        [152.2022],
        [111.9429],
        [129.4514],
        [109.0192],
        [167.8720],
        [110.9734],
        [119.3218],
        [102.2009],
        [155.2588],
        [115.5158],
        [149.2385],
        [ 96.5073],
        [147.2641],
        [151.1190],
        [121.0716],
        [153.6307],
        [ 96.9390],
        [121.9142],
        [117.6064],
        [156.0782],
        [114.2535],
        [117.0475],
        [114.3555],
        [160.7784],
        [109.7691],
        [151.4169],
        [108.6107],
        [146.3225],
        [ 95.2635],
        [138.5957],
        [108.2946],
        [171.0639],
        [105.2205],
        [143.7381],
        [129.2302],
        [134.8622],
        [ 93.6984],
        [143.9034],
        [125.0419],
        [136.6129],
        [ 91.6671],
        [130.0353],
        [105.7875],
        [170.3106],
        [ 96.4635],
        [109.8124],
        [133.4700],
        [104.9304],
        [168.4477],
        [131.7772],
        [149.5126],
        [ 94.6591],
        [142.3940],
        [126.8434],
        [138.1397],
        [ 94.4925],
        [131.8562],
        [115.1716],
        [129.8424],
        [107.0376],
        [162.9190]], device='cuda:0', dtype=torch.float64)] SHAPE IS = torch.Size([512, 1]) SHAPE IS = torch.Size([512, 1]) SHAPE IS = torch.Size([512, 1]) AFTER NORMALIZATION: [tensor([[ 5.2985],
        [ 5.6983],
        [ 9.3622],
        [ 8.8628],
        [ 9.9398],
        [ 6.2513],
        [ 5.2488],
        [ 8.2092],
        [ 7.3916],
        [ 5.0530],
        [ 8.0266],
        [ 9.9980],
        [ 9.8771],
        [ 8.7756],
        [ 5.2806],
        [ 6.6076],
        [ 6.2585],
        [ 5.1392],
        [ 8.1951],
        [ 9.6222],
        [ 9.9577],
        [ 7.6442],
        [ 5.0015],
        [ 6.7676],
        [ 8.5720],
        [ 5.1173],
        [ 6.8368],
        [ 9.7387],
        [ 9.1458],
        [ 9.5978],
        [ 6.1652],
        [ 5.6679],
        [ 5.8186],
        [ 5.9478],
        [ 9.4692],
        [ 9.3539],
        [ 9.8221],
        [ 7.1048],
        [ 5.0580],
        [ 8.3089],
        [ 7.0415],
        [ 5.0200],
        [ 7.3680],
        [ 9.9872],
        [ 9.4550],
        [ 8.4031],
        [ 5.2410],
        [ 6.0776],
        [ 6.4127],
        [ 5.4156],
        [ 8.9614],
        [ 9.7710],
        [ 9.9981],
        [ 7.7562],
        [ 5.0162],
        [ 7.6750],
        [ 7.9352],
        [ 5.1591],
        [ 6.4975],
        [ 9.9765],
        [ 9.0957],
        [ 9.2082],
        [ 5.5231],
        [ 5.4080],
        [ 5.5248],
        [ 5.6317],
        [ 9.0795],
        [ 8.9352],
        [ 9.9476],
        [ 6.6846],
        [ 5.2376],
        [ 7.7659],
        [ 7.5982],
        [ 5.0114],
        [ 7.8029],
        [ 9.9937],
        [ 9.7513],
        [ 8.8982],
        [ 5.4596],
        [ 6.4552],
        [ 5.9412],
        [ 5.1623],
        [ 8.5883],
        [ 9.5570],
        [ 9.9587],
        [ 7.1986],
        [ 5.0042],
        [ 7.2413],
        [ 8.3524],
        [ 5.0426],
        [ 7.0281],
        [ 9.8390],
        [ 9.4046],
        [ 9.4972],
        [ 5.9112],
        [ 5.7617],
        [ 5.6158],
        [ 6.1257],
        [ 9.6225],
        [ 9.2031],
        [ 9.7592],
        [ 6.7619],
        [ 5.0951],
        [ 8.6133],
        [ 6.9630],
        [ 5.0012],
        [ 7.4743],
        [ 9.9130],
        [ 9.7075],
        [ 8.3866],
        [ 5.0807],
        [ 6.1139],
        [ 6.6517],
        [ 5.3177],
        [ 8.7088],
        [ 9.8625],
        [10.0000],
        [ 8.0724],
        [ 5.0439],
        [ 7.3147],
        [ 8.0438],
        [ 5.3439],
        [ 6.4294],
        [ 9.8971],
        [ 8.6891],
        [ 9.2438],
        [ 5.8202],
        [ 5.4007],
        [ 5.3432],
        [ 5.7712],
        [ 9.2973],
        [ 8.7919],
        [ 9.8976],
        [ 6.3825],
        [ 5.3137],
        [ 8.0540],
        [ 7.3043],
        [ 5.0333],
        [ 8.1230],
        [10.0000],
        [ 9.8211],
        [ 8.6419],
        [ 5.3512],
        [ 6.7558],
        [ 6.1804],
        [ 5.1075],
        [ 8.2855],
        [ 9.6649],
        [ 9.9213],
        [ 7.4948],
        [ 5.0005],
        [ 6.9231],
        [ 8.6498],
        [ 5.0873],
        [ 6.7423],
        [ 9.7729],
        [ 9.2664],
        [ 9.6772],
        [ 6.0445],
        [ 5.5647],
        [ 5.7552],
        [ 5.8658],
        [ 9.5283],
        [ 9.4061],
        [ 9.8781],
        [ 6.9544],
        [ 5.0309],
        [ 8.4560],
        [ 7.1311],
        [ 5.0091],
        [ 7.2735],
        [ 9.9773],
        [ 9.5557],
        [ 8.5408],
        [ 5.1840],
        [ 5.9482],
        [ 6.4921],
        [ 5.4764],
        [ 8.8798],
        [ 9.7365],
        [ 9.9860],
        [ 7.9077],
        [ 5.0039],
        [ 7.5185],
        [ 7.8450],
        [ 5.1973],
        [ 6.5853],
        [ 9.9637],
        [ 8.9626],
        [ 9.0966],
        [ 5.6127],
        [ 5.5002],
        [ 5.4723],
        [ 5.5625],
        [ 9.1550],
        [ 8.9997],
        [ 9.9758],
        [ 6.5418],
        [ 5.1797],
        [ 7.9212],
        [ 7.6892],
        [ 5.0234],
        [ 7.7082],
        [ 9.9983],
        [ 9.8194],
        [ 9.0191],
        [ 5.3813],
        [ 6.3116],
        [ 6.0101],
        [ 5.2021],
        [ 8.4987],
        [ 9.5109],
        [ 9.9832],
        [ 7.3513],
        [ 5.0169],
        [ 7.0857],
        [ 8.2664],
        [ 5.0635],
        [ 7.1214],
        [ 9.8084],
        [ 9.2911],
        [ 9.4038],
        [ 6.0231],
        [ 5.8810],
        [ 5.6767],
        [ 6.2124],
        [ 9.5709],
        [ 9.1413],
        [ 9.6818],
        [ 6.9060],
        [ 5.1377],
        [ 8.4669],
        [ 6.8784],
        [ 5.0000],
        [ 7.5728],
        [ 9.9325],
        [ 9.6254],
        [ 8.2417],
        [ 5.1215],
        [ 6.2474],
        [ 6.5664],
        [ 5.2693],
        [ 8.7912],
        [ 9.8885],
        [ 9.9926],
        [ 7.9266],
        [ 5.0743],
        [ 7.4751],
        [ 8.1288],
        [ 5.2918],
        [ 6.3406],
        [ 9.9185],
        [ 8.8311],
        [ 9.3501],
        [ 5.7157],
        [ 5.3198],
        [ 5.3288],
        [ 5.7409],
        [ 9.3206],
        [ 8.8091],
        [ 9.9259],
        [ 6.3058],
        [ 5.2771],
        [ 8.1500],
        [ 7.4551],
        [ 5.0663],
        [ 7.9673],
        [ 9.9946],
        [ 9.8955],
        [ 8.8298],
        [ 5.2526],
        [ 6.5514],
        [ 6.2047],
        [ 5.1200],
        [ 8.2540],
        [ 9.6550],
        [ 9.9459],
        [ 7.5818],
        [ 5.0001],
        [ 6.8266],
        [ 8.5143],
        [ 5.1367],
        [ 6.8954],
        [ 9.7102],
        [ 9.0990],
        [ 9.5626],
        [ 6.2184],
        [ 5.7097],
        [ 5.8654],
        [ 5.9957],
        [ 9.4307],
        [ 9.3107],
        [ 9.7989],
        [ 7.1666],
        [ 5.0724],
        [ 8.2505],
        [ 7.1040],
        [ 5.0130],
        [ 7.3076],
        [ 9.9800],
        [ 9.4927],
        [ 8.4620],
        [ 5.2149],
        [ 6.0282],
        [ 6.3568],
        [ 5.3827],
        [ 9.0108],
        [ 9.7968],
        [ 9.9998],
        [ 7.6939],
        [ 5.0243],
        [ 7.7363],
        [ 7.8726],
        [ 5.1814],
        [ 6.5532],
        [ 9.9672],
        [ 9.0479],
        [ 9.1614],
        [ 5.5620],
        [ 5.4418],
        [ 5.4870],
        [ 5.5921],
        [ 9.1268],
        [ 8.9867],
        [ 9.9592],
        [ 6.6258],
        [ 5.2114],
        [ 7.8270],
        [ 7.5347],
        [ 5.0063],
        [ 7.8629],
        [ 9.9884],
        [ 9.7239],
        [ 8.8451],
        [ 5.4963],
        [ 6.5105],
        [ 5.9905],
        [ 5.1845],
        [ 8.5326],
        [ 9.5202],
        [ 9.9689],
        [ 7.2607],
        [ 5.0087],
        [ 7.1802],
        [ 8.4118],
        [ 5.0321],
        [ 6.9687],
        [ 9.8604],
        [ 9.4439],
        [ 9.5347],
        [ 5.8634],
        [ 5.7187],
        [ 5.5753],
        [ 6.0756],
        [ 9.6543],
        [ 9.2490],
        [ 9.7845],
        [ 6.7024],
        [ 5.0786],
        [ 8.6681],
        [ 6.9012],
        [ 5.0000],
        [ 7.5348],
        [ 9.9286],
        [ 9.6780],
        [ 8.3270],
        [ 5.0972],
        [ 6.1646],
        [ 6.7108],
        [ 5.3478],
        [ 8.6546],
        [ 9.8410],
        [ 9.9999],
        [ 8.1330],
        [ 5.0329],
        [ 7.2534],
        [ 8.1055],
        [ 5.3134],
        [ 6.3750],
        [ 9.9141],
        [ 8.7429],
        [ 9.2887],
        [ 5.7745],
        [ 5.3685],
        [ 5.3754],
        [ 5.8154],
        [ 9.2541],
        [ 8.7372],
        [ 9.8797],
        [ 6.4388],
        [ 5.3452],
        [ 7.9938],
        [ 7.3676],
        [ 5.0441],
        [ 8.0642],
        [ 9.9986],
        [ 9.8433],
        [ 8.6980],
        [ 5.3199],
        [ 6.6982],
        [ 6.1278],
        [ 5.0906],
        [ 8.3437],
        [ 9.6959],
        [ 9.9055],
        [ 7.4324],
        [ 5.0026],
        [ 6.9831],
        [ 8.5931],
        [ 5.1041],
        [ 6.8002],
        [ 9.7461],
        [ 9.2223],
        [ 9.6453],
        [ 6.0957],
        [ 5.6036],
        [ 5.8006],
        [ 5.9121],
        [ 9.4918],
        [ 9.3644],
        [ 9.8587],
        [ 7.0155],
        [ 5.0417],
        [ 8.3989],
        [ 7.1939],
        [ 5.0046],
        [ 7.2133],
        [ 9.9681],
        [ 9.5901],
        [ 8.5982],
        [ 5.1612],
        [ 5.9012],
        [ 6.4352],
        [ 5.4414],
        [ 8.9307],
        [ 9.7641],
        [ 9.9917],
        [ 7.8459],
        [ 5.0083],
        [ 7.5800],
        [ 7.7821],
        [ 5.2219],
        [ 6.6419],
        [ 9.9523],
        [ 8.9123],
        [ 9.0473],
        [ 5.6543],
        [ 5.5371],
        [ 5.4364],
        [ 5.5248],
        [ 9.2007],
        [ 9.0499],
        [ 9.9835],
        [ 6.4844],
        [ 5.1568],
        [ 7.9817],
        [ 7.6259],
        [ 5.0157],
        [ 7.7685],
        [ 9.9951],
        [ 9.7957],
        [ 8.9682],
        [ 5.4151],
        [ 6.3653],
        [ 6.0607],
        [ 5.2266],
        [ 8.4421],
        [ 9.4725],
        [ 9.9895],
        [ 7.4137],
        [ 5.0251],
        [ 7.0251],
        [ 8.3265],
/home/abdelmajid/workdir/cost-aware-bo/optimizer/optimize_acqf_funcs.py:518: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):
[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]
Trying again with a new set of initial conditions.
  warnings.warn(first_warn_msg, RuntimeWarning)
/home/abdelmajid/workdir/cost-aware-bo/optimizer/optimize_acqf_funcs.py:545: RuntimeWarning: Optimization failed on the second try, after generating a new set of initial conditions.
  warnings.warn(
        [ 5.8076],
        [ 6.3167],
        [ 7.5971],
        [ 5.3063],
        [ 9.5532],
        [ 7.0260],
        [ 8.0841],
        [ 5.5380],
        [ 7.7599],
        [ 7.1191],
        [ 8.5108],
        [ 5.2946],
        [ 8.1321],
        [ 6.1775],
        [ 8.1754],
        [ 5.6138],
        [10.0000],
        [ 6.6691],
        [ 8.3574],
        [ 5.2379],
        [ 8.0637],
        [ 6.5062],
        [ 6.6017],
        [ 6.3835],
        [ 8.8487],
        [ 6.2704],
        [ 6.8617],
        [ 6.4778],
        [ 9.2632],
        [ 6.8502],
        [ 8.7788],
        [ 5.2572],
        [ 8.7883],
        [ 8.7459],
        [ 6.6702],
        [ 8.5861],
        [ 5.1206],
        [ 6.8678],
        [ 5.7340],
        [ 9.4188],
        [ 6.0519],
        [ 7.2369],
        [ 6.3314],
        [ 9.4864],
        [ 6.4320],
        [ 8.6798],
        [ 6.8849],
        [ 8.4726],
        [ 5.1865],
        [ 9.2439],
        [ 6.3439],
        [ 7.2410],
        [ 6.4718],
        [ 9.0180],
        [ 5.1899],
        [ 8.6712],
        [ 6.6598],
        [ 8.4389],
        [ 5.6759],
        [ 8.4769],
        [ 6.8455],
        [ 8.6004],
        [ 6.2819],
        [ 6.5218],
        [ 6.4792],
        [ 6.3296],
        [ 8.9308],
        [ 6.1836],
        [ 7.0057],
        [ 5.3632],
        [ 8.8201],
        [ 6.9652],
        [ 8.7509],
        [ 5.1699],
        [ 8.6647],
        [ 6.2328],
        [ 8.5677],
        [ 5.7966],
        [ 9.2065],
        [ 6.0986],
        [ 6.9227],
        [ 5.4910],
        [ 7.6993],
        [ 7.6653],
        [ 8.4205],
        [ 6.0727],
        [ 9.6665],
        [ 6.5150],
        [ 7.4134],
        [ 5.5731],
        [ 9.6097],
        [ 5.9556],
        [ 7.3163],
        [ 5.3445],
        [ 7.8182],
        [ 7.0887],
        [ 8.3223],
        [ 8.2614],
        [ 5.3739],
        [ 8.7682],
        [ 7.2055],
        [ 9.8893],
        [ 5.3855],
        [ 7.8424],
        [ 5.8464],
        [ 9.6124],
        [ 5.5710],
        [ 7.3378],
        [ 6.3307],
        [ 7.4497],
        [ 5.2626],
        [ 8.1507],
        [ 7.1157],
        [ 6.2665],
        [ 8.7994],
        [ 5.2480],
        [ 8.7289],
        [ 6.3319],
        [ 7.3744],
        [ 6.1579],
        [ 9.6619],
        [ 6.2742],
        [ 6.7713],
        [ 5.7519],
        [ 8.9109],
        [ 6.5447],
        [ 8.5525],
        [ 5.4129],
        [ 8.4349],
        [ 8.6644],
        [ 6.8755],
        [ 8.8140],
        [ 5.4386],
        [ 6.9256],
        [ 6.6691],
        [ 8.9597],
        [ 6.4695],
        [ 6.6359],
        [ 6.4756],
        [ 9.2396],
        [ 6.2025],
        [ 8.6822],
        [ 6.1336],
        [ 8.3789],
        [ 5.3389],
        [ 7.9188],
        [ 6.1147],
        [ 9.8519],
        [ 5.9317],
        [ 8.2250],
        [ 7.3612],
        [ 7.6965],
        [ 5.2457],
        [ 8.2348],
        [ 7.1118],
        [ 7.8008],
        [ 5.1247],
        [ 7.4091],
        [ 5.9655],
        [ 9.8071],
        [ 5.4103],
        [ 6.2051],
        [ 7.6136],
        [ 5.9144],
        [ 9.6962],
        [ 7.5129],
        [ 8.5688],
        [ 5.3029],
        [ 8.1450],
        [ 7.2191],
        [ 7.8917],
        [ 5.2930],
        [ 7.5176],
        [ 6.5242],
        [ 7.3977],
        [ 6.0399],
        [ 9.3670]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION: [tensor([[179.9487],
        [141.2899],
        [154.6131],
        [177.8911],
        [156.6855],
        [160.1475],
        [177.3183],
        [150.7251],
        [165.5191],
        [156.4929]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.3548],
        [75.6281],
        [56.9672],
        [64.6914],
        [51.6436],
        [35.1477],
        [35.7521],
        [50.0690],
        [89.1195],
        [35.4799]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[111.3654],
        [124.6529],
        [114.9070],
        [111.0851],
        [ 90.1083],
        [113.0232],
        [138.7287],
        [110.9771],
        [126.8434],
        [160.7784]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0000],
        [ 6.7232],
        [ 9.7339],
        [ 6.9912],
        [ 7.4390],
        [ 9.6598],
        [ 6.2203],
        [ 8.1337],
        [ 6.9663]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.4088],
        [ 8.7501],
        [ 7.0214],
        [ 7.7370],
        [ 6.5282],
        [ 5.0000],
        [ 5.0560],
        [ 6.3823],
        [10.0000],
        [ 5.0308]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.5040],
        [ 7.4441],
        [ 6.7545],
        [ 6.4841],
        [ 5.0000],
        [ 6.6213],
        [ 8.4400],
        [ 6.4765],
        [ 7.5991],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[179.9230],
        [141.2665],
        [154.3017],
        [177.8106],
        [156.4041],
        [159.7459],
        [177.2569],
        [150.3757],
        [165.4386],
        [156.0007]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.3782],
        [75.3370],
        [56.8758],
        [64.7000],
        [51.4649],
        [35.1632],
        [35.7391],
        [50.0986],
        [89.1644],
        [35.4595]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[111.1477],
        [124.6005],
        [114.9237],
        [111.0719],
        [ 90.0741],
        [112.8728],
        [138.7122],
        [110.7689],
        [126.9081],
        [160.6827]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0000],
        [ 6.6860],
        [ 9.7268],
        [ 6.9580],
        [ 7.3902],
        [ 9.6552],
        [ 6.1782],
        [ 8.1265],
        [ 6.9058]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.4088],
        [ 8.7197],
        [ 7.0104],
        [ 7.7348],
        [ 6.5094],
        [ 5.0000],
        [ 5.0533],
        [ 6.3829],
        [10.0000],
        [ 5.0274]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.4923],
        [ 7.4449],
        [ 6.7597],
        [ 6.4869],
        [ 5.0000],
        [ 6.6144],
        [ 8.4442],
        [ 6.4655],
        [ 7.6083],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[163.9505],
        [140.1131],
        [142.2411],
        [167.4135],
        [142.2411],
        [142.2411],
        [170.3730],
        [141.8863],
        [158.1759],
        [142.8827]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[54.2863],
        [51.9330],
        [49.4746],
        [65.2571],
        [39.1615],
        [38.7344],
        [35.0717],
        [56.5652],
        [89.1720],
        [35.4331]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 98.7750],
        [120.4079],
        [114.9736],
        [111.0540],
        [ 89.0135],
        [110.8868],
        [138.1518],
        [ 98.9408],
        [131.5634],
        [151.8145]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 8.9388],
        [ 5.0000],
        [ 5.3516],
        [ 9.5110],
        [ 5.3516],
        [ 5.3516],
        [10.0000],
        [ 5.2930],
        [ 7.9846],
        [ 5.4576]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7758],
        [ 6.5583],
        [ 6.3311],
        [ 7.7898],
        [ 5.3780],
        [ 5.3385],
        [ 5.0000],
        [ 6.9864],
        [10.0000],
        [ 5.0334]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.7772],
        [ 7.4995],
        [ 7.0668],
        [ 6.7548],
        [ 5.0000],
        [ 6.7415],
        [ 8.9122],
        [ 5.7904],
        [ 8.3877],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[148.0811],
        [140.5902],
        [142.2411],
        [158.2569],
        [142.2411],
        [142.2411],
        [163.6915],
        [144.3851],
        [154.7348],
        [141.7145]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[55.7370],
        [48.9532],
        [45.3178],
        [64.8262],
        [36.9153],
        [39.5572],
        [35.0001],
        [55.7885],
        [86.6020],
        [35.7347]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.5815],
        [117.4396],
        [114.7032],
        [111.6119],
        [ 89.1471],
        [110.3272],
        [137.8116],
        [100.6904],
        [133.5913],
        [146.7505]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.6213],
        [ 5.0000],
        [ 5.3573],
        [ 8.8238],
        [ 5.3573],
        [ 5.3573],
        [10.0000],
        [ 5.8214],
        [ 8.0614],
        [ 5.2433]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.0093],
        [ 6.3520],
        [ 5.9997],
        [ 7.8900],
        [ 5.1856],
        [ 5.4416],
        [ 5.0000],
        [ 7.0143],
        [10.0000],
        [ 5.0712]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6453],
        [ 7.4558],
        [ 7.2183],
        [ 6.9500],
        [ 5.0000],
        [ 6.8384],
        [ 9.2241],
        [ 6.0020],
        [ 8.8578],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [142.4919],
        [142.2411],
        [142.6248],
        [142.2411],
        [142.2411],
        [148.9834],
        [151.8691],
        [147.8040],
        [140.6289]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.5636],
        [56.5035],
        [38.8173],
        [63.5890],
        [36.5343],
        [41.1954],
        [35.2087],
        [53.0320],
        [78.0425],
        [36.6803]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8582],
        [106.9933],
        [113.9843],
        [111.2263],
        [ 89.9567],
        [108.8668],
        [136.9794],
        [102.0893],
        [136.8903],
        [136.5678]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.0026],
        [ 5.8287],
        [ 5.7172],
        [ 5.8878],
        [ 5.7172],
        [ 5.7172],
        [ 8.7164],
        [10.0000],
        [ 8.1917],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.4928],
        [ 7.4857],
        [ 5.4212],
        [ 8.3128],
        [ 5.1547],
        [ 5.6988],
        [ 5.0000],
        [ 7.0805],
        [10.0000],
        [ 5.1718]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6275],
        [ 6.8115],
        [ 7.5549],
        [ 7.2616],
        [ 5.0000],
        [ 7.0107],
        [10.0000],
        [ 6.2901],
        [ 9.9905],
        [ 9.9562]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.0345],
        [142.2411],
        [142.2411],
        [142.2411],
        [142.2411],
        [142.2674],
        [144.5833],
        [143.8476],
        [140.0147]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[55.7826],
        [56.5438],
        [36.9647],
        [62.1009],
        [36.9588],
        [41.0362],
        [35.3436],
        [50.5279],
        [74.1795],
        [36.8787]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8632],
        [103.0838],
        [113.4354],
        [110.7856],
        [ 90.3743],
        [107.8703],
        [136.2528],
        [ 99.7826],
        [136.9355],
        [132.1503]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 8.1388],
        [ 5.0216],
        [ 7.4366],
        [ 7.4366],
        [ 7.4366],
        [ 7.4366],
        [ 7.4654],
        [10.0000],
        [ 9.1949],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.6315],
        [ 7.7295],
        [ 5.2087],
        [ 8.4449],
        [ 5.2080],
        [ 5.7329],
        [ 5.0000],
        [ 6.9549],
        [10.0000],
        [ 5.1976]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5894],
        [ 6.3648],
        [ 7.4764],
        [ 7.1919],
        [ 5.0000],
        [ 6.8788],
        [ 9.9267],
        [ 6.0103],
        [10.0000],
        [ 9.4861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [141.7308],
        [142.2411],
        [142.5490],
        [142.2411],
        [142.2411],
        [147.4169],
        [150.2868],
        [146.9588],
        [140.4419]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.4111],
        [56.5147],
        [38.4033],
        [63.3079],
        [36.6019],
        [41.1648],
        [35.2320],
        [52.4013],
        [77.3230],
        [36.7143]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8453],
        [106.1486],
        [113.8811],
        [111.1430],
        [ 90.0314],
        [108.6806],
        [136.8412],
        [101.6089],
        [136.8990],
        [135.7051]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.2396],
        [ 5.6546],
        [ 5.9138],
        [ 6.0702],
        [ 5.9138],
        [ 5.9138],
        [ 8.5425],
        [10.0000],
        [ 8.3098],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5159],
        [ 7.5282],
        [ 5.3767],
        [ 8.3351],
        [ 5.1627],
        [ 5.7048],
        [ 5.0000],
        [ 7.0395],
        [10.0000],
        [ 5.1761]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6202],
        [ 6.7194],
        [ 7.5444],
        [ 7.2523],
        [ 5.0000],
        [ 6.9896],
        [ 9.9938],
        [ 6.2351],
        [10.0000],
        [ 9.8726]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[146.3774],
        [142.8824],
        [142.2411],
        [142.2411],
        [142.2410],
        [142.2410],
        [142.2411],
        [142.8824],
        [142.2408],
        [179.2672]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[39.9533],
        [50.0603],
        [56.4129],
        [43.4892],
        [41.6219],
        [37.0211],
        [37.9477],
        [89.5061],
        [50.5842],
        [41.1457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 94.2175],
        [ 94.9090],
        [108.9417],
        [108.3235],
        [ 96.1504],
        [ 95.4662],
        [126.8467],
        [ 96.7545],
        [133.8845],
        [116.6637]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5586],
        [ 5.0866],
        [ 5.0000],
        [ 5.0000],
        [ 5.0000],
        [ 5.0000],
        [ 5.0000],
        [ 5.0866],
        [ 5.0000],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.2793],
        [ 6.2422],
        [ 6.8474],
        [ 5.6162],
        [ 5.4383],
        [ 5.0000],
        [ 5.0883],
        [10.0000],
        [ 6.2921],
        [ 5.3929]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0872],
        [ 6.8560],
        [ 6.7780],
        [ 5.2436],
        [ 5.1574],
        [ 9.1129],
        [ 5.3198],
        [10.0000],
        [ 7.8293]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[140.1548],
        [139.9999],
        [142.2411],
        [142.3457],
        [142.2411],
        [142.2411],
        [143.7436],
        [141.9135],
        [144.2422],
        [145.9914]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7148],
        [52.9818],
        [37.3210],
        [56.7167],
        [37.7143],
        [39.6381],
        [35.8120],
        [55.7988],
        [63.0703],
        [37.2595]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 94.7110],
        [ 98.0905],
        [112.2174],
        [110.0207],
        [ 91.3755],
        [104.3962],
        [133.7267],
        [ 96.9163],
        [135.9825],
        [122.3787]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.1293],
        [ 5.0000],
        [ 6.8703],
        [ 6.9576],
        [ 6.8703],
        [ 6.8703],
        [ 8.1242],
        [ 6.5970],
        [ 8.5403],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 8.1005],
        [ 8.1495],
        [ 5.2768],
        [ 8.8345],
        [ 5.3489],
        [ 5.7018],
        [ 5.0000],
        [ 8.6662],
        [10.0000],
        [ 5.2655]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3739],
        [ 5.7527],
        [ 7.3362],
        [ 7.0899],
        [ 5.0000],
        [ 6.4595],
        [ 9.7471],
        [ 5.6211],
        [10.0000],
        [ 8.4751]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[141.8268],
        [140.3029],
        [142.2411],
        [142.3800],
        [142.2411],
        [142.2411],
        [144.3037],
        [145.4995],
        [145.0097],
        [140.1512]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[55.0865],
        [55.4626],
        [36.8417],
        [61.1444],
        [36.9627],
        [40.6900],
        [35.4007],
        [50.0291],
        [72.3669],
        [36.8643]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.4595],
        [102.1066],
        [113.2800],
        [110.7055],
        [ 90.4696],
        [107.2892],
        [135.8054],
        [ 99.4194],
        [136.6653],
        [130.4736]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.5665],
        [ 5.1418],
        [ 6.9538],
        [ 7.0837],
        [ 6.9538],
        [ 6.9538],
        [ 8.8821],
        [10.0000],
        [ 9.5421],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.6627],
        [ 7.7135],
        [ 5.1949],
        [ 8.4821],
        [ 5.2113],
        [ 5.7154],
        [ 5.0000],
        [ 6.9786],
        [10.0000],
        [ 5.1980]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5401],
        [ 6.2595],
        [ 7.4689],
        [ 7.1902],
        [ 5.0000],
        [ 6.8205],
        [ 9.9069],
        [ 5.9687],
        [10.0000],
        [ 9.3298]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.6363],
        [140.5042],
        [142.2411],
        [142.3900],
        [142.2411],
        [142.2411],
        [144.4720],
        [146.8283],
        [145.2418],
        [140.0506]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[55.8708],
        [56.2953],
        [37.4235],
        [62.3757],
        [36.8044],
        [41.0110],
        [35.3083],
        [50.8715],
        [75.0487],
        [36.8047]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.7527],
        [103.9427],
        [113.5789],
        [110.9092],
        [ 90.2534],
        [108.0712],
        [136.3892],
        [100.3744],
        [136.8629],
        [133.1541]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9075],
        [ 5.3346],
        [ 6.6159],
        [ 6.7258],
        [ 6.6159],
        [ 6.6159],
        [ 8.2617],
        [10.0000],
        [ 8.8296],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5871],
        [ 7.6405],
        [ 5.2661],
        [ 8.4055],
        [ 5.1882],
        [ 5.7175],
        [ 5.0000],
        [ 6.9581],
        [10.0000],
        [ 5.1883]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5899],
        [ 6.4685],
        [ 7.5022],
        [ 7.2158],
        [ 5.0000],
        [ 6.9114],
        [ 9.9492],
        [ 6.0857],
        [10.0000],
        [ 9.6021]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8385],
        [140.5567],
        [142.2411],
        [142.3922],
        [142.2411],
        [142.2411],
        [144.5105],
        [147.1448],
        [145.2949],
        [140.1323]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0543],
        [56.4902],
        [37.5839],
        [62.6500],
        [36.7726],
        [41.0846],
        [35.2891],
        [51.2193],
        [75.6440],
        [36.7941]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8241],
        [104.4087],
        [113.6459],
        [110.9555],
        [ 90.2070],
        [108.2437],
        [136.5201],
        [100.6049],
        [136.9077],
        [133.7752]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9295],
        [ 5.3026],
        [ 6.5036],
        [ 6.6114],
        [ 6.5036],
        [ 6.5036],
        [ 8.1217],
        [10.0000],
        [ 8.6810],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5728],
        [ 7.6268],
        [ 5.2843],
        [ 8.3900],
        [ 5.1838],
        [ 5.7181],
        [ 5.0000],
        [ 6.9738],
        [10.0000],
        [ 5.1865]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6014],
        [ 6.5205],
        [ 7.5095],
        [ 7.2214],
        [ 5.0000],
        [ 6.9311],
        [ 9.9585],
        [ 6.1132],
        [10.0000],
        [ 9.6646]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8751],
        [140.5663],
        [142.2411],
        [142.3926],
        [142.2411],
        [142.2411],
        [144.5173],
        [147.2016],
        [145.3044],
        [140.1508]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0871],
        [56.5251],
        [37.6134],
        [62.6985],
        [36.7671],
        [41.0977],
        [35.2858],
        [51.2870],
        [75.7492],
        [36.7923]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8370],
        [104.4935],
        [113.6578],
        [110.9637],
        [ 90.1989],
        [108.2742],
        [136.5433],
        [100.6464],
        [136.9156],
        [133.8861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9319],
        [ 5.2946],
        [ 6.4823],
        [ 6.5898],
        [ 6.4823],
        [ 6.4823],
        [ 8.0965],
        [10.0000],
        [ 8.6546],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5704],
        [ 7.6245],
        [ 5.2876],
        [ 8.3873],
        [ 5.1831],
        [ 5.7182],
        [ 5.0000],
        [ 6.9772],
        [10.0000],
        [ 5.1862]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6034],
        [ 6.5299],
        [ 7.5108],
        [ 7.2224],
        [ 5.0000],
        [ 6.9346],
        [ 9.9602],
        [ 6.1182],
        [10.0000],
        [ 9.6758]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8814],
        [140.5679],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5185],
        [147.2113],
        [145.3060],
        [140.1541]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0927],
        [56.5310],
        [37.6185],
        [62.7068],
        [36.7662],
        [41.0999],
        [35.2852],
        [51.2987],
        [75.7671],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8392],
        [104.5080],
        [113.6598],
        [110.9651],
        [ 90.1975],
        [108.2794],
        [136.5473],
        [100.6535],
        [136.9170],
        [133.9050]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2932],
        [ 6.4786],
        [ 6.5861],
        [ 6.4786],
        [ 6.4786],
        [ 8.0922],
        [10.0000],
        [ 8.6501],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5700],
        [ 7.6241],
        [ 5.2882],
        [ 8.3869],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9779],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6038],
        [ 6.5315],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9352],
        [ 9.9604],
        [ 6.1190],
        [10.0000],
        [ 9.6777]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8824],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2130],
        [145.3063],
        [140.1546]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0937],
        [56.5320],
        [37.6193],
        [62.7082],
        [36.7661],
        [41.1003],
        [35.2851],
        [51.3007],
        [75.7701],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5104],
        [113.6601],
        [110.9653],
        [ 90.1972],
        [108.2803],
        [136.5479],
        [100.6547],
        [136.9172],
        [133.9082]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2930],
        [ 6.4780],
        [ 6.5854],
        [ 6.4780],
        [ 6.4780],
        [ 8.0914],
        [10.0000],
        [ 8.6493],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6038],
        [ 6.5318],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8826],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2132],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0938],
        [56.5322],
        [37.6195],
        [62.7084],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3010],
        [75.7707],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5108],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5480],
        [100.6549],
        [136.9172],
        [133.9087]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7707],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.4491],
        [140.4371],
        [142.2411],
        [142.2411],
        [142.2411],
        [142.2411],
        [144.0861],
        [145.7249],
        [145.0139],
        [140.1270]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0073],
        [56.3262],
        [37.5706],
        [62.5959],
        [36.7483],
        [41.0293],
        [35.2830],
        [51.2734],
        [75.6892],
        [36.7677]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.7941],
        [104.4048],
        [113.6382],
        [110.9556],
        [ 90.1999],
        [108.2310],
        [136.4959],
        [100.5979],
        [136.8373],
        [133.7767]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 7.0740],
        [ 5.2769],
        [ 6.8883],
        [ 6.8883],
        [ 6.8883],
        [ 6.8883],
        [ 8.5362],
        [10.0000],
        [ 9.3649],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5645],
        [ 7.6040],
        [ 5.2831],
        [ 8.3798],
        [ 5.1813],
        [ 5.7111],
        [ 5.0000],
        [ 6.9787],
        [10.0000],
        [ 5.1837]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5998],
        [ 6.5229],
        [ 7.5128],
        [ 7.2252],
        [ 5.0000],
        [ 6.9331],
        [ 9.9634],
        [ 6.1148],
        [10.0000],
        [ 9.6719]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8344],
        [140.5533],
        [142.2411],
        [142.3762],
        [142.2411],
        [142.2411],
        [144.4713],
        [147.0466],
        [145.2745],
        [140.1516]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0845],
        [56.5099],
        [37.6142],
        [62.6964],
        [36.7641],
        [41.0927],
        [35.2849],
        [51.2981],
        [75.7620],
        [36.7893]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8347],
        [104.4995],
        [113.6578],
        [110.9643],
        [ 90.1975],
        [108.2751],
        [136.5425],
        [100.6488],
        [136.9086],
        [133.8946]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9455],
        [ 5.2913],
        [ 6.5152],
        [ 6.6132],
        [ 6.5152],
        [ 6.5152],
        [ 8.1325],
        [10.0000],
        [ 8.7150],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5693],
        [ 7.6219],
        [ 5.2877],
        [ 8.3861],
        [ 5.1827],
        [ 5.7174],
        [ 5.0000],
        [ 6.9781],
        [10.0000],
        [ 5.1858]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6034],
        [ 6.5309],
        [ 7.5112],
        [ 7.2229],
        [ 5.0000],
        [ 6.9350],
        [ 9.9608],
        [ 6.1187],
        [10.0000],
        [ 9.6774]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8769],
        [140.5665],
        [142.2411],
        [142.3908],
        [142.2411],
        [142.2411],
        [144.5131],
        [147.1934],
        [145.3026],
        [140.1544]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0928],
        [56.5296],
        [37.6189],
        [62.7070],
        [36.7658],
        [41.0995],
        [35.2851],
        [51.3007],
        [75.7697],
        [36.7916]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8391],
        [104.5096],
        [113.6599],
        [110.9652],
        [ 90.1972],
        [108.2798],
        [136.5474],
        [100.6542],
        [136.9162],
        [133.9072]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9339],
        [ 5.2927],
        [ 6.4822],
        [ 6.5886],
        [ 6.4822],
        [ 6.4822],
        [ 8.0961],
        [10.0000],
        [ 8.6569],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5698],
        [ 7.6238],
        [ 5.2882],
        [ 8.3867],
        [ 5.1829],
        [ 5.7181],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6038],
        [ 6.5317],
        [ 7.5110],
        [ 7.2227],
        [ 5.0000],
        [ 6.9352],
        [ 9.9605],
        [ 6.1191],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8820],
        [140.5680],
        [142.2411],
        [142.3925],
        [142.2411],
        [142.2411],
        [144.5181],
        [147.2109],
        [145.3059],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0937],
        [56.5319],
        [37.6194],
        [62.7083],
        [36.7660],
        [41.1003],
        [35.2851],
        [51.3010],
        [75.7706],
        [36.7919]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5108],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5480],
        [100.6548],
        [136.9171],
        [133.9086]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9325],
        [ 5.2929],
        [ 6.4784],
        [ 6.5857],
        [ 6.4784],
        [ 6.4784],
        [ 8.0919],
        [10.0000],
        [ 8.6501],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5318],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8826],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2130],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7707],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9324],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6493],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8826],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9324],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8827],
        [140.5682],
        [142.2411],
        [142.3927],
        [142.2411],
        [142.2411],
        [144.5187],
        [147.2133],
        [145.3063],
        [140.1547]], device='cuda:0', dtype=torch.float64), tensor([[56.0939],
        [56.5322],
        [37.6195],
        [62.7085],
        [36.7660],
        [41.1004],
        [35.2851],
        [51.3011],
        [75.7708],
        [36.7920]], device='cuda:0', dtype=torch.float64), tensor([[ 95.8396],
        [104.5109],
        [113.6602],
        [110.9654],
        [ 90.1972],
        [108.2804],
        [136.5481],
        [100.6549],
        [136.9172],
        [133.9088]], device='cuda:0', dtype=torch.float64)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.9323],
        [ 5.2929],
        [ 6.4779],
        [ 6.5853],
        [ 6.4779],
        [ 6.4779],
        [ 8.0913],
        [10.0000],
        [ 8.6492],
        [ 5.0000]], device='cuda:0', dtype=torch.float64), tensor([[ 7.5699],
        [ 7.6240],
        [ 5.2883],
        [ 8.3868],
        [ 5.1829],
        [ 5.7182],
        [ 5.0000],
        [ 6.9780],
        [10.0000],
        [ 5.1861]], device='cuda:0', dtype=torch.float64), tensor([[ 5.6039],
        [ 6.5319],
        [ 7.5110],
        [ 7.2226],
        [ 5.0000],
        [ 6.9353],
        [ 9.9605],
        [ 6.1192],
        [10.0000],
        [ 9.6780]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION: [tensor([[142.3885],
        [145.5871],
        [174.8970],
        [170.9017],
        [179.5178],
        [150.0107],
        [141.9908],
        [165.6734],
        [159.1328],
        [140.4244],
        [164.2126],
        [179.9829],
        [179.0162],
        [170.2043],
        [142.2457],
        [152.8613],
        [150.0684],
        [141.1142],
        [165.5602],
        [176.9768],
        [179.6611],
        [161.1531],
        [140.0129],
        [154.1409],
        [168.5755],
        [140.9390],
        [154.6948],
        [177.9087],
        [173.1661],
        [176.7816],
        [149.3217],
        [145.3439],
        [146.5491],
        [147.5825],
        [175.7529],
        [174.8303],
        [178.5755],
        [156.8386],
        [140.4644],
        [166.4709],
        [156.3322],
        [140.1607],
        [158.9441],
        [179.8963],
        [175.6392],
        [167.2242],
        [141.9286],
        [148.6211],
        [151.3021],
        [143.3250],
        [171.6905],
        [178.1670],
        [179.9836],
        [162.0490],
        [140.1306],
        [161.3997],
        [163.4817],
        [141.2735],
        [151.9798],
        [179.8114],
        [172.7651],
        [173.6653],
        [144.1855],
        [143.2645],
        [144.1985],
        [145.0543],
        [172.6357],
        [171.4813],
        [179.5795],
        [153.4769],
        [141.9017],
        [162.1272],
        [160.7851],
        [140.0921],
        [162.4231],
        [179.9487],
        [178.0097],
        [171.1848],
        [143.6772],
        [151.6417],
        [147.5300],
        [141.2989],
        [168.7063],
        [176.4548],
        [179.6686],
        [157.5889],
        [140.0342],
        [157.9305],
        [166.8186],
        [140.3416],
        [156.2247],
        [178.7114],
        [175.2362],
        [175.9768],
        [147.2896],
        [146.0937],
        [144.9270],
        [149.0061],
        [176.9793],
        [173.6239],
        [178.0731],
        [154.0955],
        [140.7617],
        [168.9062],
        [155.7039],
        [140.0106],
        [159.7942],
        [179.3034],
        [177.6594],
        [167.0922],
        [140.6464],
        [148.9113],
        [153.2141],
        [142.5417],
        [169.6700],
        [178.8991],
        [179.9990],
        [164.5789],
        [140.3522],
        [158.5174],
        [164.3500],
        [142.7514],
        [151.4351],
        [179.1759],
        [169.5125],
        [173.9498],
        [146.5623],
        [143.2064],
        [142.7459],
        [146.1699],
        [174.3780],
        [170.3347],
        [179.1797],
        [151.0603],
        [142.5104],
        [164.4314],
        [158.4339],
        [140.2672],
        [164.9836],
        [179.9991],
        [178.5681],
        [169.1346],
        [142.8097],
        [154.0462],
        [149.4438],
        [140.8603],
        [166.2835],
        [177.3183],
        [179.3693],
        [159.9586],
        [140.0043],
        [155.3849],
        [169.1979],
        [140.6988],
        [153.9386],
        [178.1821],
        [174.1303],
        [177.4170],
        [148.3560],
        [144.5183],
        [146.0423],
        [146.9266],
        [176.2259],
        [175.2477],
        [179.0237],
        [155.6350],
        [140.2481],
        [167.6474],
        [157.0485],
        [140.0738],
        [158.1878],
        [179.8178],
        [176.4448],
        [168.3260],
        [141.4726],
        [147.5861],
        [151.9369],
        [143.8114],
        [171.0379],
        [177.8911],
        [179.8872],
        [163.2613],
        [140.0318],
        [160.1475],
        [162.7600],
        [141.5787],
        [152.6823],
        [179.7088],
        [171.7006],
        [172.7721],
        [144.9022],
        [144.0021],
        [143.7790],
        [144.5002],
        [173.2397],
        [171.9967],
        [179.8053],
        [152.3344],
        [141.4383],
        [163.3694],
        [161.5136],
        [140.1879],
        [161.6655],
        [179.9854],
        [178.5543],
        [172.1523],
        [143.0510],
        [150.4933],
        [148.0808],
        [141.6172],
        [167.9895],
        [176.0861],
        [179.8649],
        [158.8104],
        [140.1361],
        [156.6855],
        [166.1305],
        [140.5090],
        [156.9709],
        [178.4667],
        [174.3279],
        [175.2297],
        [148.1848],
        [147.0485],
        [145.4142],
        [149.6992],
        [176.5665],
        [173.1297],
        [177.4539],
        [155.2483],
        [141.1020],
        [167.7351],
        [155.0270],
        [140.0010],
        [160.5819],
        [179.4594],
        [177.0022],
        [165.9336],
        [140.9728],
        [149.9792],
        [152.5314],
        [142.1546],
        [170.3288],
        [179.1071],
        [179.9399],
        [163.4123],
        [140.5946],
        [159.8008],
        [165.0297],
        [142.3351],
        [150.7251],
        [179.3473],
        [170.6485],
        [174.7998],
        [145.7263],
        [142.5592],
        [142.6308],
        [145.9272],
        [174.5642],
        [170.4725],
        [179.4062],
        [150.4470],
        [142.2174],
        [165.1998],
        [159.6404],
        [140.5311],
        [163.7379],
        [179.9559],
        [179.1629],
        [170.6375],
        [142.0210],
        [152.4111],
        [149.6376],
        [140.9603],
        [166.0314],
        [177.2396],
        [179.5667],
        [160.6539],
        [140.0011],
        [154.6131],
        [168.1143],
        [141.0938],
        [155.1632],
        [177.6806],
        [172.7917],
        [176.5001],
        [149.7475],
        [145.6779],
        [146.9233],
        [147.9656],
        [175.4449],
        [174.4850],
        [178.3906],
        [157.3330],
        [140.5794],
        [166.0035],
        [156.8323],
        [140.1045],
        [158.4609],
        [179.8393],
        [175.9411],
        [167.6954],
        [141.7201],
        [148.2261],
        [150.8548],
        [143.0624],
        [172.0861],
        [178.3734],
        [179.9974],
        [161.5512],
        [140.1951],
        [161.8904],
        [162.9807],
        [141.4520],
        [152.4260],
        [179.7368],
        [172.3824],
        [173.2904],
        [144.4964],
        [143.5346],
        [143.8968],
        [144.7369],
        [173.0134],
        [171.8931],
        [179.6726],
        [153.0065],
        [141.6914],
        [162.6156],
        [160.2777],
        [140.0510],
        [162.9029],
        [179.9066],
        [177.7903],
        [170.7602],
        [143.9710],
        [152.0842],
        [147.9247],
        [141.4762],
        [168.2607],
        [176.1610],
        [179.7507],
        [158.0859],
        [140.0703],
        [157.4416],
        [167.2937],
        [140.2570],
        [155.7500],
        [178.8820],
        [175.5505],
        [176.2768],
        [146.9075],
        [145.7497],
        [144.6032],
        [148.6047],
        [177.2339],
        [173.9913],
        [178.2752],
        [153.6197],
        [140.6291],
        [169.3441],
        [155.2094],
        [140.0006],
        [160.2786],
        [179.4281],
        [177.4231],
        [166.6154],
        [140.7785],
        [149.3175],
        [153.6865],
        [142.7831],
        [169.2363],
        [178.7270],
        [179.9980],
        [165.0639],
        [140.2637],
        [158.0271],
        [164.8438],
        [142.5075],
        [151.0000],
        [179.3119],
        [169.9423],
        [174.3091],
        [146.1964],
        [142.9482],
        [143.0041],
        [146.5239],
        [174.0318],
        [169.8967],
        [179.0368],
        [151.5104],
        [142.7623],
        [163.9502],
        [158.9407],
        [140.3533],
        [164.5130],
        [179.9881],
        [178.7452],
        [169.5832],
        [142.5595],
        [153.5857],
        [149.0225],
        [140.7254],
        [166.7489],
        [177.5665],
        [179.2429],
        [159.4589],
        [140.0213],
        [155.8650],
        [168.7444],
        [140.8337],
        [154.4018],
        [177.9681],
        [173.7780],
        [177.1618],
        [148.7658],
        [144.8296],
        [146.4049],
        [147.2968],
        [175.9333],
        [174.9144],
        [178.8686],
        [156.1240],
        [140.3342],
        [167.1905],
        [157.5514],
        [140.0376],
        [157.7061],
        [179.7442],
        [176.7198],
        [168.7850],
        [141.2899],
        [147.2099],
        [151.4821],
        [143.5316],
        [171.4449],
        [178.1122],
        [179.9328],
        [162.7671],
        [140.0669],
        [160.6397],
        [162.2564],
        [141.7759],
        [153.1354],
        [179.6178],
        [171.2978],
        [172.3775],
        [145.2349],
        [144.2974],
        [143.4916],
        [144.1987],
        [173.6046],
        [172.3989],
        [179.8669],
        [151.8751],
        [141.2553],
        [163.8532],
        [161.0068],
        [140.1266],
        [162.1474],
        [179.9601],
        [178.3651],
        [171.7451],
        [143.3216],
        [150.9223],
        [148.4858],
        [141.8134],
        [167.5361],
        [175.7793],
        [179.9153],
        [159.3098],
        [140.2015],
        [156.2011],
        [166.6118],
        [140.4046],
        [156.4929],
        [178.6528],
        [174.6670],
        [175.5537],
        [147.7852],
        [146.6832],
        [145.0768],
        [149.2870],
        [176.8371],
        [173.5085],
        [177.6852],
        [154.7641],
        [140.9419],
        [168.1866],
        [154.5369],
        [140.0120],
        [161.0658],
        [179.5687],
        [176.7379],
        [165.4470],
        [141.1328],
        [150.4011],
        [152.9975],
        [142.3784],
        [169.9042],
        [178.9510],
        [179.9715],
        [163.9035],
        [140.4780],
        [159.3088],
        [165.5191],
        [142.1096],
        [150.2989],
        [179.4679],
        [171.0617],
        [175.1365],
        [145.3808],
        [142.3272]], device='cuda:0', dtype=torch.float64), tensor([[75.0703],
        [41.4119],
        [64.2435],
        [51.6881],
        [61.0223],
        [72.4932],
        [35.2420],
        [74.0302],
        [36.0483],
        [75.8277],
        [70.3055],
        [65.7143],
        [61.5228],
        [53.1337],
        [86.3652],
        [39.6187],
        [87.5631],
        [35.1431],
        [68.1909],
        [51.5884],
        [49.4679],
        [57.5461],
        [37.9250],
        [89.6168],
        [44.9967],
        [89.0338],
        [37.8727],
        [66.4291],
        [69.8908],
        [61.7676],
        [87.3461],
        [35.0081],
        [62.7331],
        [67.4877],
        [36.5570],
        [88.7283],
        [89.5605],
        [38.3740],
        [62.8284],
        [39.6119],
        [65.7181],
        [49.8731],
        [89.3853],
        [40.7054],
        [35.0429],
        [83.8818],
        [48.7136],
        [72.9867],
        [50.9960],
        [67.4900],
        [43.2462],
        [81.9585],
        [71.7223],
        [35.1135],
        [71.2610],
        [64.1276],
        [68.8389],
        [68.0444],
        [85.7808],
        [35.4364],
        [37.4554],
        [78.4790],
        [55.4370],
        [59.2046],
        [37.6739],
        [67.1101],
        [55.0538],
        [74.9960],
        [74.5571],
        [50.4239],
        [65.1239],
        [54.5078],
        [83.8262],
        [45.2385],
        [70.1317],
        [50.3548],
        [56.8404],
        [74.8412],
        [36.5610],
        [64.5917],
        [49.0484],
        [85.3220],
        [42.7768],
        [71.9072],
        [73.9636],
        [45.0424],
        [81.4255],
        [35.6111],
        [73.2214],
        [40.3622],
        [74.7804],
        [50.7755],
        [38.5482],
        [73.1290],
        [51.8904],
        [83.4547],
        [69.4951],
        [35.3384],
        [87.3302],
        [46.8926],
        [36.9202],
        [79.9593],
        [45.8800],
        [74.5475],
        [40.3251],
        [74.9842],
        [38.8324],
        [76.9365],
        [81.7957],
        [55.8512],
        [73.9707],
        [46.6882],
        [74.9622],
        [51.2223],
        [60.3975],
        [41.0986],
        [53.7129],
        [78.5064],
        [50.6233],
        [72.6630],
        [49.8954],
        [70.6030],
        [50.4146],
        [73.8638],
        [81.8224],
        [36.2471],
        [73.4333],
        [57.5338],
        [66.6395],
        [50.6986],
        [80.8598],
        [43.9614],
        [35.0523],
        [71.8345],
        [63.2318],
        [70.6182],
        [67.3488],
        [68.3419],
        [35.3422],
        [85.3246],
        [76.0693],
        [37.6835],
        [58.5415],
        [54.9849],
        [65.3247],
        [61.4505],
        [89.4242],
        [35.7521],
        [39.8506],
        [89.4867],
        [38.5884],
        [60.3704],
        [49.5026],
        [63.7596],
        [42.2131],
        [89.7879],
        [85.2608],
        [35.2816],
        [71.8991],
        [48.6633],
        [35.5427],
        [87.2069],
        [53.5136],
        [69.5819],
        [59.5803],
        [46.4181],
        [89.9261],
        [36.8534],
        [88.2094],
        [42.7889],
        [68.3536],
        [37.8625],
        [61.4788],
        [71.4224],
        [35.1088],
        [85.8876],
        [40.9948],
        [75.0774],
        [51.3910],
        [64.6914],
        [72.7333],
        [61.4493],
        [77.9682],
        [35.1477],
        [76.1143],
        [36.4437],
        [66.4569],
        [71.0575],
        [53.6170],
        [62.3582],
        [38.9415],
        [88.6160],
        [52.9417],
        [74.6977],
        [39.6435],
        [58.1567],
        [71.8248],
        [51.6828],
        [73.6044],
        [50.1864],
        [72.1115],
        [49.9782],
        [71.4530],
        [48.0589],
        [35.5390],
        [77.1302],
        [59.7216],
        [74.2926],
        [35.5899],
        [70.0382],
        [46.4524],
        [86.3368],
        [79.5107],
        [36.7191],
        [74.6789],
        [51.6436],
        [75.0155],
        [42.0761],
        [75.9787],
        [38.3371],
        [54.9857],
        [81.0600],
        [49.4619],
        [74.2827],
        [86.0063],
        [50.0991],
        [71.4075],
        [40.6436],
        [43.7063],
        [73.6301],
        [35.9073],
        [82.4765],
        [40.8493],
        [73.8924],
        [49.5568],
        [74.8481],
        [72.9074],
        [36.2611],
        [83.9984],
        [52.5839],
        [71.7846],
        [39.1569],
        [74.8932],
        [53.5281],
        [50.9966],
        [73.8942],
        [57.1937],
        [67.8157],
        [47.2789],
        [86.0516],
        [50.0690],
        [68.6946],
        [74.4740],
        [55.3177],
        [69.3404],
        [37.5571],
        [49.9560],
        [85.5052],
        [35.1952],
        [71.5420],
        [73.6731],
        [50.4486],
        [82.6152],
        [35.8356],
        [73.9794],
        [40.9537],
        [74.8722],
        [38.3809],
        [47.2670],
        [72.7863],
        [52.8283],
        [84.2399],
        [39.0744],
        [63.6632],
        [53.2007],
        [74.9171],
        [73.9417],
        [51.5966],
        [74.0659],
        [56.9672],
        [76.0468],
        [47.5197],
        [68.5151],
        [49.9520],
        [55.3124],
        [74.4399],
        [37.6189],
        [78.6395],
        [74.6717],
        [53.2148],
        [62.9990],
        [39.5224],
        [51.4730],
        [67.9001],
        [49.8723],
        [73.6934],
        [50.0117],
        [72.0345],
        [48.1917],
        [81.0151],
        [68.1776],
        [35.6012],
        [74.2265],
        [59.4714],
        [70.0794],
        [44.1654],
        [87.1945],
        [46.2316],
        [36.6599],
        [78.6137],
        [42.2899],
        [74.8190],
        [53.0470],
        [75.0002],
        [38.4742],
        [76.3551],
        [81.0189],
        [55.1324],
        [74.2679],
        [38.0057],
        [87.3551],
        [35.6008],
        [69.7182],
        [57.7014],
        [41.7567],
        [59.7534],
        [36.7920],
        [89.7379],
        [42.9844],
        [88.3439],
        [47.1207],
        [68.1654],
        [71.3442],
        [52.0243],
        [85.9334],
        [35.0941],
        [84.6954],
        [40.7829],
        [64.8198],
        [52.1746],
        [60.6092],
        [72.8458],
        [35.2460],
        [69.4640],
        [36.3672],
        [87.8100],
        [71.0711],
        [66.3354],
        [62.1296],
        [53.3297],
        [77.6403],
        [39.1065],
        [50.4663],
        [66.8385],
        [43.8024],
        [74.1558],
        [77.0967],
        [35.0015],
        [70.7093],
        [63.8331],
        [68.1585],
        [67.0398],
        [74.2439],
        [35.3078],
        [37.7505],
        [86.9511],
        [54.9498],
        [58.3963],
        [54.8683],
        [65.5246],
        [35.7928],
        [88.7417],
        [89.9667],
        [39.6915],
        [60.5334],
        [46.2734],
        [63.6372],
        [40.0066],
        [89.7202],
        [42.3265],
        [35.3243],
        [85.5209],
        [58.3050],
        [71.7510],
        [39.6276],
        [69.3595],
        [47.0262],
        [87.6393],
        [79.9454],
        [37.0270],
        [74.5200],
        [41.3547],
        [74.9857],
        [50.2411],
        [76.8304],
        [38.7455],
        [55.6073],
        [81.5473],
        [37.7796],
        [74.0519],
        [51.9123],
        [74.9757],
        [41.1777],
        [69.8670],
        [69.8212],
        [54.0034],
        [72.5928],
        [49.7122],
        [70.7562],
        [50.0549],
        [85.0251],
        [50.1550],
        [36.2164],
        [70.3620],
        [57.5184],
        [73.4896],
        [61.0437],
        [37.7886],
        [74.9985],
        [54.6240],
        [50.9055],
        [74.5044],
        [54.6941],
        [71.1045],
        [45.1196],
        [72.9530],
        [50.3099],
        [70.2267],
        [74.8707],
        [57.0812],
        [75.6281],
        [36.4592],
        [84.9002],
        [49.2845],
        [71.8567],
        [35.5869],
        [51.9559],
        [73.8506],
        [35.6475],
        [82.0742],
        [40.1967],
        [72.9002],
        [40.9606],
        [74.7542],
        [73.1783],
        [47.9099],
        [83.4640],
        [51.7436],
        [67.3502],
        [56.6507],
        [88.4430],
        [36.4631],
        [38.4557],
        [89.9415],
        [45.6103],
        [62.6523],
        [38.5172],
        [65.9311],
        [40.5355],
        [89.2714],
        [83.8528],
        [35.0337],
        [73.0424],
        [59.4342],
        [67.3740],
        [50.4265],
        [74.5935],
        [43.4252],
        [35.0133],
        [78.7323],
        [64.4750],
        [71.1177],
        [68.0809],
        [68.9439],
        [35.4799],
        [76.0943],
        [88.1575],
        [37.3268],
        [59.4452],
        [55.6908],
        [41.5676],
        [79.6979],
        [51.8008],
        [64.0260],
        [72.4208],
        [60.6423],
        [70.0172],
        [35.3025],
        [84.7287],
        [36.1231],
        [65.9219],
        [70.5954],
        [53.1788],
        [61.6610],
        [39.5304],
        [76.7273],
        [35.1261],
        [88.5015],
        [60.4070],
        [67.9449],
        [57.4029],
        [40.2976],
        [88.7088],
        [38.0546],
        [89.1195],
        [44.8686],
        [66.5327],
        [49.3942],
        [50.8442],
        [70.0747],
        [35.0027],
        [87.0391]], device='cuda:0', dtype=torch.float64), tensor([[109.6853],
        [163.1213],
        [110.1927],
        [125.3351],
        [ 95.1258],
        [154.9402],
        [120.2891],
        [155.9777],
        [ 97.0723],
        [139.6182],
        [120.4123],
        [148.6575],
        [113.1622],
        [159.6941],
        [114.6645],
        [114.7146],
        [163.8523],
        [111.5581],
        [121.8632],
        [115.1507],
        [149.8895],
        [ 93.8678],
        [153.4095],
        [117.5145],
        [150.6926],
        [ 92.5144],
        [155.4174],
        [111.9711],
        [160.2034],
        [103.6415],
        [118.7265],
        [102.9348],
        [139.3690],
        [100.7871],
        [143.6486],
        [135.9993],
        [159.3367],
        [105.9897],
        [134.2207],
        [112.7493],
        [165.6301],
        [ 98.4753],
        [134.9682],
        [112.3786],
        [139.0253],
        [ 95.7358],
        [136.5642],
        [120.2195],
        [ 91.3997],
        [145.7531],
        [123.8396],
        [146.6787],
        [100.7920],
        [170.6888],
        [108.0619],
        [139.8706],
        [ 98.1338],
        [159.1827],
        [112.8883],
        [129.6132],
        [ 97.0819],
        [135.8906],
        [124.1178],
        [141.6740],
        [157.2296],
        [117.1579],
        [154.4287],
        [ 89.5718],
        [123.3089],
        [108.0110],
        [165.7572],
        [113.2656],
        [120.2463],
        [112.8839],
        [156.3851],
        [111.3654],
        [148.2135],
        [113.5836],
        [144.3345],
        [ 90.9270],
        [122.5820],
        [147.7196],
        [ 95.1863],
        [145.0244],
        [115.7150],
        [125.9735],
        [118.4464],
        [162.1410],
        [108.0633],
        [119.0295],
        [108.6338],
        [159.1888],
        [118.6245],
        [147.8384],
        [ 95.7172],
        [148.5835],
        [113.8649],
        [137.0297],
        [ 99.2728],
        [164.8039],
        [124.4379],
        [144.9254],
        [ 96.7005],
        [144.1974],
        [112.1823],
        [143.9982],
        [ 91.5408],
        [135.7789],
        [113.8244],
        [131.6935],
        [ 97.4011],
        [170.6645],
        [140.2049],
        [113.6289],
        [171.7835],
        [102.9138],
        [144.1265],
        [125.6516],
        [139.1790],
        [ 96.7353],
        [139.3881],
        [127.6273],
        [132.5084],
        [ 99.4896],
        [129.0562],
        [114.6426],
        [163.2512],
        [ 99.0750],
        [141.9147],
        [ 93.6718],
        [146.1255],
        [119.8816],
        [168.6309],
        [ 94.8482],
        [133.4038],
        [103.2993],
        [171.9270],
        [104.5272],
        [134.2593],
        [113.1232],
        [136.1417],
        [ 94.5135],
        [148.4576],
        [130.3477],
        [ 96.3945],
        [127.3777],
        [127.4564],
        [138.7287],
        [101.0591],
        [165.3281],
        [116.1446],
        [126.6196],
        [100.6559],
        [170.6065],
        [105.3656],
        [133.8484],
        [ 97.3069],
        [139.6983],
        [130.2318],
        [148.9530],
        [108.9590],
        [155.2003],
        [110.7861],
        [117.2482],
        [ 97.3017],
        [148.8483],
        [118.4062],
        [151.7636],
        [ 90.2558],
        [158.7955],
        [113.5818],
        [152.8305],
        [110.7066],
        [163.8409],
        [111.8385],
        [132.4279],
        [157.2536],
        [106.2157],
        [120.2524],
        [111.0851],
        [148.1106],
        [ 95.1662],
        [145.6325],
        [113.0232],
        [151.4651],
        [100.8664],
        [147.1486],
        [123.5448],
        [152.3247],
        [113.7357],
        [122.6062],
        [114.7308],
        [108.2183],
        [128.8399],
        [100.2441],
        [168.0173],
        [126.8866],
        [139.5479],
        [ 94.4982],
        [132.5973],
        [130.9848],
        [139.0302],
        [ 98.1403],
        [132.0112],
        [113.6169],
        [137.0487],
        [106.0537],
        [166.7550],
        [132.8694],
        [111.7189],
        [167.6661],
        [104.5785],
        [141.5184],
        [124.1205],
        [132.2041],
        [ 90.1083],
        [150.9055],
        [128.3313],
        [144.9370],
        [ 92.2995],
        [137.6738],
        [106.7473],
        [170.9543],
        [102.5912],
        [144.8792],
        [117.2631],
        [143.6599],
        [ 99.3227],
        [118.0352],
        [115.2229],
        [153.8468],
        [104.8558],
        [126.4690],
        [114.1316],
        [166.0919],
        [112.7584],
        [150.6313],
        [115.8700],
        [148.3515],
        [ 95.2095],
        [104.1310],
        [152.1774],
        [ 93.4958],
        [150.1726],
        [113.0122],
        [123.3742],
        [105.7603],
        [163.0223],
        [115.8389],
        [125.1153],
        [110.9771],
        [160.3729],
        [117.8296],
        [153.2269],
        [ 93.9281],
        [156.1017],
        [ 91.5511],
        [141.1268],
        [120.2602],
        [141.6659],
        [ 96.3083],
        [169.6316],
        [106.6602],
        [136.5604],
        [102.6516],
        [163.5068],
        [109.1642],
        [136.1675],
        [ 98.7209],
        [142.6044],
        [133.7644],
        [146.8626],
        [133.9634],
        [100.7436],
        [140.1624],
        [128.5827],
        [157.4642],
        [100.1565],
        [124.7454],
        [114.9070],
        [166.5653],
        [102.5075],
        [138.2366],
        [111.0239],
        [143.4409],
        [ 95.5426],
        [142.6376],
        [127.0814],
        [161.7142],
        [107.9527],
        [117.8115],
        [111.9326],
        [143.5148],
        [ 95.8479],
        [151.4440],
        [117.0040],
        [157.1454],
        [ 92.9448],
        [159.0758],
        [118.5536],
        [165.6014],
        [107.3945],
        [127.6229],
        [105.0270],
        [105.8003],
        [156.2717],
        [103.8599],
        [114.9676],
        [ 95.7429],
        [148.4970],
        [115.9105],
        [152.8470],
        [ 96.2918],
        [144.3724],
        [122.3060],
        [152.0785],
        [115.9057],
        [162.6358],
        [116.3184],
        [117.2437],
        [129.0213],
        [115.6391],
        [167.3262],
        [100.2016],
        [142.1284],
        [116.8609],
        [132.5908],
        [ 94.8224],
        [143.9979],
        [129.9601],
        [139.5701],
        [ 99.2698],
        [131.4737],
        [114.8014],
        [163.8539],
        [103.1368],
        [111.6864],
        [133.1916],
        [ 94.7156],
        [166.0470],
        [123.5995],
        [141.3709],
        [ 98.6077],
        [135.9259],
        [125.1636],
        [148.5377],
        [ 94.5194],
        [142.1783],
        [109.3489],
        [142.9043],
        [ 99.8804],
        [173.5507],
        [117.6051],
        [145.9628],
        [ 93.5681],
        [141.0294],
        [114.8695],
        [116.4741],
        [112.8088],
        [154.2135],
        [110.9097],
        [120.8410],
        [114.3923],
        [161.1749],
        [120.6475],
        [153.0391],
        [ 93.8916],
        [153.1997],
        [152.4866],
        [117.6236],
        [149.8038],
        [ 91.5980],
        [120.9425],
        [101.8994],
        [163.7890],
        [107.2388],
        [127.1416],
        [111.9337],
        [164.9248],
        [113.6235],
        [151.3768],
        [121.2296],
        [147.8975],
        [ 92.7047],
        [160.8521],
        [112.1438],
        [127.2119],
        [114.2918],
        [157.0564],
        [ 92.7620],
        [151.2318],
        [117.4500],
        [147.3313],
        [100.9248],
        [147.9686],
        [120.5686],
        [150.0432],
        [111.1030],
        [115.1308],
        [114.4169],
        [111.9041],
        [155.5921],
        [109.4521],
        [123.2595],
        [ 95.6722],
        [153.7338],
        [122.5786],
        [152.5716],
        [ 92.4255],
        [151.1225],
        [110.2785],
        [149.4946],
        [102.9519],
        [160.2240],
        [108.0243],
        [121.8648],
        [ 97.8191],
        [134.9092],
        [134.3379],
        [147.0213],
        [107.5886],
        [167.9496],
        [115.0182],
        [130.1060],
        [ 99.1977],
        [166.9952],
        [105.6217],
        [128.4757],
        [ 95.3587],
        [136.9053],
        [124.6529],
        [145.3723],
        [144.3497],
        [ 95.8518],
        [152.8625],
        [126.6154],
        [171.6913],
        [ 96.0465],
        [137.3130],
        [103.7879],
        [167.0406],
        [ 99.1620],
        [128.8370],
        [111.9212],
        [130.7166],
        [ 93.9823],
        [142.4910],
        [125.1064],
        [110.8437],
        [153.3858],
        [ 93.7377],
        [152.2022],
        [111.9429],
        [129.4514],
        [109.0192],
        [167.8720],
        [110.9734],
        [119.3218],
        [102.2009],
        [155.2588],
        [115.5158],
        [149.2385],
        [ 96.5073],
        [147.2641],
        [151.1190],
        [121.0716],
        [153.6307],
        [ 96.9390],
        [121.9142],
        [117.6064],
        [156.0782],
        [114.2535],
        [117.0475],
        [114.3555],
        [160.7784],
        [109.7691],
        [151.4169],
        [108.6107],
        [146.3225],
        [ 95.2635],
        [138.5957],
        [108.2946],
        [171.0639],
        [105.2205],
        [143.7381],
        [129.2302],
        [134.8622],
        [ 93.6984],
        [143.9034],
        [125.0419],
        [136.6129],
        [ 91.6671],
        [130.0353],
        [105.7875],
        [170.3106],
        [ 96.4635],
        [109.8124],
        [133.4700],
        [104.9304],
        [168.4477],
        [131.7772],
        [149.5126],
        [ 94.6591],
        [142.3940],
        [126.8434],
        [138.1397],
        [ 94.4925],
        [131.8562],
        [115.1716],
        [129.8424],
        [107.0376],
        [162.9190]], device='cuda:0', dtype=torch.float64)] SHAPE IS = torch.Size([512, 1]) SHAPE IS = torch.Size([512, 1]) SHAPE IS = torch.Size([512, 1]) AFTER NORMALIZATION: [tensor([[ 5.2985],
        [ 5.6983],
        [ 9.3622],
        [ 8.8628],
        [ 9.9398],
        [ 6.2513],
        [ 5.2488],
        [ 8.2092],
        [ 7.3916],
        [ 5.0530],
        [ 8.0266],
        [ 9.9980],
        [ 9.8771],
        [ 8.7756],
        [ 5.2806],
        [ 6.6076],
        [ 6.2585],
        [ 5.1392],
        [ 8.1951],
        [ 9.6222],
        [ 9.9577],
        [ 7.6442],
        [ 5.0015],
        [ 6.7676],
        [ 8.5720],
        [ 5.1173],
        [ 6.8368],
        [ 9.7387],
        [ 9.1458],
        [ 9.5978],
        [ 6.1652],
        [ 5.6679],
        [ 5.8186],
        [ 5.9478],
        [ 9.4692],
        [ 9.3539],
        [ 9.8221],
        [ 7.1048],
        [ 5.0580],
        [ 8.3089],
        [ 7.0415],
        [ 5.0200],
        [ 7.3680],
        [ 9.9872],
        [ 9.4550],
        [ 8.4031],
        [ 5.2410],
        [ 6.0776],
        [ 6.4127],
        [ 5.4156],
        [ 8.9614],
        [ 9.7710],
        [ 9.9981],
        [ 7.7562],
        [ 5.0162],
        [ 7.6750],
        [ 7.9352],
        [ 5.1591],
        [ 6.4975],
        [ 9.9765],
        [ 9.0957],
        [ 9.2082],
        [ 5.5231],
        [ 5.4080],
        [ 5.5248],
        [ 5.6317],
        [ 9.0795],
        [ 8.9352],
        [ 9.9476],
        [ 6.6846],
        [ 5.2376],
        [ 7.7659],
        [ 7.5982],
        [ 5.0114],
        [ 7.8029],
        [ 9.9937],
        [ 9.7513],
        [ 8.8982],
        [ 5.4596],
        [ 6.4552],
        [ 5.9412],
        [ 5.1623],
        [ 8.5883],
        [ 9.5570],
        [ 9.9587],
        [ 7.1986],
        [ 5.0042],
        [ 7.2413],
        [ 8.3524],
        [ 5.0426],
        [ 7.0281],
        [ 9.8390],
        [ 9.4046],
        [ 9.4972],
        [ 5.9112],
        [ 5.7617],
        [ 5.6158],
        [ 6.1257],
        [ 9.6225],
        [ 9.2031],
        [ 9.7592],
        [ 6.7619],
        [ 5.0951],
        [ 8.6133],
        [ 6.9630],
        [ 5.0012],
        [ 7.4743],
        [ 9.9130],
        [ 9.7075],
        [ 8.3866],
        [ 5.0807],
        [ 6.1139],
        [ 6.6517],
        [ 5.3177],
        [ 8.7088],
        [ 9.8625],
        [10.0000],
        [ 8.0724],
        [ 5.0439],
        [ 7.3147],
        [ 8.0438],
        [ 5.3439],
        [ 6.4294],
        [ 9.8971],
        [ 8.6891],
        [ 9.2438],
        [ 5.8202],
        [ 5.4007],
        [ 5.3432],
        [ 5.7712],
        [ 9.2973],
        [ 8.7919],
        [ 9.8976],
        [ 6.3825],
        [ 5.3137],
        [ 8.0540],
        [ 7.3043],
        [ 5.0333],
        [ 8.1230],
        [10.0000],
        [ 9.8211],
        [ 8.6419],
        [ 5.3512],
        [ 6.7558],
        [ 6.1804],
        [ 5.1075],
        [ 8.2855],
        [ 9.6649],
        [ 9.9213],
        [ 7.4948],
        [ 5.0005],
        [ 6.9231],
        [ 8.6498],
        [ 5.0873],
        [ 6.7423],
        [ 9.7729],
        [ 9.2664],
        [ 9.6772],
        [ 6.0445],
        [ 5.5647],
        [ 5.7552],
        [ 5.8658],
        [ 9.5283],
        [ 9.4061],
        [ 9.8781],
        [ 6.9544],
        [ 5.0309],
        [ 8.4560],
        [ 7.1311],
        [ 5.0091],
        [ 7.2735],
        [ 9.9773],
        [ 9.5557],
        [ 8.5408],
        [ 5.1840],
        [ 5.9482],
        [ 6.4921],
        [ 5.4764],
        [ 8.8798],
        [ 9.7365],
        [ 9.9860],
        [ 7.9077],
        [ 5.0039],
        [ 7.5185],
        [ 7.8450],
        [ 5.1973],
        [ 6.5853],
        [ 9.9637],
        [ 8.9626],
        [ 9.0966],
        [ 5.6127],
        [ 5.5002],
        [ 5.4723],
        [ 5.5625],
        [ 9.1550],
        [ 8.9997],
        [ 9.9758],
        [ 6.5418],
        [ 5.1797],
        [ 7.9212],
        [ 7.6892],
        [ 5.0234],
        [ 7.7082],
        [ 9.9983],
        [ 9.8194],
        [ 9.0191],
        [ 5.3813],
        [ 6.3116],
        [ 6.0101],
        [ 5.2021],
        [ 8.4987],
        [ 9.5109],
        [ 9.9832],
        [ 7.3513],
        [ 5.0169],
        [ 7.0857],
        [ 8.2664],
        [ 5.0635],
        [ 7.1214],
        [ 9.8084],
        [ 9.2911],
        [ 9.4038],
        [ 6.0231],
        [ 5.8810],
        [ 5.6767],
        [ 6.2124],
        [ 9.5709],
        [ 9.1413],
        [ 9.6818],
        [ 6.9060],
        [ 5.1377],
        [ 8.4669],
        [ 6.8784],
        [ 5.0000],
        [ 7.5728],
        [ 9.9325],
        [ 9.6254],
        [ 8.2417],
        [ 5.1215],
        [ 6.2474],
        [ 6.5664],
        [ 5.2693],
        [ 8.7912],
        [ 9.8885],
        [ 9.9926],
        [ 7.9266],
        [ 5.0743],
        [ 7.4751],
        [ 8.1288],
        [ 5.2918],
        [ 6.3406],
        [ 9.9185],
        [ 8.8311],
        [ 9.3501],
        [ 5.7157],
        [ 5.3198],
        [ 5.3288],
        [ 5.7409],
        [ 9.3206],
        [ 8.8091],
        [ 9.9259],
        [ 6.3058],
        [ 5.2771],
        [ 8.1500],
        [ 7.4551],
        [ 5.0663],
        [ 7.9673],
        [ 9.9946],
        [ 9.8955],
        [ 8.8298],
        [ 5.2526],
        [ 6.5514],
        [ 6.2047],
        [ 5.1200],
        [ 8.2540],
        [ 9.6550],
        [ 9.9459],
        [ 7.5818],
        [ 5.0001],
        [ 6.8266],
        [ 8.5143],
        [ 5.1367],
        [ 6.8954],
        [ 9.7102],
        [ 9.0990],
        [ 9.5626],
        [ 6.2184],
        [ 5.7097],
        [ 5.8654],
        [ 5.9957],
        [ 9.4307],
        [ 9.3107],
        [ 9.7989],
        [ 7.1666],
        [ 5.0724],
        [ 8.2505],
        [ 7.1040],
        [ 5.0130],
        [ 7.3076],
        [ 9.9800],
        [ 9.4927],
        [ 8.4620],
        [ 5.2149],
        [ 6.0282],
        [ 6.3568],
        [ 5.3827],
        [ 9.0108],
        [ 9.7968],
        [ 9.9998],
        [ 7.6939],
        [ 5.0243],
        [ 7.7363],
        [ 7.8726],
        [ 5.1814],
        [ 6.5532],
        [ 9.9672],
        [ 9.0479],
        [ 9.1614],
        [ 5.5620],
        [ 5.4418],
        [ 5.4870],
        [ 5.5921],
        [ 9.1268],
        [ 8.9867],
        [ 9.9592],
        [ 6.6258],
        [ 5.2114],
        [ 7.8270],
        [ 7.5347],
        [ 5.0063],
        [ 7.8629],
        [ 9.9884],
        [ 9.7239],
        [ 8.8451],
        [ 5.4963],
        [ 6.5105],
        [ 5.9905],
        [ 5.1845],
        [ 8.5326],
        [ 9.5202],
        [ 9.9689],
        [ 7.2607],
        [ 5.0087],
        [ 7.1802],
        [ 8.4118],
        [ 5.0321],
        [ 6.9687],
        [ 9.8604],
        [ 9.4439],
        [ 9.5347],
        [ 5.8634],
        [ 5.7187],
        [ 5.5753],
        [ 6.0756],
        [ 9.6543],
        [ 9.2490],
        [ 9.7845],
        [ 6.7024],
        [ 5.0786],
        [ 8.6681],
        [ 6.9012],
        [ 5.0000],
        [ 7.5348],
        [ 9.9286],
        [ 9.6780],
        [ 8.3270],
        [ 5.0972],
        [ 6.1646],
        [ 6.7108],
        [ 5.3478],
        [ 8.6546],
        [ 9.8410],
        [ 9.9999],
        [ 8.1330],
        [ 5.0329],
        [ 7.2534],
        [ 8.1055],
        [ 5.3134],
        [ 6.3750],
        [ 9.9141],
        [ 8.7429],
        [ 9.2887],
        [ 5.7745],
        [ 5.3685],
        [ 5.3754],
        [ 5.8154],
        [ 9.2541],
        [ 8.7372],
        [ 9.8797],
        [ 6.4388],
        [ 5.3452],
        [ 7.9938],
        [ 7.3676],
        [ 5.0441],
        [ 8.0642],
        [ 9.9986],
        [ 9.8433],
        [ 8.6980],
        [ 5.3199],
        [ 6.6982],
        [ 6.1278],
        [ 5.0906],
        [ 8.3437],
        [ 9.6959],
        [ 9.9055],
        [ 7.4324],
        [ 5.0026],
        [ 6.9831],
        [ 8.5931],
        [ 5.1041],
        [ 6.8002],
        [ 9.7461],
        [ 9.2223],
        [ 9.6453],
        [ 6.0957],
        [ 5.6036],
        [ 5.8006],
        [ 5.9121],
        [ 9.4918],
        [ 9.3644],
        [ 9.8587],
        [ 7.0155],
        [ 5.0417],
        [ 8.3989],
        [ 7.1939],
        [ 5.0046],
        [ 7.2133],
        [ 9.9681],
        [ 9.5901],
        [ 8.5982],
        [ 5.1612],
        [ 5.9012],
        [ 6.4352],
        [ 5.4414],
        [ 8.9307],
        [ 9.7641],
        [ 9.9917],
        [ 7.8459],
        [ 5.0083],
        [ 7.5800],
        [ 7.7821],
        [ 5.2219],
        [ 6.6419],
        [ 9.9523],
        [ 8.9123],
        [ 9.0473],
        [ 5.6543],
        [ 5.5371],
        [ 5.4364],
        [ 5.5248],
        [ 9.2007],
        [ 9.0499],
        [ 9.9835],
        [ 6.4844],
        [ 5.1568],
        [ 7.9817],
        [ 7.6259],
        [ 5.0157],
        [ 7.7685],
        [ 9.9951],
        [ 9.7957],
        [ 8.9682],
        [ 5.4151],
        [ 6.3653],
        [ 6.0607],
        [ 5.2266],
        [ 8.4421],
        [ 9.4725],
        [ 9.9895],
        [ 7.4137],
        [ 5.0251],
        [ 7.0251],
        [ 8.3265],
        [ 5.0505],
        [ 7.0616],
        [ 9.8317],
        [ 9.3335],
        [ 9.4443],
        [ 5.9731],
        [ 5.8354],
        [ 5.6345],
        [ 6.1608],
        [ 9.6047],
        [ 9.1887],
        [ 9.7108],
        [ 6.8455],
        [ 5.1177],
        [ 8.5234],
        [ 6.8171],
        [ 5.0014],
        [ 7.6333],
        [ 9.9462],
        [ 9.5923],
        [ 8.1809],
        [ 5.1415],
        [ 6.3001],
        [ 6.6247],
        [ 5.2972],
        [ 8.7381],
        [ 9.8690],
        [ 9.9966],
        [ 7.9880],
        [ 5.0597],
        [ 7.4136],
        [ 8.1899],
        [ 5.2636],
        [ 6.2873],
        [ 9.9336],
        [ 8.8828],
        [ 9.3922],
        [ 5.6725],
        [ 5.2908]], device='cuda:0', dtype=torch.float64), tensor([[ 8.6449],
        [ 5.5831],
        [ 7.6601],
        [ 6.5179],
        [ 7.3670],
        [ 8.4105],
        [ 5.0219],
        [ 8.5503],
        [ 5.0952],
        [ 8.7138],
        [ 8.2115],
        [ 7.7938],
        [ 7.4126],
        [ 6.6494],
        [ 9.6724],
        [ 5.4200],
        [ 9.7814],
        [ 5.0129],
        [ 8.0191],
        [ 6.5089],
        [ 6.3160],
        [ 7.0508],
        [ 5.2659],
        [ 9.9682],
        [ 5.9092],
        [ 9.9151],
        [ 5.2612],
        [ 7.8589],
        [ 8.1738],
        [ 7.4348],
        [ 9.7616],
        [ 5.0006],
        [ 7.5227],
        [ 7.9552],
        [ 5.1415],
        [ 9.8874],
        [ 9.9630],
        [ 5.3068],
        [ 7.5313],
        [ 5.4194],
        [ 7.7942],
        [ 6.3528],
        [ 9.9471],
        [ 5.5189],
        [ 5.0038],
        [ 9.4465],
        [ 6.2473],
        [ 8.4554],
        [ 6.4550],
        [ 7.9554],
        [ 5.7500],
        [ 9.2715],
        [ 8.3404],
        [ 5.0102],
        [ 8.2984],
        [ 7.6495],
        [ 8.0781],
        [ 8.0058],
        [ 9.6192],
        [ 5.0396],
        [ 5.2232],
        [ 8.9550],
        [ 6.8589],
        [ 7.2017],
        [ 5.2431],
        [ 7.9208],
        [ 6.8241],
        [ 8.6382],
        [ 8.5982],
        [ 6.4029],
        [ 7.7401],
        [ 6.7744],
        [ 9.4414],
        [ 5.9312],
        [ 8.1957],
        [ 6.3966],
        [ 6.9866],
        [ 8.6241],
        [ 5.1419],
        [ 7.6917],
        [ 6.2778],
        [ 9.5775],
        [ 5.7073],
        [ 8.3572],
        [ 8.5443],
        [ 5.9134],
        [ 9.2230],
        [ 5.0555],
        [ 8.4767],
        [ 5.4876],
        [ 8.6186],
        [ 6.4349],
        [ 5.3226],
        [ 8.4683],
        [ 6.5363],
        [ 9.4076],
        [ 8.1378],
        [ 5.0306],
        [ 9.7602],
        [ 6.0817],
        [ 5.1745],
        [ 9.0897],
        [ 5.9896],
        [ 8.5974],
        [ 5.4843],
        [ 8.6371],
        [ 5.3485],
        [ 8.8147],
        [ 9.2567],
        [ 6.8966],
        [ 8.5449],
        [ 6.0631],
        [ 8.6351],
        [ 6.4755],
        [ 7.3102],
        [ 5.5546],
        [ 6.7021],
        [ 8.9575],
        [ 6.4211],
        [ 8.4259],
        [ 6.3548],
        [ 8.2386],
        [ 6.4021],
        [ 8.5352],
        [ 9.2591],
        [ 5.1133],
        [ 8.4960],
        [ 7.0497],
        [ 7.8780],
        [ 6.4279],
        [ 9.1716],
        [ 5.8151],
        [ 5.0046],
        [ 8.3506],
        [ 7.5680],
        [ 8.2399],
        [ 7.9425],
        [ 8.0329],
        [ 5.0310],
        [ 9.5777],
        [ 8.7358],
        [ 5.2440],
        [ 7.1414],
        [ 6.8178],
        [ 7.7584],
        [ 7.4060],
        [ 9.9507],
        [ 5.0683],
        [ 5.4411],
        [ 9.9563],
        [ 5.3263],
        [ 7.3077],
        [ 6.3191],
        [ 7.6160],
        [ 5.6560],
        [ 9.9837],
        [ 9.5719],
        [ 5.0255],
        [ 8.3564],
        [ 6.2428],
        [ 5.0492],
        [ 9.7489],
        [ 6.6840],
        [ 8.1457],
        [ 7.2359],
        [ 6.0385],
        [ 9.9963],
        [ 5.1685],
        [ 9.8401],
        [ 5.7084],
        [ 8.0339],
        [ 5.2603],
        [ 7.4086],
        [ 8.3131],
        [ 5.0098],
        [ 9.6289],
        [ 5.5452],
        [ 8.6456],
        [ 6.4909],
        [ 7.7008],
        [ 8.4323],
        [ 7.4059],
        [ 8.9085],
        [ 5.0133],
        [ 8.7399],
        [ 5.1312],
        [ 7.8614],
        [ 8.2799],
        [ 6.6934],
        [ 7.4885],
        [ 5.3584],
        [ 9.8771],
        [ 6.6320],
        [ 8.6110],
        [ 5.4223],
        [ 7.1063],
        [ 8.3497],
        [ 6.5174],
        [ 8.5116],
        [ 6.3813],
        [ 8.3758],
        [ 6.3624],
        [ 8.3159],
        [ 6.1878],
        [ 5.0489],
        [ 8.8323],
        [ 7.2487],
        [ 8.5742],
        [ 5.0535],
        [ 8.1872],
        [ 6.0417],
        [ 9.6698],
        [ 9.0489],
        [ 5.1562],
        [ 8.6093],
        [ 6.5139],
        [ 8.6399],
        [ 5.6436],
        [ 8.7276],
        [ 5.3034],
        [ 6.8179],
        [ 9.1898],
        [ 6.3154],
        [ 8.5733],
        [ 9.6397],
        [ 6.3734],
        [ 8.3117],
        [ 5.5132],
        [ 5.7918],
        [ 8.5139],
        [ 5.0824],
        [ 9.3186],
        [ 5.5320],
        [ 8.5378],
        [ 6.3240],
        [ 8.6247],
        [ 8.4482],
        [ 5.1146],
        [ 9.4571],
        [ 6.5994],
        [ 8.3460],
        [ 5.3780],
        [ 8.6288],
        [ 6.6853],
        [ 6.4550],
        [ 8.5379],
        [ 7.0187],
        [ 7.9850],
        [ 6.1168],
        [ 9.6439],
        [ 6.3706],
        [ 8.0650],
        [ 8.5907],
        [ 6.8481],
        [ 8.1237],
        [ 5.2325],
        [ 6.3604],
        [ 9.5942],
        [ 5.0176],
        [ 8.3240],
        [ 8.5178],
        [ 6.4052],
        [ 9.3313],
        [ 5.0759],
        [ 8.5457],
        [ 5.5414],
        [ 8.6269],
        [ 5.3074],
        [ 6.1157],
        [ 8.4372],
        [ 6.6216],
        [ 9.4791],
        [ 5.3705],
        [ 7.6073],
        [ 6.6555],
        [ 8.6310],
        [ 8.5423],
        [ 6.5096],
        [ 8.5536],
        [ 6.9981],
        [ 8.7338],
        [ 6.1387],
        [ 8.0486],
        [ 6.3600],
        [ 6.8476],
        [ 8.5876],
        [ 5.2381],
        [ 8.9696],
        [ 8.6087],
        [ 6.6568],
        [ 7.5468],
        [ 5.4112],
        [ 6.4984],
        [ 7.9927],
        [ 6.3527],
        [ 8.5197],
        [ 6.3654],
        [ 8.3688],
        [ 6.1999],
        [ 9.1857],
        [ 8.0179],
        [ 5.0546],
        [ 8.5682],
        [ 7.2259],
        [ 8.1909],
        [ 5.8336],
        [ 9.7478],
        [ 6.0216],
        [ 5.1509],
        [ 8.9673],
        [ 5.6630],
        [ 8.6221],
        [ 6.6415],
        [ 8.6385],
        [ 5.3159],
        [ 8.7618],
        [ 9.1860],
        [ 6.8312],
        [ 8.5719],
        [ 5.2733],
        [ 9.7624],
        [ 5.0545],
        [ 8.1581],
        [ 7.0649],
        [ 5.6145],
        [ 7.2516],
        [ 5.1629],
        [ 9.9792],
        [ 5.7262],
        [ 9.8524],
        [ 6.1024],
        [ 8.0168],
        [ 8.3060],
        [ 6.5485],
        [ 9.6331],
        [ 5.0084],
        [ 9.5205],
        [ 5.5259],
        [ 7.7125],
        [ 6.5622],
        [ 7.3294],
        [ 8.4426],
        [ 5.0222],
        [ 8.1349],
        [ 5.1242],
        [ 9.8038],
        [ 8.2811],
        [ 7.8503],
        [ 7.4678],
        [ 6.6673],
        [ 8.8787],
        [ 5.3734],
        [ 6.4068],
        [ 7.8961],
        [ 5.8006],
        [ 8.5617],
        [ 8.8293],
        [ 5.0000],
        [ 8.2482],
        [ 7.6227],
        [ 8.0162],
        [ 7.9144],
        [ 8.5697],
        [ 5.0279],
        [ 5.2501],
        [ 9.7257],
        [ 6.8146],
        [ 7.1281],
        [ 6.8072],
        [ 7.7766],
        [ 5.0720],
        [ 9.8886],
        [10.0000],
        [ 5.4266],
        [ 7.3225],
        [ 6.0254],
        [ 7.6049],
        [ 5.4553],
        [ 9.9776],
        [ 5.6663],
        [ 5.0294],
        [ 9.5956],
        [ 7.1198],
        [ 8.3430],
        [ 5.4208],
        [ 8.1254],
        [ 6.0938],
        [ 9.7883],
        [ 9.0884],
        [ 5.1843],
        [ 8.5949],
        [ 5.5779],
        [ 8.6372],
        [ 6.3863],
        [ 8.8050],
        [ 5.3406],
        [ 6.8744],
        [ 9.2341],
        [ 5.2527],
        [ 8.5523],
        [ 6.5383],
        [ 8.6363],
        [ 5.5618],
        [ 8.1716],
        [ 8.1674],
        [ 6.7285],
        [ 8.4196],
        [ 6.3382],
        [ 8.2525],
        [ 6.3694],
        [ 9.5505],
        [ 6.3785],
        [ 5.1105],
        [ 8.2166],
        [ 7.0483],
        [ 8.5011],
        [ 7.3690],
        [ 5.2535],
        [ 8.6384],
        [ 6.7850],
        [ 6.4467],
        [ 8.5935],
        [ 6.7914],
        [ 8.2842],
        [ 5.9204],
        [ 8.4523],
        [ 6.3926],
        [ 8.2043],
        [ 8.6268],
        [ 7.0085],
        [ 8.6957],
        [ 5.1326],
        [ 9.5391],
        [ 6.2993],
        [ 8.3526],
        [ 5.0532],
        [ 6.5423],
        [ 8.5340],
        [ 5.0588],
        [ 9.2820],
        [ 5.4726],
        [ 8.4475],
        [ 5.5421],
        [ 8.6162],
        [ 8.4728],
        [ 6.1742],
        [ 9.4085],
        [ 6.5230],
        [ 7.9427],
        [ 6.9694],
        [ 9.8614],
        [ 5.1330],
        [ 5.3142],
        [ 9.9977],
        [ 5.9650],
        [ 7.5153],
        [ 5.3198],
        [ 7.8136],
        [ 5.5034],
        [ 9.9368],
        [ 9.4438],
        [ 5.0029],
        [ 8.4605],
        [ 7.2226],
        [ 7.9448],
        [ 6.4032],
        [ 8.6016],
        [ 5.7663],
        [ 5.0011],
        [ 8.9780],
        [ 7.6811],
        [ 8.2854],
        [ 8.0091],
        [ 8.0876],
        [ 5.0435],
        [ 8.7381],
        [ 9.8354],
        [ 5.2115],
        [ 7.2236],
        [ 6.8820],
        [ 5.5973],
        [ 9.0659],
        [ 6.5282],
        [ 7.6403],
        [ 8.4039],
        [ 7.3325],
        [ 8.1853],
        [ 5.0274],
        [ 9.5235],
        [ 5.1020],
        [ 7.8127],
        [ 8.2379],
        [ 6.6535],
        [ 7.4251],
        [ 5.4120],
        [ 8.7957],
        [ 5.0113],
        [ 9.8667],
        [ 7.3111],
        [ 7.9968],
        [ 7.0378],
        [ 5.4818],
        [ 9.8856],
        [ 5.2777],
        [ 9.9229],
        [ 5.8976],
        [ 7.8683],
        [ 6.3093],
        [ 6.4412],
        [ 8.1905],
        [ 5.0001],
        [ 9.7337]], device='cuda:0', dtype=torch.float64), tensor([[ 6.1975],
        [ 9.3790],
        [ 6.2277],
        [ 7.1293],
        [ 5.3307],
        [ 8.8920],
        [ 6.8289],
        [ 8.9537],
        [ 5.4466],
        [ 7.9797],
        [ 6.8362],
        [ 8.5179],
        [ 6.4045],
        [ 9.1750],
        [ 6.4940],
        [ 6.4970],
        [ 9.4226],
        [ 6.3090],
        [ 6.9226],
        [ 6.5229],
        [ 8.5912],
        [ 5.2558],
        [ 8.8008],
        [ 6.6637],
        [ 8.6391],
        [ 5.1752],
        [ 8.9204],
        [ 6.3336],
        [ 9.2053],
        [ 5.8377],
        [ 6.7358],
        [ 5.7956],
        [ 7.9649],
        [ 5.6677],
        [ 8.2197],
        [ 7.7642],
        [ 9.1537],
        [ 5.9775],
        [ 7.6583],
        [ 6.3800],
        [ 9.5284],
        [ 5.5301],
        [ 7.7028],
        [ 6.3579],
        [ 7.9444],
        [ 5.3670],
        [ 7.7979],
        [ 6.8247],
        [ 5.1088],
        [ 8.3450],
        [ 7.0403],
        [ 8.4001],
        [ 5.6680],
        [ 9.8296],
        [ 6.1009],
        [ 7.9947],
        [ 5.5098],
        [ 9.1445],
        [ 6.3882],
        [ 7.3840],
        [ 5.4471],
        [ 7.7578],
        [ 7.0568],
        [ 8.1021],
        [ 9.0283],
        [ 6.6424],
        [ 8.8615],
        [ 5.0000],
        [ 7.0087],
        [ 6.0978],
        [ 9.5360],
        [ 6.4107],
        [ 6.8263],
        [ 6.3880],
        [ 8.9780],
        [ 6.2976],
        [ 8.4915],
        [ 6.4296],
        [ 8.2605],
        [ 5.0807],
        [ 6.9654],
        [ 8.4620],
        [ 5.3343],
        [ 8.3016],
        [ 6.5565],
        [ 7.1673],
        [ 6.7192],
        [ 9.3207],
        [ 6.1010],
        [ 6.7539],
        [ 6.1349],
        [ 9.1449],
        [ 6.7298],
        [ 8.4691],
        [ 5.3659],
        [ 8.5135],
        [ 6.4464],
        [ 7.8256],
        [ 5.5776],
        [ 9.4792],
        [ 7.0759],
        [ 8.2957],
        [ 5.4244],
        [ 8.2523],
        [ 6.3462],
        [ 8.2405],
        [ 5.1172],
        [ 7.7511],
        [ 6.4440],
        [ 7.5079],
        [ 5.4661],
        [ 9.8282],
        [ 8.0146],
        [ 6.4323],
        [ 9.8948],
        [ 5.7944],
        [ 8.2481],
        [ 7.1481],
        [ 7.9535],
        [ 5.4265],
        [ 7.9660],
        [ 7.2658],
        [ 7.5564],
        [ 5.5905],
        [ 7.3509],
        [ 6.4927],
        [ 9.3868],
        [ 5.5658],
        [ 8.1164],
        [ 5.2441],
        [ 8.3671],
        [ 6.8046],
        [ 9.7071],
        [ 5.3142],
        [ 7.6097],
        [ 5.8173],
        [ 9.9033],
        [ 5.8904],
        [ 7.6606],
        [ 6.4022],
        [ 7.7727],
        [ 5.2942],
        [ 8.5060],
        [ 7.4277],
        [ 5.4062],
        [ 7.2509],
        [ 7.2556],
        [ 7.9267],
        [ 5.6839],
        [ 9.5104],
        [ 6.5821],
        [ 7.2058],
        [ 5.6599],
        [ 9.8247],
        [ 5.9403],
        [ 7.6362],
        [ 5.4605],
        [ 7.9845],
        [ 7.4208],
        [ 8.5355],
        [ 6.1543],
        [ 8.9074],
        [ 6.2631],
        [ 6.6478],
        [ 5.4602],
        [ 8.5292],
        [ 6.7168],
        [ 8.7028],
        [ 5.0407],
        [ 9.1215],
        [ 6.4295],
        [ 8.7663],
        [ 6.2583],
        [ 9.4219],
        [ 6.3257],
        [ 7.5516],
        [ 9.0297],
        [ 5.9910],
        [ 6.8267],
        [ 6.2809],
        [ 8.4853],
        [ 5.3331],
        [ 8.3378],
        [ 6.3963],
        [ 8.6850],
        [ 5.6725],
        [ 8.4281],
        [ 7.0227],
        [ 8.7362],
        [ 6.4387],
        [ 6.9668],
        [ 6.4979],
        [ 6.1102],
        [ 7.3380],
        [ 5.6354],
        [ 9.6705],
        [ 7.2217],
        [ 7.9755],
        [ 5.2933],
        [ 7.5617],
        [ 7.4657],
        [ 7.9447],
        [ 5.5102],
        [ 7.5268],
        [ 6.4316],
        [ 7.8267],
        [ 5.9813],
        [ 9.5954],
        [ 7.5779],
        [ 6.3186],
        [ 9.6496],
        [ 5.8935],
        [ 8.0928],
        [ 7.0570],
        [ 7.5383],
        [ 5.0319],
        [ 8.6517],
        [ 7.3077],
        [ 8.2964],
        [ 5.1624],
        [ 7.8639],
        [ 6.0226],
        [ 9.8454],
        [ 5.7752],
        [ 8.2929],
        [ 6.6487],
        [ 8.2203],
        [ 5.5806],
        [ 6.6947],
        [ 6.5272],
        [ 8.8269],
        [ 5.9100],
        [ 7.1968],
        [ 6.4623],
        [ 9.5559],
        [ 6.3805],
        [ 8.6354],
        [ 6.5658],
        [ 8.4997],
        [ 5.3357],
        [ 5.8668],
        [ 8.7275],
        [ 5.2336],
        [ 8.6081],
        [ 6.3956],
        [ 7.0126],
        [ 5.9638],
        [ 9.3732],
        [ 6.5639],
        [ 7.1162],
        [ 6.2744],
        [ 9.2154],
        [ 6.6824],
        [ 8.7899],
        [ 5.2594],
        [ 8.9611],
        [ 5.1178],
        [ 8.0695],
        [ 6.8271],
        [ 8.1016],
        [ 5.4011],
        [ 9.7667],
        [ 6.0174],
        [ 7.7976],
        [ 5.7788],
        [ 9.4020],
        [ 6.1665],
        [ 7.7742],
        [ 5.5447],
        [ 8.1575],
        [ 7.6312],
        [ 8.4110],
        [ 7.6430],
        [ 5.6652],
        [ 8.0121],
        [ 7.3227],
        [ 9.0422],
        [ 5.6302],
        [ 7.0942],
        [ 6.5084],
        [ 9.5841],
        [ 5.7702],
        [ 7.8974],
        [ 6.2772],
        [ 8.2073],
        [ 5.3555],
        [ 8.1595],
        [ 7.2333],
        [ 9.2953],
        [ 6.0944],
        [ 6.6814],
        [ 6.3313],
        [ 8.2117],
        [ 5.3737],
        [ 8.6838],
        [ 6.6333],
        [ 9.0232],
        [ 5.2008],
        [ 9.1382],
        [ 6.7255],
        [ 9.5267],
        [ 6.0611],
        [ 7.2655],
        [ 5.9202],
        [ 5.9662],
        [ 8.9712],
        [ 5.8507],
        [ 6.5120],
        [ 5.3674],
        [ 8.5083],
        [ 6.5682],
        [ 8.7673],
        [ 5.4001],
        [ 8.2628],
        [ 6.9490],
        [ 8.7216],
        [ 6.5679],
        [ 9.3501],
        [ 6.5925],
        [ 6.6476],
        [ 7.3488],
        [ 6.5520],
        [ 9.6294],
        [ 5.6329],
        [ 8.1292],
        [ 6.6248],
        [ 7.5613],
        [ 5.3126],
        [ 8.2405],
        [ 7.4047],
        [ 7.9768],
        [ 5.5774],
        [ 7.4948],
        [ 6.5021],
        [ 9.4227],
        [ 5.8076],
        [ 6.3167],
        [ 7.5971],
        [ 5.3063],
        [ 9.5532],
        [ 7.0260],
        [ 8.0841],
        [ 5.5380],
        [ 7.7599],
        [ 7.1191],
        [ 8.5108],
        [ 5.2946],
        [ 8.1321],
        [ 6.1775],
        [ 8.1754],
        [ 5.6138],
        [10.0000],
        [ 6.6691],
        [ 8.3574],
        [ 5.2379],
        [ 8.0637],
        [ 6.5062],
        [ 6.6017],
        [ 6.3835],
        [ 8.8487],
        [ 6.2704],
        [ 6.8617],
        [ 6.4778],
        [ 9.2632],
        [ 6.8502],
        [ 8.7788],
        [ 5.2572],
        [ 8.7883],
        [ 8.7459],
        [ 6.6702],
        [ 8.5861],
        [ 5.1206],
        [ 6.8678],
        [ 5.7340],
        [ 9.4188],
        [ 6.0519],
        [ 7.2369],
        [ 6.3314],
        [ 9.4864],
        [ 6.4320],
        [ 8.6798],
        [ 6.8849],
        [ 8.4726],
        [ 5.1865],
        [ 9.2439],
        [ 6.3439],
        [ 7.2410],
        [ 6.4718],
        [ 9.0180],
        [ 5.1899],
        [ 8.6712],
        [ 6.6598],
        [ 8.4389],
        [ 5.6759],
        [ 8.4769],
        [ 6.8455],
        [ 8.6004],
        [ 6.2819],
        [ 6.5218],
        [ 6.4792],
        [ 6.3296],
        [ 8.9308],
        [ 6.1836],
        [ 7.0057],
        [ 5.3632],
        [ 8.8201],
        [ 6.9652],
        [ 8.7509],
        [ 5.1699],
        [ 8.6647],
        [ 6.2328],
        [ 8.5677],
        [ 5.7966],
        [ 9.2065],
        [ 6.0986],
        [ 6.9227],
        [ 5.4910],
        [ 7.6993],
        [ 7.6653],
        [ 8.4205],
        [ 6.0727],
        [ 9.6665],
        [ 6.5150],
        [ 7.4134],
        [ 5.5731],
        [ 9.6097],
        [ 5.9556],
        [ 7.3163],
        [ 5.3445],
        [ 7.8182],
        [ 7.0887],
        [ 8.3223],
        [ 8.2614],
        [ 5.3739],
        [ 8.7682],
        [ 7.2055],
        [ 9.8893],
        [ 5.3855],
        [ 7.8424],
        [ 5.8464],
        [ 9.6124],
        [ 5.5710],
        [ 7.3378],
        [ 6.3307],
        [ 7.4497],
        [ 5.2626],
        [ 8.1507],
        [ 7.1157],
        [ 6.2665],
        [ 8.7994],
        [ 5.2480],
        [ 8.7289],
        [ 6.3319],
        [ 7.3744],
        [ 6.1579],
        [ 9.6619],
        [ 6.2742],
        [ 6.7713],
        [ 5.7519],
        [ 8.9109],
        [ 6.5447],
        [ 8.5525],
        [ 5.4129],
        [ 8.4349],
        [ 8.6644],
        [ 6.8755],
        [ 8.8140],
        [ 5.4386],
        [ 6.9256],
        [ 6.6691],
        [ 8.9597],
        [ 6.4695],
        [ 6.6359],
        [ 6.4756],
        [ 9.2396],
        [ 6.2025],
        [ 8.6822],
        [ 6.1336],
        [ 8.3789],
        [ 5.3389],
        [ 7.9188],
        [ 6.1147],
        [ 9.8519],
        [ 5.9317],
        [ 8.2250],
        [ 7.3612],
        [ 7.6965],
        [ 5.2457],
        [ 8.2348],
        [ 7.1118],
        [ 7.8008],
        [ 5.1247],
        [ 7.4091],
        [ 5.9655],
        [ 9.8071],
        [ 5.4103],
        [ 6.2051],
        [ 7.6136],
        [ 5.9144],
        [ 9.6962],
        [ 7.5129],
        [ 8.5688],
        [ 5.3029],
        [ 8.1450],
        [ 7.2191],
        [ 7.8917],
        [ 5.2930],
        [ 7.5176],
        [ 6.5242],
        [ 7.3977],
        [ 6.0399],
        [ 9.3670]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION: [tensor([[143.7790],
        [140.7617],
        [174.5642],
        [165.4470],
        [143.8968],
        [166.0314],
        [157.7061],
        [153.1354],
        [140.0703],
        [150.7251]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.9417],
        [45.8800],
        [35.1952],
        [61.6610],
        [87.3551],
        [53.2007],
        [50.3099],
        [40.9606],
        [35.2460],
        [50.0690]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[108.2183],
        [ 96.7005],
        [120.2602],
        [105.7875],
        [129.0213],
        [140.1624],
        [105.6217],
        [128.8370],
        [ 98.6077],
        [110.9771]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5376],
        [ 5.1002],
        [10.0000],
        [ 8.6784],
        [ 5.5547],
        [ 8.7631],
        [ 7.5564],
        [ 6.8938],
        [ 5.0000],
        [ 6.5444]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7012],
        [ 6.0242],
        [ 5.0000],
        [ 7.5370],
        [10.0000],
        [ 6.7260],
        [ 6.4489],
        [ 5.5527],
        [ 5.0049],
        [ 6.4258]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3251],
        [ 5.0000],
        [ 7.7104],
        [ 6.0454],
        [ 8.7183],
        [10.0000],
        [ 6.0263],
        [ 8.6971],
        [ 5.2194],
        [ 6.6424]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[143.7388],
        [140.7206],
        [174.2461],
        [165.3587],
        [143.8655],
        [165.8949],
        [157.3918],
        [152.8431],
        [140.0792],
        [150.1887]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8833],
        [45.6339],
        [35.1966],
        [61.6440],
        [87.3327],
        [53.1665],
        [50.3265],
        [40.9060],
        [35.2747],
        [50.0794]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[108.1890],
        [ 96.7282],
        [120.1100],
        [105.7864],
        [128.9320],
        [140.1090],
        [105.5566],
        [128.6168],
        [ 98.6122],
        [110.6733]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5356],
        [ 5.0939],
        [10.0000],
        [ 8.6994],
        [ 5.5541],
        [ 8.7779],
        [ 7.5335],
        [ 6.8679],
        [ 5.0000],
        [ 6.4794]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.6962],
        [ 6.0010],
        [ 5.0000],
        [ 7.5364],
        [10.0000],
        [ 6.7234],
        [ 6.4510],
        [ 5.5476],
        [ 5.0075],
        [ 6.4273]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3209],
        [ 5.0000],
        [ 7.6949],
        [ 6.0440],
        [ 8.7118],
        [10.0000],
        [ 6.0175],
        [ 8.6754],
        [ 5.2171],
        [ 6.6073]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[143.6984],
        [140.6805],
        [173.9121],
        [165.2692],
        [143.8340],
        [165.7564],
        [157.0722],
        [152.5489],
        [140.0880],
        [149.6502]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.8257],
        [45.3920],
        [35.2000],
        [61.6269],
        [87.3102],
        [53.1322],
        [50.3436],
        [40.8528],
        [35.3057],
        [50.0909]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[108.1597],
        [ 96.7574],
        [119.9584],
        [105.7851],
        [128.8426],
        [140.0548],
        [105.4900],
        [128.3924],
        [ 98.6178],
        [110.3654]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5337],
        [ 5.0876],
        [10.0000],
        [ 8.7224],
        [ 5.5537],
        [ 8.7944],
        [ 7.5107],
        [ 6.8420],
        [ 5.0000],
        [ 6.4135]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.6912],
        [ 5.9779],
        [ 5.0000],
        [ 7.5357],
        [10.0000],
        [ 6.7206],
        [ 6.4530],
        [ 5.5424],
        [ 5.0101],
        [ 6.4288]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3167],
        [ 5.0000],
        [ 7.6793],
        [ 6.0425],
        [ 8.7052],
        [10.0000],
        [ 6.0084],
        [ 8.6532],
        [ 5.2148],
        [ 6.5715]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[143.6798],
        [140.6623],
        [173.7553],
        [165.2279],
        [143.8195],
        [165.6924],
        [156.9248],
        [152.4137],
        [140.0923],
        [149.4049]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7993],
        [45.2821],
        [35.2022],
        [61.6189],
        [87.2997],
        [53.1164],
        [50.3516],
        [40.8288],
        [35.3207],
        [50.0964]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[108.1462],
        [ 96.7708],
        [119.8886],
        [105.7846],
        [128.8013],
        [140.0297],
        [105.4593],
        [128.2888],
        [ 98.6204],
        [110.2239]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5329],
        [ 5.0847],
        [10.0000],
        [ 8.7334],
        [ 5.5536],
        [ 8.8024],
        [ 7.5002],
        [ 6.8301],
        [ 5.0000],
        [ 6.3832]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.6889],
        [ 5.9674],
        [ 5.0000],
        [ 7.5353],
        [10.0000],
        [ 6.7193],
        [ 6.4539],
        [ 5.5400],
        [ 5.0114],
        [ 6.4295]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3148],
        [ 5.0000],
        [ 7.6720],
        [ 6.0418],
        [ 8.7022],
        [10.0000],
        [ 6.0042],
        [ 8.6429],
        [ 5.2138],
        [ 6.5550]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[143.6389],
        [140.6234],
        [173.3969],
        [165.1366],
        [143.7878],
        [165.5510],
        [156.5973],
        [152.1169],
        [140.1008],
        [148.8652]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.7430],
        [45.0469],
        [35.2088],
        [61.6015],
        [87.2769],
        [53.0819],
        [50.3694],
        [40.7777],
        [35.3553],
        [50.1094]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[108.1170],
        [ 96.8021],
        [119.7348],
        [105.7629],
        [128.7115],
        [139.9744],
        [105.3907],
        [128.0583],
        [ 98.6274],
        [109.9099]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5313],
        [ 5.0785],
        [10.0000],
        [ 8.7596],
        [ 5.5537],
        [ 8.8218],
        [ 7.4772],
        [ 6.8044],
        [ 5.0000],
        [ 6.3161]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.6838],
        [ 5.9447],
        [ 5.0000],
        [ 7.5344],
        [10.0000],
        [ 6.7163],
        [ 6.4558],
        [ 5.5348],
        [ 5.0141],
        [ 6.4309]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3104],
        [ 5.0000],
        [ 7.6560],
        [ 6.0378],
        [ 8.6956],
        [10.0000],
        [ 5.9947],
        [ 8.6199],
        [ 5.2114],
        [ 6.5181]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[143.5977],
        [140.5854],
        [173.0209],
        [165.0442],
        [143.7559],
        [165.4076],
        [156.2643],
        [151.8182],
        [140.1089],
        [148.3262]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.6875],
        [44.8167],
        [35.2177],
        [61.5839],
        [87.2540],
        [53.0472],
        [50.3878],
        [40.7282],
        [35.3923],
        [50.1236]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[108.0879],
        [ 96.8350],
        [119.5794],
        [105.7412],
        [128.6216],
        [139.9181],
        [105.3205],
        [127.8235],
        [ 98.6354],
        [109.5919]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5300],
        [ 5.0724],
        [10.0000],
        [ 8.7882],
        [ 5.5540],
        [ 8.8434],
        [ 7.4543],
        [ 6.7789],
        [ 5.0000],
        [ 6.2484]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.6786],
        [ 5.9223],
        [ 5.0000],
        [ 7.5334],
        [10.0000],
        [ 6.7132],
        [ 6.4576],
        [ 5.5295],
        [ 5.0168],
        [ 6.4323]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3060],
        [ 5.0000],
        [ 7.6396],
        [ 6.0336],
        [ 8.6890],
        [10.0000],
        [ 5.9848],
        [ 8.5964],
        [ 5.2089],
        [ 6.4805]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[143.4350],
        [140.4452],
        [171.4377],
        [164.6731],
        [143.6295],
        [164.8311],
        [154.9438],
        [150.6461],
        [140.1446],
        [146.3011]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[52.4707],
        [43.9570],
        [35.2751],
        [61.5135],
        [87.1612],
        [52.9096],
        [50.4641],
        [40.5496],
        [35.5651],
        [50.1888]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[107.9722],
        [ 96.9645],
        [118.9615],
        [105.6542],
        [128.2618],
        [139.6925],
        [105.0422],
        [126.8823],
        [ 98.6677],
        [108.3488]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5257],
        [ 5.0480],
        [10.0000],
        [ 8.9192],
        [ 5.5568],
        [ 8.9444],
        [ 7.3646],
        [ 6.6779],
        [ 5.0000],
        [ 5.9837]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.6571],
        [ 5.8366],
        [ 5.0000],
        [ 7.5285],
        [10.0000],
        [ 6.6994],
        [ 6.4637],
        [ 5.5083],
        [ 5.0279],
        [ 6.4372]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.2881],
        [ 5.0000],
        [ 7.5741],
        [ 6.0169],
        [ 8.6624],
        [10.0000],
        [ 5.9452],
        [ 8.5010],
        [ 5.1993],
        [ 6.3322]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.8186],
        [140.0752],
        [164.1332],
        [163.1732],
        [143.1437],
        [162.4871],
        [149.9522],
        [146.4027],
        [140.3378],
        [140.8422]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[51.6863],
        [41.5948],
        [35.9152],
        [61.2310],
        [86.7758],
        [52.3784],
        [50.8182],
        [40.1568],
        [36.7326],
        [50.5822]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[107.5186],
        [ 97.4487],
        [116.5512],
        [105.3063],
        [126.8232],
        [138.7780],
        [103.9714],
        [123.1042],
        [ 98.8019],
        [103.9231]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5702],
        [ 5.0000],
        [10.0000],
        [ 9.8005],
        [ 5.6377],
        [ 9.6579],
        [ 7.0528],
        [ 6.3151],
        [ 5.0546],
        [ 5.1594]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.5504],
        [ 5.5584],
        [ 5.0000],
        [ 7.4887],
        [10.0000],
        [ 6.6185],
        [ 6.4651],
        [ 5.4170],
        [ 5.0804],
        [ 6.4419]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.2183],
        [ 5.0000],
        [ 7.3110],
        [ 5.9506],
        [ 8.5537],
        [10.0000],
        [ 5.7891],
        [ 8.1038],
        [ 5.1637],
        [ 5.7833]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0177],
        [155.9077],
        [161.6030],
        [142.6752],
        [160.0269],
        [145.5652],
        [142.9859],
        [140.6213],
        [140.6295]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[51.0209],
        [41.1658],
        [37.5362],
        [60.9374],
        [86.3538],
        [51.8688],
        [51.2656],
        [40.3040],
        [39.1611],
        [51.2042]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[107.0665],
        [ 97.8796],
        [114.1772],
        [104.9474],
        [125.3382],
        [137.8130],
        [102.9496],
        [119.2271],
        [ 98.9482],
        [100.4808]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5150],
        [ 5.0000],
        [ 8.6807],
        [10.0000],
        [ 5.6156],
        [ 9.6349],
        [ 6.2850],
        [ 5.6876],
        [ 5.1398],
        [ 5.1417]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3811],
        [ 5.3717],
        [ 5.0000],
        [ 7.3968],
        [10.0000],
        [ 6.4680],
        [ 6.4062],
        [ 5.2835],
        [ 5.1664],
        [ 6.3999]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.1503],
        [ 5.0000],
        [ 7.0406],
        [ 5.8849],
        [ 8.4380],
        [10.0000],
        [ 5.6348],
        [ 7.6729],
        [ 5.1338],
        [ 5.3257]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0213],
        [154.8766],
        [161.4543],
        [142.6365],
        [159.7933],
        [145.1716],
        [142.7712],
        [140.5235],
        [140.4776]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.9948],
        [41.3597],
        [37.7917],
        [60.9142],
        [86.3231],
        [51.8334],
        [51.3105],
        [40.3706],
        [39.3881],
        [51.2906]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[107.0377],
        [ 97.9769],
        [113.9317],
        [104.9241],
        [125.2414],
        [137.7229],
        [102.8223],
        [118.8030],
        [ 98.9759],
        [100.4562]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5178],
        [ 5.0000],
        [ 8.4655],
        [10.0000],
        [ 5.6101],
        [ 9.6125],
        [ 6.2015],
        [ 5.6415],
        [ 5.1171],
        [ 5.1064]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3603],
        [ 5.3676],
        [ 5.0000],
        [ 7.3822],
        [10.0000],
        [ 6.4467],
        [ 6.3928],
        [ 5.2657],
        [ 5.1645],
        [ 6.3907]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.1398],
        [ 5.0000],
        [ 7.0071],
        [ 5.8740],
        [ 8.4299],
        [10.0000],
        [ 5.6096],
        [ 7.6199],
        [ 5.1257],
        [ 5.3119]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0393],
        [150.9246],
        [160.8587],
        [142.4844],
        [158.8595],
        [143.7239],
        [141.9875],
        [140.2153],
        [140.0786]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.8935],
        [42.2348],
        [39.0313],
        [60.8209],
        [86.1989],
        [51.6945],
        [51.4976],
        [40.6878],
        [40.4573],
        [51.6636]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[106.9232],
        [ 98.3495],
        [112.9362],
        [104.8311],
        [124.8546],
        [137.3605],
        [102.3399],
        [117.1211],
        [ 99.0948],
        [100.3587]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5288],
        [ 5.0000],
        [ 7.6142],
        [10.0000],
        [ 5.5872],
        [ 9.5199],
        [ 5.8849],
        [ 5.4679],
        [ 5.0423],
        [ 5.0094]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.2575],
        [ 5.3396],
        [ 5.0000],
        [ 7.3098],
        [10.0000],
        [ 6.3424],
        [ 6.3215],
        [ 5.1756],
        [ 5.1512],
        [ 6.3391]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.0989],
        [ 5.0000],
        [ 6.8696],
        [ 5.8307],
        [ 8.3971],
        [10.0000],
        [ 5.5115],
        [ 7.4059],
        [ 5.0955],
        [ 5.2575]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0814],
        [145.3323],
        [159.8672],
        [142.2409],
        [157.3138],
        [141.8053],
        [140.9623],
        [140.0010],
        [140.1630]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.7362],
        [44.0038],
        [41.9146],
        [60.6656],
        [85.9883],
        [51.4742],
        [51.8331],
        [41.3898],
        [42.8216],
        [52.3800]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[106.7338],
        [ 98.9072],
        [111.2476],
        [104.6765],
        [124.2122],
        [136.7516],
        [101.6364],
        [114.3926],
        [ 99.3197],
        [100.1958]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.5638],
        [ 5.0202],
        [ 6.3418],
        [10.0000],
        [ 5.5638],
        [ 9.3574],
        [ 5.4541],
        [ 5.2419],
        [ 5.0000],
        [ 5.0408]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.0478],
        [ 5.2931],
        [ 5.0588],
        [ 7.1610],
        [10.0000],
        [ 6.1306],
        [ 6.1708],
        [ 5.0000],
        [ 5.1605],
        [ 6.2321]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.0340],
        [ 5.0000],
        [ 6.6304],
        [ 5.7622],
        [ 8.3433],
        [10.0000],
        [ 5.3606],
        [ 7.0459],
        [ 5.0545],
        [ 5.1703]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [142.3477],
        [142.8824],
        [146.9794],
        [142.2410],
        [141.0784],
        [142.8824],
        [142.8824],
        [161.2568],
        [162.2381]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.0451],
        [56.4791],
        [56.5652],
        [58.3433],
        [82.5467],
        [49.9515],
        [56.5607],
        [55.5141],
        [56.0096],
        [56.5466]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[104.1564],
        [ 98.4677],
        [ 93.7660],
        [103.1195],
        [115.5408],
        [127.2597],
        [106.7416],
        [102.5607],
        [105.1031],
        [ 98.3557]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.2747],
        [ 5.2999],
        [ 5.4263],
        [ 6.3944],
        [ 5.2747],
        [ 5.0000],
        [ 5.4263],
        [ 5.4263],
        [ 9.7681],
        [10.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0144],
        [ 6.0013],
        [ 6.0145],
        [ 6.2873],
        [10.0000],
        [ 5.0000],
        [ 6.0138],
        [ 5.8533],
        [ 5.9293],
        [ 6.0117]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.5511],
        [ 5.7019],
        [ 5.0000],
        [ 6.3963],
        [ 8.2506],
        [10.0000],
        [ 6.9370],
        [ 6.3129],
        [ 6.6924],
        [ 5.6852]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.7118],
        [140.3017],
        [153.7346],
        [142.2409],
        [148.2795],
        [140.0001],
        [140.0466],
        [144.9681],
        [146.3360]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.0962],
        [51.2891],
        [53.2244],
        [59.6419],
        [84.5695],
        [50.4163],
        [53.6206],
        [47.4675],
        [53.4100],
        [54.0083]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[105.5524],
        [100.4945],
        [101.0967],
        [103.9904],
        [120.3058],
        [132.6752],
        [100.4728],
        [100.6273],
        [101.2908],
        [ 97.8751]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.8158],
        [ 5.2591],
        [ 5.1098],
        [10.0000],
        [ 5.8158],
        [ 8.0141],
        [ 5.0000],
        [ 5.0169],
        [ 6.8086],
        [ 7.3066]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3543],
        [ 5.5150],
        [ 5.7758],
        [ 6.6407],
        [10.0000],
        [ 5.3974],
        [ 5.8292],
        [ 5.0000],
        [ 5.8008],
        [ 5.8815]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.1031],
        [ 5.3763],
        [ 5.4629],
        [ 5.8786],
        [ 8.2228],
        [10.0000],
        [ 5.3732],
        [ 5.3954],
        [ 5.4908],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [141.4873],
        [141.4835],
        [149.2931],
        [142.2409],
        [142.9106],
        [140.1600],
        [140.0393],
        [148.0484],
        [146.9166]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[49.9663],
        [49.3921],
        [49.8927],
        [58.7976],
        [83.3978],
        [50.0097],
        [51.4047],
        [49.9998],
        [52.6244],
        [53.9234]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[104.6912],
        [ 98.1730],
        [ 95.0056],
        [103.4943],
        [117.6283],
        [129.0058],
        [ 99.2930],
        [ 98.1684],
        [101.0617],
        [ 97.3954]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.1896],
        [ 5.7824],
        [ 5.7803],
        [10.0000],
        [ 6.1896],
        [ 6.5514],
        [ 5.0652],
        [ 5.0000],
        [ 9.3274],
        [ 8.7159]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0844],
        [ 5.0000],
        [ 5.0736],
        [ 6.3829],
        [10.0000],
        [ 5.0908],
        [ 5.2959],
        [ 5.0893],
        [ 5.4753],
        [ 5.6662]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.4243],
        [ 5.4658],
        [ 5.0000],
        [ 6.2483],
        [ 8.3268],
        [10.0000],
        [ 5.6305],
        [ 5.4651],
        [ 5.8906],
        [ 5.3514]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [141.0314],
        [140.7319],
        [151.6449],
        [142.2409],
        [145.5437],
        [140.0356],
        [140.0006],
        [146.2987],
        [146.5983]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.0119],
        [50.2743],
        [51.1401],
        [59.2578],
        [84.0467],
        [50.1849],
        [52.4918],
        [48.6908],
        [53.0758],
        [53.9697]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[105.1572],
        [ 99.5422],
        [ 97.7284],
        [103.7649],
        [119.0787],
        [131.0197],
        [ 99.7192],
        [ 99.0032],
        [101.1456],
        [ 97.4766]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 5.9620],
        [ 5.4426],
        [ 5.3140],
        [10.0000],
        [ 5.9620],
        [ 7.3802],
        [ 5.0150],
        [ 5.0000],
        [ 7.7044],
        [ 7.8330]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.1868],
        [ 5.2239],
        [ 5.3464],
        [ 6.4944],
        [10.0000],
        [ 5.2113],
        [ 5.5375],
        [ 5.0000],
        [ 5.6201],
        [ 5.7465]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.1449],
        [ 5.3079],
        [ 5.0375],
        [ 5.9373],
        [ 8.2201],
        [10.0000],
        [ 5.3343],
        [ 5.2276],
        [ 5.5469],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.4118],
        [140.6023],
        [149.7847],
        [142.2409],
        [143.3671],
        [140.0169],
        [140.2552],
        [142.6454],
        [142.3261]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[49.9872],
        [49.7055],
        [49.9270],
        [58.8903],
        [83.6036],
        [50.0424],
        [51.1282],
        [47.6740],
        [51.7868],
        [53.7138]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[104.8218],
        [ 98.7524],
        [ 96.1149],
        [103.5357],
        [118.2045],
        [129.2165],
        [ 98.4035],
        [ 98.5635],
        [ 99.8955],
        [ 97.4169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.1385],
        [ 5.2021],
        [ 5.2997],
        [10.0000],
        [ 6.1385],
        [ 6.7149],
        [ 5.0000],
        [ 5.1220],
        [ 6.3455],
        [ 6.1821]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3219],
        [ 5.2827],
        [ 5.3135],
        [ 6.5609],
        [10.0000],
        [ 5.3296],
        [ 5.4807],
        [ 5.0000],
        [ 5.5723],
        [ 5.8405]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3152],
        [ 5.3984],
        [ 5.0000],
        [ 6.1209],
        [ 8.3366],
        [10.0000],
        [ 5.3457],
        [ 5.3699],
        [ 5.5711],
        [ 5.1967]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0403],
        [140.0509],
        [147.7263],
        [142.2409],
        [141.4721],
        [140.0014],
        [140.4591],
        [140.0905],
        [140.1158]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[49.9941],
        [48.9786],
        [49.2366],
        [58.4894],
        [83.1950],
        [49.9503],
        [50.4510],
        [46.1677],
        [49.5282],
        [52.4025]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[104.5195],
        [ 98.2029],
        [ 96.4783],
        [103.2319],
        [117.6098],
        [126.6357],
        [ 96.8539],
        [ 99.6178],
        [ 98.1120],
        [ 97.2509]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 6.4496],
        [ 5.0252],
        [ 5.0321],
        [10.0000],
        [ 6.4496],
        [ 5.9520],
        [ 5.0000],
        [ 5.2963],
        [ 5.0577],
        [ 5.0741]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5167],
        [ 5.3796],
        [ 5.4144],
        [ 6.6639],
        [10.0000],
        [ 5.5108],
        [ 5.5784],
        [ 5.0000],
        [ 5.4538],
        [ 5.8419]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.3332],
        [ 5.2859],
        [ 5.0000],
        [ 6.1197],
        [ 8.5035],
        [10.0000],
        [ 5.0623],
        [ 5.5205],
        [ 5.2709],
        [ 5.1281]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0623],
        [140.0818],
        [145.0389],
        [142.2410],
        [140.1218],
        [140.0296],
        [140.1297],
        [140.0121],
        [140.0152]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[49.9693],
        [49.5873],
        [49.7670],
        [57.9184],
        [82.4378],
        [49.9599],
        [50.6676],
        [47.0609],
        [49.8848],
        [51.8736]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[103.9689],
        [ 97.7229],
        [ 95.7608],
        [102.9664],
        [116.1306],
        [123.2452],
        [ 97.0119],
        [ 98.3839],
        [ 97.9043],
        [ 96.7907]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 7.2171],
        [ 5.0500],
        [ 5.0694],
        [10.0000],
        [ 7.2170],
        [ 5.1092],
        [ 5.0175],
        [ 5.1170],
        [ 5.0000],
        [ 5.0031]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4111],
        [ 5.3571],
        [ 5.3825],
        [ 6.5345],
        [10.0000],
        [ 5.4097],
        [ 5.5097],
        [ 5.0000],
        [ 5.3991],
        [ 5.6802]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.4932],
        [ 5.3570],
        [ 5.0000],
        [ 6.3108],
        [ 8.7057],
        [10.0000],
        [ 5.2276],
        [ 5.4772],
        [ 5.3899],
        [ 5.1874]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0186],
        [140.0500],
        [140.8753],
        [142.2410],
        [141.2853],
        [140.0352],
        [140.1245],
        [140.3465],
        [140.4010]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[49.9912],
        [50.4094],
        [50.2624],
        [56.7269],
        [80.9266],
        [50.5813],
        [51.0054],
        [47.5325],
        [50.0310],
        [50.9598]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[102.8509],
        [ 97.0277],
        [ 95.5540],
        [102.4292],
        [113.5199],
        [114.8379],
        [ 96.7458],
        [ 97.5358],
        [ 97.2096],
        [ 96.5755]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0000],
        [ 5.0706],
        [ 6.9273],
        [ 9.9998],
        [ 7.8497],
        [ 5.0374],
        [ 5.2384],
        [ 5.7377],
        [ 5.8604]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3681],
        [ 5.4307],
        [ 5.4087],
        [ 6.3766],
        [10.0000],
        [ 5.4565],
        [ 5.5200],
        [ 5.0000],
        [ 5.3741],
        [ 5.5132]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.8920],
        [ 5.3821],
        [ 5.0000],
        [ 6.7826],
        [ 9.6583],
        [10.0000],
        [ 5.3090],
        [ 5.5139],
        [ 5.4293],
        [ 5.2649]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0454],
        [140.0706],
        [143.3493],
        [142.2410],
        [140.0174],
        [140.0031],
        [140.0166],
        [140.0701],
        [140.0833]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[49.9700],
        [49.9080],
        [49.9155],
        [57.5343],
        [81.9607],
        [50.0704],
        [50.7694],
        [47.2131],
        [49.9711],
        [51.5468]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[103.6086],
        [ 97.4978],
        [ 95.6892],
        [102.7947],
        [115.2795],
        [120.4905],
        [ 96.9251],
        [ 98.0791],
        [ 97.6803],
        [ 96.6936]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 8.3440],
        [ 5.0632],
        [ 5.1009],
        [10.0000],
        [ 8.3438],
        [ 5.0214],
        [ 5.0000],
        [ 5.0202],
        [ 5.1001],
        [ 5.1198]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3967],
        [ 5.3878],
        [ 5.3889],
        [ 6.4852],
        [10.0000],
        [ 5.4111],
        [ 5.5117],
        [ 5.0000],
        [ 5.3969],
        [ 5.6236]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.5966],
        [ 5.3646],
        [ 5.0000],
        [ 6.4325],
        [ 8.9495],
        [10.0000],
        [ 5.2492],
        [ 5.4818],
        [ 5.4014],
        [ 5.2025]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.1886],
        [140.0128],
        [142.8827],
        [142.2410],
        [142.8824],
        [140.1352],
        [141.6156],
        [140.0000],
        [140.0052]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1931],
        [50.8462],
        [51.3683],
        [53.9939],
        [77.2751],
        [54.8685],
        [51.3438],
        [47.4705],
        [50.0364],
        [50.0085]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.3293],
        [ 95.6100],
        [ 95.6926],
        [101.1307],
        [108.1334],
        [ 99.7598],
        [ 95.7534],
        [ 96.5003],
        [ 95.1514],
        [ 97.3041]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 8.8871],
        [ 5.3272],
        [ 5.0222],
        [10.0000],
        [ 8.8870],
        [ 9.9996],
        [ 5.2345],
        [ 7.8022],
        [ 5.0000],
        [ 5.0091]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4568],
        [ 5.5663],
        [ 5.6539],
        [ 6.0944],
        [10.0000],
        [ 6.2411],
        [ 5.6498],
        [ 5.0000],
        [ 5.4305],
        [ 5.4258]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.9943],
        [ 5.1766],
        [ 5.2085],
        [ 7.3029],
        [10.0000],
        [ 6.7750],
        [ 5.2319],
        [ 5.5196],
        [ 5.0000],
        [ 5.8291]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0002],
        [140.0163],
        [140.3176],
        [142.2410],
        [140.4957],
        [140.0095],
        [140.1437],
        [140.0268],
        [140.0247]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.0063],
        [50.4186],
        [50.3166],
        [56.2580],
        [80.3499],
        [51.0380],
        [50.9592],
        [47.3060],
        [49.9310],
        [50.5806]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[102.4250],
        [ 96.7709],
        [ 95.6535],
        [102.2069],
        [112.6166],
        [111.5120],
        [ 96.4288],
        [ 97.3997],
        [ 96.7278],
        [ 96.6371]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0000],
        [ 5.0361],
        [ 5.7083],
        [ 9.9998],
        [ 6.1057],
        [ 5.0207],
        [ 5.3203],
        [ 5.0593],
        [ 5.0547]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4086],
        [ 5.4710],
        [ 5.4555],
        [ 6.3546],
        [10.0000],
        [ 5.5647],
        [ 5.5528],
        [ 5.0000],
        [ 5.3972],
        [ 5.4955]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.9960],
        [ 5.3294],
        [ 5.0000],
        [ 6.9317],
        [10.0000],
        [ 9.6744],
        [ 5.2285],
        [ 5.5147],
        [ 5.3167],
        [ 5.2899]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.2553],
        [140.3968],
        [142.8827],
        [142.2410],
        [140.0105],
        [140.0071],
        [141.4341],
        [140.1711],
        [140.0883]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.4479],
        [51.4679],
        [56.2388],
        [51.0240],
        [73.3833],
        [56.5515],
        [52.9597],
        [46.5058],
        [50.1408],
        [51.3568]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 97.6368],
        [ 95.2380],
        [ 98.3255],
        [ 99.4589],
        [103.3470],
        [ 99.8530],
        [ 96.1515],
        [ 95.6898],
        [ 93.8813],
        [101.5490]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[ 8.8844],
        [ 5.4315],
        [ 5.6775],
        [10.0000],
        [ 8.8842],
        [ 5.0058],
        [ 5.0000],
        [ 7.4812],
        [ 5.2851],
        [ 5.1411]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.7333],
        [ 5.9231],
        [ 6.8106],
        [ 5.8405],
        [10.0000],
        [ 6.8688],
        [ 6.2006],
        [ 5.0000],
        [ 5.6762],
        [ 5.9024]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.9837],
        [ 5.7167],
        [ 7.3476],
        [ 7.9462],
        [10.0000],
        [ 8.1544],
        [ 6.1992],
        [ 5.9553],
        [ 5.0000],
        [ 9.0503]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0150],
        [140.0550],
        [140.0066],
        [142.2410],
        [140.3333],
        [140.0090],
        [140.3062],
        [140.0469],
        [140.0349]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.0586],
        [50.7211],
        [51.0293],
        [55.1454],
        [78.9648],
        [51.8441],
        [51.2945],
        [47.1372],
        [49.9523],
        [50.1241]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[101.3965],
        [ 96.3787],
        [ 96.1112],
        [101.6395],
        [110.5198],
        [104.5644],
        [ 96.1898],
        [ 97.0043],
        [ 96.0384],
        [ 97.1136]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0188],
        [ 5.1084],
        [ 5.0000],
        [ 9.9998],
        [ 5.7312],
        [ 5.0054],
        [ 5.6705],
        [ 5.0902],
        [ 5.0634]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4589],
        [ 5.5630],
        [ 5.6114],
        [ 6.2580],
        [10.0000],
        [ 5.7394],
        [ 5.6531],
        [ 5.0000],
        [ 5.4422],
        [ 5.4692]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.8500],
        [ 5.1175],
        [ 5.0251],
        [ 6.9339],
        [10.0000],
        [ 7.9438],
        [ 5.0523],
        [ 5.3335],
        [ 5.0000],
        [ 5.3712]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.2332],
        [142.1340],
        [141.4686],
        [142.2410],
        [140.2123],
        [140.4604],
        [140.1895],
        [140.0760],
        [140.1598]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.5414],
        [52.2388],
        [55.6752],
        [50.2924],
        [72.4693],
        [56.3784],
        [52.9370],
        [48.0196],
        [50.0126],
        [50.7532]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.8622],
        [ 94.8470],
        [ 96.8214],
        [ 98.7780],
        [102.2285],
        [100.5320],
        [ 95.8276],
        [ 95.7199],
        [ 93.8539],
        [100.1354]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.3630],
        [ 9.7527],
        [ 8.2161],
        [ 9.9998],
        [ 5.3146],
        [ 5.8878],
        [ 5.2621],
        [ 5.0000],
        [ 5.1935]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5157],
        [ 5.8628],
        [ 6.5656],
        [ 5.4648],
        [10.0000],
        [ 6.7094],
        [ 6.0056],
        [ 5.0000],
        [ 5.4076],
        [ 5.5590]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.7960],
        [ 5.5929],
        [ 6.7717],
        [ 7.9399],
        [10.0000],
        [ 8.9871],
        [ 6.1784],
        [ 6.1141],
        [ 5.0000],
        [ 8.7503]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0005],
        [140.0010],
        [140.0155],
        [142.2410],
        [140.1709],
        [140.0351],
        [140.2859],
        [140.0510],
        [140.0487]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1073],
        [50.9535],
        [51.5422],
        [54.3708],
        [77.9879],
        [52.3981],
        [51.5121],
        [47.2708],
        [49.9700],
        [50.0240]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.6589],
        [ 96.0920],
        [ 96.2085],
        [101.1929],
        [109.1084],
        [101.2268],
        [ 96.0709],
        [ 96.7649],
        [ 95.6572],
        [ 97.4191]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0000],
        [ 5.0011],
        [ 5.0335],
        [ 9.9998],
        [ 5.3803],
        [ 5.0772],
        [ 5.6369],
        [ 5.1128],
        [ 5.1075]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4617],
        [ 5.5995],
        [ 5.6953],
        [ 6.1557],
        [10.0000],
        [ 5.8346],
        [ 5.6904],
        [ 5.0000],
        [ 5.4394],
        [ 5.4481]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.8592],
        [ 5.1616],
        [ 5.2049],
        [ 7.0577],
        [10.0000],
        [ 7.0703],
        [ 5.1538],
        [ 5.4117],
        [ 5.0000],
        [ 5.6549]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0025],
        [140.6144],
        [140.0019],
        [142.2410],
        [140.1654],
        [140.1295],
        [140.0015],
        [140.0099],
        [140.0119]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.2145],
        [51.3131],
        [53.9773],
        [52.0847],
        [75.1940],
        [52.7830],
        [52.5134],
        [47.0340],
        [50.0877],
        [50.0615]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 98.4209],
        [ 95.8337],
        [ 97.4333],
        [ 99.6556],
        [105.4445],
        [ 96.5256],
        [ 96.3067],
        [ 96.5078],
        [ 95.0135],
        [ 99.0296]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0024],
        [ 6.3683],
        [ 5.0009],
        [ 9.9998],
        [ 5.3661],
        [ 5.2859],
        [ 5.0000],
        [ 5.0187],
        [ 5.0232]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5647],
        [ 5.7598],
        [ 6.2328],
        [ 5.8968],
        [10.0000],
        [ 6.0208],
        [ 5.9729],
        [ 5.0000],
        [ 5.5422],
        [ 5.5375]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.6333],
        [ 5.3931],
        [ 6.1599],
        [ 7.2251],
        [10.0000],
        [ 5.7248],
        [ 5.6199],
        [ 5.7163],
        [ 5.0000],
        [ 6.9251]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [139.9998],
        [140.0338],
        [140.0063],
        [142.2410],
        [140.0376],
        [140.0016],
        [140.1448],
        [140.0369],
        [140.0364]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1331],
        [51.0563],
        [52.0939],
        [53.7565],
        [77.2544],
        [52.4991],
        [51.7567],
        [47.2070],
        [49.9972],
        [50.0004]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[100.0537],
        [ 96.0146],
        [ 96.5235],
        [100.7837],
        [108.1004],
        [ 99.1851],
        [ 96.1024],
        [ 96.6909],
        [ 95.4644],
        [ 97.7966]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0000],
        [ 5.0760],
        [ 5.0146],
        [ 9.9998],
        [ 5.0843],
        [ 5.0041],
        [ 5.3234],
        [ 5.0828],
        [ 5.0817]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4869],
        [ 5.6405],
        [ 5.8132],
        [ 6.0899],
        [10.0000],
        [ 5.8806],
        [ 5.7571],
        [ 5.0000],
        [ 5.4643],
        [ 5.4648]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.8160],
        [ 5.2177],
        [ 5.4191],
        [ 7.1048],
        [10.0000],
        [ 6.4723],
        [ 5.2525],
        [ 5.4853],
        [ 5.0000],
        [ 5.9228]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0024],
        [140.0021],
        [140.0032],
        [142.2410],
        [140.0157],
        [140.0000],
        [140.1354],
        [140.0241],
        [140.0139]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1841],
        [51.5011],
        [53.0089],
        [52.2899],
        [75.6289],
        [52.0886],
        [52.1187],
        [47.4612],
        [50.3150],
        [50.0218]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 98.5654],
        [ 95.7958],
        [ 96.5047],
        [ 99.5838],
        [105.8996],
        [ 96.3338],
        [ 96.1224],
        [ 96.4976],
        [ 95.3482],
        [ 98.0699]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0054],
        [ 5.0046],
        [ 5.0071],
        [ 9.9998],
        [ 5.0350],
        [ 5.0000],
        [ 5.3021],
        [ 5.0538],
        [ 5.0309]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4833],
        [ 5.7171],
        [ 5.9848],
        [ 5.8571],
        [10.0000],
        [ 5.8214],
        [ 5.8267],
        [ 5.0000],
        [ 5.5066],
        [ 5.4545]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.5245],
        [ 5.2121],
        [ 5.5480],
        [ 7.0071],
        [10.0000],
        [ 5.4670],
        [ 5.3669],
        [ 5.5446],
        [ 5.0000],
        [ 6.2897]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0169],
        [139.9998],
        [140.0201],
        [142.2410],
        [140.0193],
        [140.0204],
        [140.1152],
        [140.0020],
        [140.0022]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.2205],
        [51.6169],
        [52.9239],
        [51.3045],
        [74.6212],
        [52.0415],
        [52.0021],
        [47.7382],
        [50.7462],
        [50.1435]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 97.5489],
        [ 95.5309],
        [ 95.9230],
        [ 98.6023],
        [104.5324],
        [ 95.5764],
        [ 95.9403],
        [ 96.2502],
        [ 95.3120],
        [ 97.6725]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0381],
        [ 5.0000],
        [ 5.0452],
        [ 9.9998],
        [ 5.0434],
        [ 5.0458],
        [ 5.2573],
        [ 5.0047],
        [ 5.0054]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4617],
        [ 5.7214],
        [ 5.9645],
        [ 5.6633],
        [10.0000],
        [ 5.8004],
        [ 5.7930],
        [ 5.0000],
        [ 5.5595],
        [ 5.4474]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 6.2130],
        [ 5.1187],
        [ 5.3313],
        [ 6.7842],
        [10.0000],
        [ 5.1434],
        [ 5.3407],
        [ 5.5088],
        [ 5.0000],
        [ 6.2800]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0006],
        [140.0028],
        [140.0356],
        [142.2410],
        [140.2714],
        [140.0020],
        [140.0014],
        [140.0085],
        [139.9999]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1928],
        [51.8815],
        [52.2440],
        [49.8220],
        [73.5934],
        [51.3873],
        [51.5388],
        [48.1854],
        [52.8244],
        [51.4240]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.9160],
        [ 95.4070],
        [ 95.1254],
        [ 96.5378],
        [102.9388],
        [ 94.9456],
        [ 95.7034],
        [ 95.9248],
        [ 95.8620],
        [ 96.5190]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0016],
        [ 5.0064],
        [ 5.0796],
        [ 9.9998],
        [ 5.6057],
        [ 5.0048],
        [ 5.0034],
        [ 5.0191],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3950],
        [ 5.7274],
        [ 5.7987],
        [ 5.3221],
        [10.0000],
        [ 5.6301],
        [ 5.6599],
        [ 5.0000],
        [ 5.9129],
        [ 5.6373]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6071],
        [ 5.2886],
        [ 5.1125],
        [ 5.9960],
        [10.0000],
        [ 5.0000],
        [ 5.4740],
        [ 5.6125],
        [ 5.5732],
        [ 5.9842]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0089],
        [139.9999],
        [140.0250],
        [142.2410],
        [140.0740],
        [140.0119],
        [140.0554],
        [139.9999],
        [140.0011]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.2106],
        [51.7072],
        [52.6779],
        [50.7859],
        [74.2649],
        [51.8004],
        [51.8344],
        [47.8937],
        [51.3249],
        [50.4412]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.9632],
        [ 95.4651],
        [ 95.5810],
        [ 97.8646],
        [103.9699],
        [ 95.3313],
        [ 95.8458],
        [ 96.1321],
        [ 95.4759],
        [ 97.1888]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0202],
        [ 5.0001],
        [ 5.0560],
        [ 9.9998],
        [ 5.1653],
        [ 5.0268],
        [ 5.1238],
        [ 5.0000],
        [ 5.0027]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4393],
        [ 5.7230],
        [ 5.9071],
        [ 5.5484],
        [10.0000],
        [ 5.7407],
        [ 5.7471],
        [ 5.0000],
        [ 5.6506],
        [ 5.4830]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.9445],
        [ 5.0774],
        [ 5.1445],
        [ 6.4663],
        [10.0000],
        [ 5.0000],
        [ 5.2978],
        [ 5.4635],
        [ 5.0837],
        [ 6.0751]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0062],
        [140.0388],
        [140.4953],
        [142.2410],
        [140.4370],
        [140.0392],
        [140.0896],
        [140.0069],
        [140.0001]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1872],
        [51.6774],
        [51.1356],
        [48.2628],
        [72.5191],
        [51.5557],
        [50.9111],
        [48.5146],
        [53.7256],
        [52.6160]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 94.3547],
        [ 95.1230],
        [ 94.6831],
        [ 94.4501],
        [101.2925],
        [ 94.7378],
        [ 95.3403],
        [ 95.5036],
        [ 95.8330],
        [ 95.8799]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0135],
        [ 5.0864],
        [ 6.1050],
        [ 9.9998],
        [ 5.9747],
        [ 5.0872],
        [ 5.1997],
        [ 5.0153],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3967],
        [ 5.7039],
        [ 5.5922],
        [ 5.0000],
        [10.0000],
        [ 5.6788],
        [ 5.5459],
        [ 5.0519],
        [ 6.1261],
        [ 5.8973]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.5537],
        [ 5.2367],
        [ 5.0687],
        [10.0000],
        [ 5.2761],
        [ 5.7103],
        [ 5.8280],
        [ 6.0653],
        [ 6.0992]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0085],
        [140.0011],
        [140.0526],
        [142.2410],
        [140.0225],
        [140.0146],
        [140.0594],
        [139.9999],
        [140.0006]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.2075],
        [51.7035],
        [52.4419],
        [50.4516],
        [74.0387],
        [51.7676],
        [51.6965],
        [47.9755],
        [51.5731],
        [50.6244]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.5926],
        [ 95.3977],
        [ 95.3863],
        [ 97.3765],
        [103.6079],
        [ 95.2384],
        [ 95.7630],
        [ 96.0391],
        [ 95.4985],
        [ 96.8855]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0192],
        [ 5.0026],
        [ 5.1175],
        [ 9.9998],
        [ 5.0503],
        [ 5.0327],
        [ 5.1326],
        [ 5.0000],
        [ 5.0015]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4282],
        [ 5.7152],
        [ 5.8568],
        [ 5.4750],
        [10.0000],
        [ 5.7275],
        [ 5.7138],
        [ 5.0000],
        [ 5.6902],
        [ 5.5082]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.8090],
        [ 5.0952],
        [ 5.0884],
        [ 6.2774],
        [10.0000],
        [ 5.0000],
        [ 5.3134],
        [ 5.4784],
        [ 5.1554],
        [ 5.9840]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0035],
        [140.0045],
        [140.0743],
        [142.2410],
        [140.0130],
        [140.0011],
        [139.9998],
        [140.0019],
        [140.0005]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1686],
        [51.5967],
        [51.3602],
        [48.3571],
        [72.6933],
        [51.3840],
        [51.0488],
        [48.1917],
        [52.7189],
        [51.6905]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 94.4426],
        [ 95.1987],
        [ 94.9404],
        [ 94.4507],
        [101.4890],
        [ 94.8924],
        [ 95.3893],
        [ 95.5856],
        [ 95.5525],
        [ 95.7879]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0083],
        [ 5.0104],
        [ 5.1663],
        [ 9.9998],
        [ 5.0294],
        [ 5.0029],
        [ 5.0000],
        [ 5.0047],
        [ 5.0015]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4034],
        [ 5.6949],
        [ 5.6466],
        [ 5.0338],
        [10.0000],
        [ 5.6515],
        [ 5.5830],
        [ 5.0000],
        [ 5.9239],
        [ 5.7140]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.5365],
        [ 5.3532],
        [ 5.0057],
        [10.0000],
        [ 5.3191],
        [ 5.6718],
        [ 5.8110],
        [ 5.7875],
        [ 5.9546]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0078],
        [140.0014],
        [140.0549],
        [142.2410],
        [140.0213],
        [140.0123],
        [140.0462],
        [140.0000],
        [140.0003]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.2029],
        [51.6913],
        [52.3044],
        [50.2108],
        [73.8870],
        [51.7219],
        [51.6156],
        [48.0002],
        [51.6883],
        [50.7198]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.3292],
        [ 95.3663],
        [ 95.3133],
        [ 97.0147],
        [103.3605],
        [ 95.1904],
        [ 95.7152],
        [ 95.9833],
        [ 95.4928],
        [ 96.7052]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0175],
        [ 5.0031],
        [ 5.1224],
        [ 9.9998],
        [ 5.0475],
        [ 5.0274],
        [ 5.1031],
        [ 5.0000],
        [ 5.0006]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4254],
        [ 5.7129],
        [ 5.8313],
        [ 5.4270],
        [10.0000],
        [ 5.7188],
        [ 5.6983],
        [ 5.0000],
        [ 5.7124],
        [ 5.5253]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6970],
        [ 5.1077],
        [ 5.0752],
        [ 6.1165],
        [10.0000],
        [ 5.0000],
        [ 5.3212],
        [ 5.4852],
        [ 5.1851],
        [ 5.9271]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0048],
        [140.0033],
        [140.0674],
        [142.2410],
        [140.0156],
        [140.0036],
        [140.0044],
        [140.0010],
        [139.9998]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1799],
        [51.6287],
        [51.6548],
        [48.9813],
        [73.1005],
        [51.4950],
        [51.2283],
        [48.1269],
        [52.3430],
        [51.3163]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0478],
        [ 95.2402],
        [ 95.0275],
        [ 95.2639],
        [102.1127],
        [ 94.9793],
        [ 95.4911],
        [ 95.7133],
        [ 95.5111],
        [ 96.0009]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0111],
        [ 5.0076],
        [ 5.1507],
        [ 9.9998],
        [ 5.0351],
        [ 5.0084],
        [ 5.0101],
        [ 5.0027],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4110],
        [ 5.7011],
        [ 5.7063],
        [ 5.1711],
        [10.0000],
        [ 5.6743],
        [ 5.6209],
        [ 5.0000],
        [ 5.8441],
        [ 5.6386]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0480],
        [ 5.1829],
        [ 5.0338],
        [ 5.1995],
        [10.0000],
        [ 5.0000],
        [ 5.3588],
        [ 5.5144],
        [ 5.3727],
        [ 5.7161]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0003],
        [140.0037],
        [140.0695],
        [142.2410],
        [139.9997],
        [140.0190],
        [140.0022],
        [140.0572],
        [140.0003]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1629],
        [51.4416],
        [50.9411],
        [45.7927],
        [70.7606],
        [51.2675],
        [50.8285],
        [48.2050],
        [52.9113],
        [52.1022]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[92.3980],
        [95.0455],
        [94.8629],
        [91.8637],
        [98.8796],
        [94.6835],
        [95.1171],
        [95.1231],
        [95.3205],
        [95.4269]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0011],
        [ 5.0087],
        [ 5.1556],
        [ 9.9998],
        [ 5.0000],
        [ 5.0430],
        [ 5.0054],
        [ 5.1282],
        [ 5.0012]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.8752],
        [ 6.1312],
        [ 6.0310],
        [ 5.0000],
        [10.0000],
        [ 6.0964],
        [ 6.0084],
        [ 5.4831],
        [ 6.4255],
        [ 6.2635]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.3808],
        [ 7.2676],
        [ 7.1375],
        [ 5.0000],
        [10.0000],
        [ 7.0096],
        [ 7.3186],
        [ 7.3229],
        [ 7.4636],
        [ 7.5394]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0065],
        [140.0018],
        [140.0578],
        [142.2410],
        [140.0186],
        [140.0103],
        [140.0320],
        [139.9999],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1966],
        [51.6696],
        [52.1083],
        [49.7992],
        [73.6193],
        [51.6577],
        [51.5017],
        [48.0333],
        [51.8524],
        [50.8662]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8942],
        [ 95.3190],
        [ 95.2178],
        [ 96.4169],
        [102.9353],
        [ 95.1202],
        [ 95.6426],
        [ 95.8910],
        [ 95.4758],
        [ 96.4552]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0147],
        [ 5.0042],
        [ 5.1292],
        [ 9.9998],
        [ 5.0417],
        [ 5.0232],
        [ 5.0717],
        [ 5.0000],
        [ 5.0002]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4228],
        [ 5.7106],
        [ 5.7963],
        [ 5.3451],
        [10.0000],
        [ 5.7083],
        [ 5.6778],
        [ 5.0000],
        [ 5.7463],
        [ 5.5536]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4952],
        [ 5.1272],
        [ 5.0624],
        [ 5.8296],
        [10.0000],
        [ 5.0000],
        [ 5.3343],
        [ 5.4932],
        [ 5.2275],
        [ 5.8542]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0070],
        [140.0017],
        [140.0575],
        [142.2410],
        [140.0198],
        [140.0101],
        [140.0335],
        [140.0001],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1977],
        [51.6765],
        [52.1499],
        [49.9233],
        [73.7037],
        [51.6701],
        [51.5247],
        [48.0281],
        [51.8242],
        [50.8373]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0208],
        [ 95.3319],
        [ 95.2362],
        [ 96.5912],
        [103.0656],
        [ 95.1372],
        [ 95.6608],
        [ 95.9180],
        [ 95.4875],
        [ 96.5126]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0157],
        [ 5.0039],
        [ 5.1283],
        [ 9.9998],
        [ 5.0441],
        [ 5.0225],
        [ 5.0746],
        [ 5.0002],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4225],
        [ 5.7105],
        [ 5.8027],
        [ 5.3691],
        [10.0000],
        [ 5.7092],
        [ 5.6809],
        [ 5.0000],
        [ 5.7392],
        [ 5.5471]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5573],
        [ 5.1228],
        [ 5.0625],
        [ 5.9170],
        [10.0000],
        [ 5.0000],
        [ 5.3303],
        [ 5.4924],
        [ 5.2209],
        [ 5.8674]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0101],
        [140.0337],
        [140.0001],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6777],
        [52.1570],
        [49.9445],
        [73.7181],
        [51.6722],
        [51.5286],
        [48.0273],
        [51.8194],
        [50.8325]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0425],
        [ 95.3342],
        [ 95.2394],
        [ 96.6211],
        [103.0878],
        [ 95.1401],
        [ 95.6640],
        [ 95.9227],
        [ 95.4896],
        [ 96.5225]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1282],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0752],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4225],
        [ 5.7105],
        [ 5.8037],
        [ 5.3731],
        [10.0000],
        [ 5.7094],
        [ 5.6814],
        [ 5.0000],
        [ 5.7380],
        [ 5.5460]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5677],
        [ 5.1221],
        [ 5.0625],
        [ 5.9317],
        [10.0000],
        [ 5.0000],
        [ 5.3296],
        [ 5.4923],
        [ 5.2199],
        [ 5.8697]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0101],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6779],
        [52.1583],
        [49.9482],
        [73.7206],
        [51.6726],
        [51.5293],
        [48.0271],
        [51.8185],
        [50.8316]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0463],
        [ 95.3346],
        [ 95.2399],
        [ 96.6263],
        [103.0917],
        [ 95.1406],
        [ 95.6645],
        [ 95.9235],
        [ 95.4899],
        [ 96.5242]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8039],
        [ 5.3738],
        [10.0000],
        [ 5.7094],
        [ 5.6815],
        [ 5.0000],
        [ 5.7378],
        [ 5.5458]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5695],
        [ 5.1220],
        [ 5.0625],
        [ 5.9343],
        [10.0000],
        [ 5.0000],
        [ 5.3295],
        [ 5.4923],
        [ 5.2197],
        [ 5.8701]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9488],
        [73.7210],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8315]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0470],
        [ 95.3346],
        [ 95.2400],
        [ 96.6272],
        [103.0924],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5245]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9347],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9489],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8315]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9489],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0071],
        [140.0017],
        [140.0574],
        [142.2410],
        [140.0200],
        [140.0100],
        [140.0337],
        [140.0002],
        [140.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1979],
        [51.6780],
        [52.1585],
        [49.9490],
        [73.7211],
        [51.6726],
        [51.5294],
        [48.0271],
        [51.8184],
        [50.8314]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 96.0471],
        [ 95.3346],
        [ 95.2401],
        [ 96.6274],
        [103.0925],
        [ 95.1407],
        [ 95.6646],
        [ 95.9236],
        [ 95.4900],
        [ 96.5246]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0159],
        [ 5.0039],
        [ 5.1281],
        [ 9.9998],
        [ 5.0446],
        [ 5.0224],
        [ 5.0753],
        [ 5.0003],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4224],
        [ 5.7105],
        [ 5.8040],
        [ 5.3740],
        [10.0000],
        [ 5.7094],
        [ 5.6816],
        [ 5.0000],
        [ 5.7378],
        [ 5.5457]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.5699],
        [ 5.1219],
        [ 5.0625],
        [ 5.9348],
        [10.0000],
        [ 5.0000],
        [ 5.3294],
        [ 5.4923],
        [ 5.2196],
        [ 5.8702]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0039],
        [140.0021],
        [140.0440],
        [142.2410],
        [140.0079],
        [140.0039],
        [140.0135],
        [140.0015],
        [140.0010]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1951],
        [51.6410],
        [52.0913],
        [49.7825],
        [73.6205],
        [51.6484],
        [51.4982],
        [48.0183],
        [51.7635],
        [50.8182]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.8705],
        [ 95.3133],
        [ 95.2322],
        [ 96.3693],
        [102.9255],
        [ 95.1434],
        [ 95.6396],
        [ 95.8865],
        [ 95.4424],
        [ 96.4281]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0065],
        [ 5.0025],
        [ 5.0959],
        [ 9.9998],
        [ 5.0154],
        [ 5.0064],
        [ 5.0280],
        [ 5.0011],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4251],
        [ 5.7075],
        [ 5.7954],
        [ 5.3445],
        [10.0000],
        [ 5.7089],
        [ 5.6796],
        [ 5.0000],
        [ 5.7314],
        [ 5.5468]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4672],
        [ 5.1092],
        [ 5.0571],
        [ 5.7876],
        [10.0000],
        [ 5.0000],
        [ 5.3188],
        [ 5.4775],
        [ 5.1921],
        [ 5.8254]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0000],
        [140.0034],
        [140.0011],
        [142.2410],
        [140.0015],
        [140.0005],
        [140.0035],
        [140.0319],
        [140.0300]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1767],
        [51.4236],
        [51.6920],
        [48.6666],
        [72.9498],
        [51.4924],
        [51.3154],
        [47.9381],
        [51.4480],
        [50.7568]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 94.7469],
        [ 95.1826],
        [ 95.1806],
        [ 94.7290],
        [101.8265],
        [ 95.2012],
        [ 95.4841],
        [ 95.6440],
        [ 95.1690],
        [ 95.9112]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0000],
        [ 5.0077],
        [ 5.0024],
        [ 9.9998],
        [ 5.0033],
        [ 5.0010],
        [ 5.0078],
        [ 5.0713],
        [ 5.0670]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4475],
        [ 5.6968],
        [ 5.7504],
        [ 5.1456],
        [10.0000],
        [ 5.7105],
        [ 5.6751],
        [ 5.0000],
        [ 5.7017],
        [ 5.5635]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0126],
        [ 5.3196],
        [ 5.3181],
        [ 5.0000],
        [10.0000],
        [ 5.3326],
        [ 5.5319],
        [ 5.6446],
        [ 5.3100],
        [ 5.8329]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0034],
        [140.0022],
        [140.0379],
        [142.2410],
        [140.0061],
        [140.0030],
        [140.0102],
        [140.0026],
        [140.0020]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1935],
        [51.6219],
        [52.0557],
        [49.6868],
        [73.5636],
        [51.6348],
        [51.4822],
        [48.0115],
        [51.7355],
        [50.8128]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.7704],
        [ 95.3018],
        [ 95.2275],
        [ 96.2214],
        [102.8304],
        [ 95.1441],
        [ 95.6259],
        [ 95.8650],
        [ 95.4175],
        [ 96.3783]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0032],
        [ 5.0005],
        [ 5.0802],
        [ 9.9998],
        [ 5.0091],
        [ 5.0022],
        [ 5.0183],
        [ 5.0014],
        [ 5.0000]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4270],
        [ 5.7065],
        [ 5.7914],
        [ 5.3278],
        [10.0000],
        [ 5.7090],
        [ 5.6791],
        [ 5.0000],
        [ 5.7287],
        [ 5.5482]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4074],
        [ 5.1026],
        [ 5.0543],
        [ 5.7008],
        [10.0000],
        [ 5.0000],
        [ 5.3134],
        [ 5.4690],
        [ 5.1779],
        [ 5.8029]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [139.9998],
        [140.0049],
        [140.0354],
        [142.2410],
        [140.0099],
        [140.0034],
        [140.0138],
        [140.0564],
        [140.0517]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1480],
        [51.1454],
        [51.1780],
        [46.7734],
        [71.8162],
        [51.2665],
        [51.0835],
        [47.7879],
        [51.0682],
        [50.7281]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 93.1033],
        [ 94.9957],
        [ 95.1002],
        [ 92.4177],
        [100.0387],
        [ 95.3796],
        [ 95.2534],
        [ 95.2827],
        [ 94.8521],
        [ 95.4260]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0000],
        [ 5.0116],
        [ 5.0795],
        [ 9.9998],
        [ 5.0226],
        [ 5.0081],
        [ 5.0314],
        [ 5.1263],
        [ 5.1160]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.6738],
        [ 5.8729],
        [ 5.8794],
        [ 5.0000],
        [10.0000],
        [ 5.8971],
        [ 5.8606],
        [ 5.2026],
        [ 5.8575],
        [ 5.7896]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4498],
        [ 6.6913],
        [ 6.7599],
        [ 5.0000],
        [10.0000],
        [ 6.9432],
        [ 6.8604],
        [ 6.8796],
        [ 6.5971],
        [ 6.9737]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0066],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0190],
        [140.0174]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1815],
        [51.4815],
        [51.7965],
        [48.9610],
        [73.1292],
        [51.5338],
        [51.3643],
        [47.9591],
        [51.5315],
        [50.7746]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0349],
        [ 95.2169],
        [ 95.1934],
        [ 95.1429],
        [102.1153],
        [ 95.1732],
        [ 95.5247],
        [ 95.7067],
        [ 95.2397],
        [ 96.0378]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0019],
        [ 5.0072],
        [ 5.0153],
        [ 9.9998],
        [ 5.0002],
        [ 5.0001],
        [ 5.0000],
        [ 5.0428],
        [ 5.0393]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4415],
        [ 5.6997],
        [ 5.7623],
        [ 5.1990],
        [10.0000],
        [ 5.7101],
        [ 5.6764],
        [ 5.0000],
        [ 5.7097],
        [ 5.5593]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.1285],
        [ 5.1119],
        [ 5.0763],
        [10.0000],
        [ 5.0977],
        [ 5.3459],
        [ 5.4744],
        [ 5.1446],
        [ 5.7082]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4894],
        [51.8115],
        [49.0103],
        [73.1581],
        [51.5400],
        [51.3708],
        [47.9629],
        [51.5427],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0828],
        [ 95.2221],
        [ 95.1957],
        [ 95.2140],
        [102.1629],
        [ 95.1717],
        [ 95.5311],
        [ 95.7169],
        [ 95.2495],
        [ 96.0558]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2079],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0984],
        [ 5.0797],
        [ 5.0926],
        [10.0000],
        [ 5.0627],
        [ 5.3166],
        [ 5.4478],
        [ 5.1177],
        [ 5.6871]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0840],
        [ 95.2223],
        [ 95.1958],
        [ 95.2158],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
        [ 9.5841],
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0027],
        [140.0027],
        [140.0064],
        [142.2410],
        [140.0027],
        [140.0016],
        [140.0042],
        [140.0055],
        [140.0057]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1796],
        [51.4725],
        [51.7725],
        [48.8221],
        [73.0554],
        [51.5208],
        [51.3578],
        [47.9429],
        [51.5211],
        [50.7856]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 94.9073],
        [ 95.2062],
        [ 95.1855],
        [ 94.9424],
        [101.9877],
        [ 95.1601],
        [ 95.5106],
        [ 95.6791],
        [ 95.2270],
        [ 96.0143]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0024],
        [ 5.0024],
        [ 5.0107],
        [ 9.9998],
        [ 5.0025],
        [ 5.0000],
        [ 5.0057],
        [ 5.0086],
        [ 5.0092]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4453],
        [ 5.7028],
        [ 5.7625],
        [ 5.1751],
        [10.0000],
        [ 5.7124],
        [ 5.6799],
        [ 5.0000],
        [ 5.7124],
        [ 5.5660]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.2111],
        [ 5.1964],
        [ 5.0247],
        [10.0000],
        [ 5.1785],
        [ 5.4260],
        [ 5.5450],
        [ 5.2257],
        [ 5.7817]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0008],
        [140.0030],
        [140.0076],
        [142.2410],
        [139.9999],
        [139.9999],
        [139.9998],
        [140.0176],
        [140.0163]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1822],
        [51.4889],
        [51.8102],
        [49.0032],
        [73.1542],
        [51.5393],
        [51.3704],
        [47.9621],
        [51.5420],
        [50.7761]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0761],
        [ 95.2215],
        [ 95.1953],
        [ 95.2035],
        [102.1563],
        [ 95.1711],
        [ 95.5303],
        [ 95.7155],
        [ 95.2487],
        [ 96.0544]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0023],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0002],
        [ 5.0000],
        [ 5.0399],
        [ 5.0368]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4406],
        [ 5.7000],
        [ 5.7637],
        [ 5.2066],
        [10.0000],
        [ 5.7100],
        [ 5.6765],
        [ 5.0000],
        [ 5.7105],
        [ 5.5585]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.1027],
        [ 5.0842],
        [ 5.0900],
        [10.0000],
        [ 5.0670],
        [ 5.3208],
        [ 5.4515],
        [ 5.1219],
        [ 5.6908]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0183],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0112],
        [73.1586],
        [51.5401],
        [51.3710],
        [47.9629],
        [51.5429],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0837],
        [ 95.2222],
        [ 95.1958],
        [ 95.2153],
        [102.1638],
        [ 95.1716],
        [ 95.5312],
        [ 95.7171],
        [ 95.2497],
        [ 96.0562]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0414],
        [ 5.0381]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6999],
        [ 5.7638],
        [ 5.2080],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0978],
        [ 5.0791],
        [ 5.0929],
        [10.0000],
        [ 5.0620],
        [ 5.3160],
        [ 5.4473],
        [ 5.1172],
        [ 5.6868]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2158],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0414],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64,
       grad_fn=<UnsqueezeBackward0>)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64,
       grad_fn=<MulBackward0>)]
BEFORE NORMALIZATION: [tensor([[142.2411],
        [140.0007],
        [140.0030],
        [140.0077],
        [142.2410],
        [139.9999],
        [139.9998],
        [139.9998],
        [140.0184],
        [140.0169]], device='cuda:0', dtype=torch.float64), tensor([[50.1823],
        [51.4896],
        [51.8119],
        [49.0116],
        [73.1588],
        [51.5401],
        [51.3710],
        [47.9630],
        [51.5430],
        [50.7756]], device='cuda:0', dtype=torch.float64), tensor([[ 95.0841],
        [ 95.2223],
        [ 95.1958],
        [ 95.2159],
        [102.1642],
        [ 95.1716],
        [ 95.5313],
        [ 95.7172],
        [ 95.2497],
        [ 96.0563]], device='cuda:0', dtype=torch.float64)] SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) SHAPE IS = torch.Size([10, 1]) AFTER NORMALIZATION: [tensor([[10.0000],
        [ 5.0021],
        [ 5.0072],
        [ 5.0176],
        [ 9.9998],
        [ 5.0003],
        [ 5.0001],
        [ 5.0000],
        [ 5.0415],
        [ 5.0382]], device='cuda:0', dtype=torch.float64), tensor([[ 5.4404],
        [ 5.6998],
        [ 5.7638],
        [ 5.2081],
        [10.0000],
        [ 5.7099],
        [ 5.6763],
        [ 5.0000],
        [ 5.7104],
        [ 5.5582]], device='cuda:0', dtype=torch.float64), tensor([[ 5.0000],
        [ 5.0976],
        [ 5.0789],
        [ 5.0931],
        [10.0000],
        [ 5.0618],
        [ 5.3158],
        [ 5.4471],
        [ 5.1170],
        [ 5.6866]], device='cuda:0', dtype=torch.float64)]
BEFORE NORMALIZATION: [tensor([[140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682],
        [140.5682]], device='cuda:0', dtype=torch.float64), tensor([[56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322],
        [56.5322]], device='cuda:0', dtype=torch.float64), tensor([[109.6853],
        [163.1213],
        [110.1927],
        [125.3351],
        [ 95.1258],
        [154.9402],
        [120.2891],
        [155.9777],
        [ 97.0723],
        [139.6182],
        [120.4123],
        [148.6575],
        [113.1622],
        [159.6941],
        [114.6645],
        [114.7146],
        [163.8523],
        [111.5581],
        [121.8632],
        [115.1507],
        [149.8895],
        [ 93.8678],
        [153.4095],
        [117.5145],
        [150.6926],
        [ 92.5144],
        [155.4174],
        [111.9711],
        [160.2034],
        [103.6415],
        [118.7265],
        [102.9348],
        [139.3690],
        [100.7871],
        [143.6486],
        [135.9993],
        [159.3367],
        [105.9897],
        [134.2207],
        [112.7493],
        [165.6301],
        [ 98.4753],
        [134.9682],
        [112.3786],
        [139.0253],
        [ 95.7358],
        [136.5642],
        [120.2195],
        [ 91.3997],
        [145.7531],
        [123.8396],
        [146.6787],
        [100.7920],
        [170.6888],
        [108.0619],
        [139.8706],
        [ 98.1338],
        [159.1827],
        [112.8883],
        [129.6132],
        [ 97.0819],
        [135.8906],
        [124.1178],
        [141.6740],
        [157.2296],
        [117.1579],
        [154.4287],
        [ 89.5718],
        [123.3089],
        [108.0110],
        [165.7572],
        [113.2656],
        [120.2463],
        [112.8839],
        [156.3851],
        [111.3654],
        [148.2135],
        [113.5836],
        [144.3345],
        [ 90.9270],
        [122.5820],
        [147.7196],
        [ 95.1863],
        [145.0244],
        [115.7150],
        [125.9735],
        [118.4464],
        [162.1410],
        [108.0633],
        [119.0295],
        [108.6338],
        [159.1888],
        [118.6245],
        [147.8384],
        [ 95.7172],
        [148.5835],
        [113.8649],
        [137.0297],
        [ 99.2728],
        [164.8039],
        [124.4379],
        [144.9254],
        [ 96.7005],
        [144.1974],
        [112.1823],
        [143.9982],
        [ 91.5408],
        [135.7789],
        [113.8244],
        [131.6935],
        [ 97.4011],
        [170.6645],
        [140.2049],
        [113.6289],
        [171.7835],
        [102.9138],
        [144.1265],
        [125.6516],
        [139.1790],
        [ 96.7353],
        [139.3881],
        [127.6273],
        [132.5084],
        [ 99.4896],
        [129.0562],
        [114.6426],
        [163.2512],
        [ 99.0750],
        [141.9147],
        [ 93.6718],
        [146.1255],
        [119.8816],
        [168.6309],
        [ 94.8482],
        [133.4038],
        [103.2993],
        [171.9270],
        [104.5272],
        [134.2593],
        [113.1232],
        [136.1417],
        [ 94.5135],
        [148.4576],
        [130.3477],
        [ 96.3945],
        [127.3777],
        [127.4564],
        [138.7287],
        [101.0591],
        [165.3281],
        [116.1446],
        [126.6196],
        [100.6559],
        [170.6065],
        [105.3656],
        [133.8484],
        [ 97.3069],
        [139.6983],
        [130.2318],
        [148.9530],
        [108.9590],
        [155.2003],
        [110.7861],
        [117.2482],
        [ 97.3017],
        [148.8483],
        [118.4062],
        [151.7636],
        [ 90.2558],
        [158.7955],
        [113.5818],
        [152.8305],
        [110.7066],
        [163.8409],
        [111.8385],
        [132.4279],
        [157.2536],
        [106.2157],
        [120.2524],
        [111.0851],
        [148.1106],
        [ 95.1662],
        [145.6325],
        [113.0232],
        [151.4651],
        [100.8664],
        [147.1486],
        [123.5448],
        [152.3247],
        [113.7357],
        [122.6062],
        [114.7308],
        [108.2183],
        [128.8399],
        [100.2441],
        [168.0173],
        [126.8866],
        [139.5479],
        [ 94.4982],
        [132.5973],
        [130.9848],
        [139.0302],
        [ 98.1403],
        [132.0112],
        [113.6169],
        [137.0487],
        [106.0537],
        [166.7550],
        [132.8694],
        [111.7189],
        [167.6661],
        [104.5785],
        [141.5184],
        [124.1205],
        [132.2041],
        [ 90.1083],
        [150.9055],
        [128.3313],
        [144.9370],
        [ 92.2995],
        [137.6738],
        [106.7473],
        [170.9543],
        [102.5912],
        [144.8792],
        [117.2631],
        [143.6599],
        [ 99.3227],
        [118.0352],
        [115.2229],
        [153.8468],
        [104.8558],
        [126.4690],
        [114.1316],
        [166.0919],
        [112.7584],
        [150.6313],
        [115.8700],
        [148.3515],
        [ 95.2095],
        [104.1310],
        [152.1774],
        [ 93.4958],
        [150.1726],
        [113.0122],
        [123.3742],
        [105.7603],
        [163.0223],
        [115.8389],
        [125.1153],
        [110.9771],
        [160.3729],
        [117.8296],
        [153.2269],
        [ 93.9281],
        [156.1017],
        [ 91.5511],
        [141.1268],
        [120.2602],
        [141.6659],
        [ 96.3083],
        [169.6316],
        [106.6602],
        [136.5604],
        [102.6516],
        [163.5068],
        [109.1642],
        [136.1675],
        [ 98.7209],
        [142.6044],
        [133.7644],
        [146.8626],
        [133.9634],
        [100.7436],
        [140.1624],
        [128.5827],
        [157.4642],
        [100.1565],
        [124.7454],
        [114.9070],
        [166.5653],
        [102.5075],
        [138.2366],
        [111.0239],
        [143.4409],
        [ 95.5426],
        [142.6376],
        [127.0814],
        [161.7142],
        [107.9527],
        [117.8115],
        [111.9326],
        [143.5148],
        [ 95.8479],
        [151.4440],
        [117.0040],
        [157.1454],
        [ 92.9448],
        [159.0758],
        [118.5536],
        [165.6014],
        [107.3945],
        [127.6229],
        [105.0270],
        [105.8003],
        [156.2717],
        [103.8599],
        [114.9676],
        [ 95.7429],
        [148.4970],
        [115.9105],
        [152.8470],
        [ 96.2918],
        [144.3724],
        [122.3060],
        [152.0785],
        [115.9057],
        [162.6358],
        [116.3184],
        [117.2437],
        [129.0213],
        [115.6391],
        [167.3262],
        [100.2016],
        [142.1284],
        [116.8609],
        [132.5908],
        [ 94.8224],
        [143.9979],
        [129.9601],
        [139.5701],
        [ 99.2698],
        [131.4737],
        [114.8014],
        [163.8539],
        [103.1368],
        [111.6864],
        [133.1916],
        [ 94.7156],
        [166.0470],
        [123.5995],
        [141.3709],
        [ 98.6077],
        [135.9259],
        [125.1636],
        [148.5377],
        [ 94.5194],
        [142.1783],
        [109.3489],
        [142.9043],
        [ 99.8804],
        [173.5507],
        [117.6051],
        [145.9628],
        [ 93.5681],
        [141.0294],
        [114.8695],
        [116.4741],
        [112.8088],
        [154.2135],
        [110.9097],
        [120.8410],
        [114.3923],
        [161.1749],
        [120.6475],
        [153.0391],
        [ 93.8916],
        [153.1997],
        [152.4866],
        [117.6236],
        [149.8038],
        [ 91.5980],
        [120.9425],
        [101.8994],
        [163.7890],
        [107.2388],
        [127.1416],
        [111.9337],
        [164.9248],
        [113.6235],
        [151.3768],
        [121.2296],
        [147.8975],
        [ 92.7047],
        [160.8521],
        [112.1438],
        [127.2119],
        [114.2918],
        [157.0564],
        [ 92.7620],
        [151.2318],
        [117.4500],
        [147.3313],
        [100.9248],
        [147.9686],
        [120.5686],
        [150.0432],
        [111.1030],
        [115.1308],
        [114.4169],
        [111.9041],
        [155.5921],
        [109.4521],
        [123.2595],
        [ 95.6722],
        [153.7338],
        [122.5786],
        [152.5716],
        [ 92.4255],
        [151.1225],
        [110.2785],
        [149.4946],
        [102.9519],
        [160.2240],
        [108.0243],
        [121.8648],
        [ 97.8191],
        [134.9092],
        [134.3379],
        [147.0213],
        [107.5886],
        [167.9496],
        [115.0182],
        [130.1060],
        [ 99.1977],
        [166.9952],
        [105.6217],
        [128.4757],
        [ 95.3587],
        [136.9053],
        [124.6529],
        [145.3723],
        [144.3497],
        [ 95.8518],
        [152.8625],
        [126.6154],
        [171.6913],
        [ 96.0465],
        [137.3130],
        [103.7879],
        [167.0406],
        [ 99.1620],
        [128.8370],
        [111.9212],
        [130.7166],
        [ 93.9823],
        [142.4910],
        [125.1064],
        [110.8437],
        [153.3858],
        [ 93.7377],
        [152.2022],
        [111.9429],
        [129.4514],
        [109.0192],
        [167.8720],
        [110.9734],
        [119.3218],
        [102.2009],
        [155.2588],
        [115.5158],
        [149.2385],
        [ 96.5073],
        [147.2641],
        [151.1190],
        [121.0716],
        [153.6307],
        [ 96.9390],
        [121.9142],
        [117.6064],
        [156.0782],
        [114.2535],
        [117.0475],
        [114.3555],
        [160.7784],
        [109.7691],
        [151.4169],
        [108.6107],
        [146.3225],
        [ 95.2635],
        [138.5957],
        [108.2946],
        [171.0639],
        [105.2205],
        [143.7381],
        [129.2302],
        [134.8622],
        [ 93.6984],
        [143.9034],
        [125.0419],
        [136.6129],
        [ 91.6671],
        [130.0353],
        [105.7875],
        [170.3106],
        [ 96.4635],
        [109.8124],
        [133.4700],
        [104.9304],
        [168.4477],
        [131.7772],
        [149.5126],
        [ 94.6591],
        [142.3940],
        [126.8434],
        [138.1397],
        [ 94.4925],
        [131.8562],
        [115.1716],
        [129.8424],
        [107.0376],
        [162.9190]], device='cuda:0', dtype=torch.float64)] SHAPE IS = torch.Size([512, 1])
Traceback (most recent call last):
  File "/home/abdelmajid/workdir/cost-aware-bo/main.py", line 61, in <module>
    bo_trial(trial_number=trial, acqf=args.acqf, wandb=wandb, params=params)
  File "/home/abdelmajid/workdir/cost-aware-bo/single_trial.py", line 62, in bo_trial
    new_x, n_memoised, E_c, E_inv_c, y_pred = bo_iteration(X, Y, C, bounds=bounds, acqf_str=acqf, decay=eta, iter=iteration, params=params)
  File "/home/abdelmajid/workdir/cost-aware-bo/single_iteration.py", line 72, in bo_iteration
    new_x, n_memoised = optimize_acqf_by_mem(acqf=acqf, acqf_str=acqf_str, bounds=norm_bounds, iter=iter, prefix_pool=prefix_pool, seed=params['rand_seed'])
  File "/home/abdelmajid/workdir/cost-aware-bo/optimize_mem_acqf.py", line 26, in optimize_acqf_by_mem
    new_candidate, acqf_val = optimize_acqf(acq_function=acqf, acq_type=acqf_str, delta=pref_stages, curr_iter=iter, bounds=bounds, q=1, num_restarts=10, raw_samples=512, options={'seed': seed})
  File "/home/abdelmajid/workdir/cost-aware-bo/optimizer/optimize_acqf_funcs.py", line 401, in optimize_acqf
    return _optimize_acqf(opt_acqf_inputs)
  File "/home/abdelmajid/miniconda3/envs/tuun/lib/python3.10/site-packages/botorch/optim/optimize.py", line 554, in _optimize_acqf
    return _optimize_acqf_batch(
  File "/home/abdelmajid/workdir/cost-aware-bo/optimizer/optimize_acqf_funcs.py", line 414, in _optimize_acqf_batch
    batch_initial_conditions = opt_inputs.get_ic_generator()(
  File "/home/abdelmajid/workdir/cost-aware-bo/optimizer/optimize_acqf_funcs.py", line 221, in gen_batch_initial_conditions
    ).cpu() if 'EIPU' not in acq_type else acq_function(
  File "/home/abdelmajid/miniconda3/envs/tuun/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/abdelmajid/miniconda3/envs/tuun/lib/python3.10/site-packages/botorch/utils/transforms.py", line 287, in decorated
    output = method(acqf, X, *args, **kwargs)
  File "/home/abdelmajid/workdir/cost-aware-bo/EEIPU/EIPUVariants.py", line 158, in forward
    costs[stage] = self.cost_normalizer(costs[stage], self.params)
  File "/home/abdelmajid/workdir/cost-aware-bo/functions.py", line 59, in normalize_cost
    assert data.min() > 0
AssertionError